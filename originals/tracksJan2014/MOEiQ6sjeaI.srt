1
00:00:00,000 --> 00:00:00,240

2
00:00:00,240 --> 00:00:02,082
JAKE: He wrote the
high-performance browser

3
00:00:02,082 --> 00:00:03,540
networking book
for O'Reilly, which

4
00:00:03,540 --> 00:00:07,050
is also available for free
in the links on his website.

5
00:00:07,050 --> 00:00:08,600
If the internet is
a series of tubes,

6
00:00:08,600 --> 00:00:11,096
then this is one of the
world's greatest plumbers.

7
00:00:11,096 --> 00:00:12,470
Hands together
for Ilya Grigorik.

8
00:00:12,470 --> 00:00:15,820
[APPLAUSE]

9
00:00:15,820 --> 00:00:18,334
ILYA GRIGORIK: All
right, thanks, Jake.

10
00:00:18,334 --> 00:00:20,250
All right, so we're going
to talk a little bit

11
00:00:20,250 --> 00:00:23,130
about optimizing network
performance and specifically

12
00:00:23,130 --> 00:00:25,610
some of the things that we've
been doing on the Chrome team

13
00:00:25,610 --> 00:00:28,450
for helping deliver better apps.

14
00:00:28,450 --> 00:00:32,080
And I guess the first
thing that we should ask

15
00:00:32,080 --> 00:00:33,910
is, does it matter, right?

16
00:00:33,910 --> 00:00:35,750
What's the problem
we're trying to solve?

17
00:00:35,750 --> 00:00:38,550
And Tony Gentilcore, who's
actually somewhere here

18
00:00:38,550 --> 00:00:41,140
in the room, ran a
number of different tests

19
00:00:41,140 --> 00:00:43,070
over the last couple
of months, where

20
00:00:43,070 --> 00:00:46,250
he's been kind of deep
diving into where do we

21
00:00:46,250 --> 00:00:46,890
spend our time.

22
00:00:46,890 --> 00:00:48,940
Like when we try to
render a web page, what

23
00:00:48,940 --> 00:00:50,210
are the bottlenecks today?

24
00:00:50,210 --> 00:00:52,212
And he has a series
of these posts

25
00:00:52,212 --> 00:00:54,170
on Blink-dev if you guys
are interested in kind

26
00:00:54,170 --> 00:00:56,200
of low-level guts
of how Blink works

27
00:00:56,200 --> 00:00:58,100
and in Chrome kind
of end to end.

28
00:00:58,100 --> 00:01:00,730
But one test to me stood
out, in particular.

29
00:01:00,730 --> 00:01:03,769
And this is a test where we took
the top 1 million Alexa sites

30
00:01:03,769 --> 00:01:05,560
and just ran them
through Chrome and looked

31
00:01:05,560 --> 00:01:06,810
at where do we spend our time?

32
00:01:06,810 --> 00:01:09,970
Like in terms of the
actual main Blink thread,

33
00:01:09,970 --> 00:01:11,370
where is the time going?

34
00:01:11,370 --> 00:01:14,980
And the big takeaway here
is that, approximately 70%

35
00:01:14,980 --> 00:01:17,164
of the time, we're
just basically idling

36
00:01:17,164 --> 00:01:18,080
on the network, right?

37
00:01:18,080 --> 00:01:20,370
That's that big chunk
right here in the blue.

38
00:01:20,370 --> 00:01:23,246
And then after that, you have
all of your usual offenders,

39
00:01:23,246 --> 00:01:25,370
things like, well, we've
got to get the JavaScript,

40
00:01:25,370 --> 00:01:28,904
we've got to paint pixels,
and all the rest, do layouts.

41
00:01:28,904 --> 00:01:30,570
So this should not
be surprising, right?

42
00:01:30,570 --> 00:01:32,590
This is specifically
for the first page load.

43
00:01:32,590 --> 00:01:34,034
There's a very
different profile,

44
00:01:34,034 --> 00:01:35,450
of course, once
the page is loaded

45
00:01:35,450 --> 00:01:37,020
and you're interacting
with the page.

46
00:01:37,020 --> 00:01:38,430
That's a different problem.

47
00:01:38,430 --> 00:01:41,555
But this, in part,
is one big problem

48
00:01:41,555 --> 00:01:42,680
that we're trying to solve.

49
00:01:42,680 --> 00:01:46,932
Like how do we make this blue
part smaller or just go faster?

50
00:01:46,932 --> 00:01:49,140
So there's two takeaways
that you can take from this.

51
00:01:49,140 --> 00:01:53,390
One is, page loads in
network are a problem, right?

52
00:01:53,390 --> 00:01:56,130
That's 70% of loading
the page today.

53
00:01:56,130 --> 00:02:00,510
But the good news is that if we
can do anything to the network

54
00:02:00,510 --> 00:02:02,880
stack in terms of improving
that latency and improving

55
00:02:02,880 --> 00:02:05,660
performance, it's going to have
a significant impact on how

56
00:02:05,660 --> 00:02:06,850
we experience the web.

57
00:02:06,850 --> 00:02:09,889
So even small fractional
wins in this space

58
00:02:09,889 --> 00:02:13,770
will, in fact, have
huge performance impact.

59
00:02:13,770 --> 00:02:15,930
So kind of with that in
mind, what I wanted to do

60
00:02:15,930 --> 00:02:19,280
is actually take a look
at some of the things

61
00:02:19,280 --> 00:02:21,280
that we've been working
on internally in Chrome.

62
00:02:21,280 --> 00:02:22,904
This is kind of
looking under the hood.

63
00:02:22,904 --> 00:02:24,530
This is not perhaps
something that you

64
00:02:24,530 --> 00:02:27,104
would be, as a developer,
looking at APIs

65
00:02:27,104 --> 00:02:28,770
or trying to figure
out how to optimize.

66
00:02:28,770 --> 00:02:31,030
This is the kind of stuff
that Chrome does internally.

67
00:02:31,030 --> 00:02:34,480
But we have a very dedicated
and awesome performance team

68
00:02:34,480 --> 00:02:35,510
working on this stuff.

69
00:02:35,510 --> 00:02:37,270
And I wanted to highlight
some of the wins

70
00:02:37,270 --> 00:02:41,290
that we had over the last year
and also kind of essentially

71
00:02:41,290 --> 00:02:42,760
so you know what
we're working on

72
00:02:42,760 --> 00:02:46,460
and also highlight the
potential areas for improvement

73
00:02:46,460 --> 00:02:47,492
in the future.

74
00:02:47,492 --> 00:02:48,950
And after that,
we're going to look

75
00:02:48,950 --> 00:02:51,180
at some of the new
additions, specifically,

76
00:02:51,180 --> 00:02:52,910
kind of low-level
network plumbing

77
00:02:52,910 --> 00:02:54,660
stuff that we support
in Chrome, so things

78
00:02:54,660 --> 00:02:58,340
like SPDY, some notes about
QUIC, and other things.

79
00:02:58,340 --> 00:03:00,760
And then finally we'll talk
about measurements, right?

80
00:03:00,760 --> 00:03:02,385
Of course, performance
is the big theme

81
00:03:02,385 --> 00:03:04,056
throughout this entire event.

82
00:03:04,056 --> 00:03:06,180
And we want to make sure
that we give you the tools

83
00:03:06,180 --> 00:03:10,190
to measure performance
in the best way possible.

84
00:03:10,190 --> 00:03:13,670
You should be able to measure
anything you need in the stack.

85
00:03:13,670 --> 00:03:17,090
So first, let's actually
do a quick survey.

86
00:03:17,090 --> 00:03:19,020
This is going to be kind
of all over the map,

87
00:03:19,020 --> 00:03:21,380
but I want to
highlight a few things.

88
00:03:21,380 --> 00:03:26,380
First, in Chrome 26, we landed
the new asynchronous DNS

89
00:03:26,380 --> 00:03:29,610
resolver, which is kind of
low-level plumbing stuff,

90
00:03:29,610 --> 00:03:32,410
so we're no longer relying
on the operating system DNS

91
00:03:32,410 --> 00:03:32,910
resolver.

92
00:03:32,910 --> 00:03:35,940
We actually have our own.

93
00:03:35,940 --> 00:03:39,960
Today, it's available on
Windows, Mac, and Chrome

94
00:03:39,960 --> 00:03:42,930
OS, so this is
not yet on mobile.

95
00:03:42,930 --> 00:03:44,370
Hopefully, it will be.

96
00:03:44,370 --> 00:03:46,775
So why did we want to do this?

97
00:03:46,775 --> 00:03:48,900
Well, first of all, it
gives us a lot more control.

98
00:03:48,900 --> 00:03:51,810
We can do a lot
smarter strategies

99
00:03:51,810 --> 00:03:54,190
for high resolve names
and other things.

100
00:03:54,190 --> 00:03:56,730
And here's some
performance numbers

101
00:03:56,730 --> 00:04:01,100
in terms of what we've seen
since we've landed M26.

102
00:04:01,100 --> 00:04:03,410
It took us a couple of tries
to actually kind of get

103
00:04:03,410 --> 00:04:05,390
the performance numbers
as good as they are.

104
00:04:05,390 --> 00:04:07,265
But you can see that
there's significant wins

105
00:04:07,265 --> 00:04:08,200
across the board.

106
00:04:08,200 --> 00:04:10,920
And for things like
Chrome OS, we've

107
00:04:10,920 --> 00:04:14,736
reduced the DNS resolution
time significantly, 36%.

108
00:04:14,736 --> 00:04:16,110
And not only that,
but we're also

109
00:04:16,110 --> 00:04:18,130
measuring the resolve
plus TCP connect.

110
00:04:18,130 --> 00:04:20,545
And you can see that there
are wins across the board.

111
00:04:20,545 --> 00:04:22,670
And of course, some of
these are platform specific.

112
00:04:22,670 --> 00:04:24,310
Some platforms just
do a better job

113
00:04:24,310 --> 00:04:27,150
of implementing their DNS
resolvers in the first place.

114
00:04:27,150 --> 00:04:29,502
But the cool thing is
that we can actually now

115
00:04:29,502 --> 00:04:30,960
kind of take control
now that we've

116
00:04:30,960 --> 00:04:32,770
got the basic plumbing working.

117
00:04:32,770 --> 00:04:35,110
We can take control
and do smarter things.

118
00:04:35,110 --> 00:04:38,650
So, for example, we can
raise different resolutions

119
00:04:38,650 --> 00:04:40,520
for IPv6 and IPv4.

120
00:04:40,520 --> 00:04:42,620
We are now actually
doing adaptive retry,

121
00:04:42,620 --> 00:04:45,790
so we actually remember
which DNS servers we've used.

122
00:04:45,790 --> 00:04:50,970
So we can do a better job of
making these resolutions faster

123
00:04:50,970 --> 00:04:52,680
in the future.

124
00:04:52,680 --> 00:04:56,810
And this is definitely a
space for a lot of improvement

125
00:04:56,810 --> 00:05:00,795
and also kind of subtle things
like providing better user

126
00:05:00,795 --> 00:05:02,790
error pages, right?

127
00:05:02,790 --> 00:05:05,430
Before you would just
get a failed timeout

128
00:05:05,430 --> 00:05:06,401
from DNS resolution.

129
00:05:06,401 --> 00:05:08,150
I mean, you just kind
of like, we give up.

130
00:05:08,150 --> 00:05:08,816
We have no idea.

131
00:05:08,816 --> 00:05:11,290
We can't give any useful
feedback to the user.

132
00:05:11,290 --> 00:05:12,800
Now we can go
much, much further.

133
00:05:12,800 --> 00:05:13,950
So that's pretty cool.

134
00:05:13,950 --> 00:05:18,050
Moving on, in M27, we landed
this big and important

135
00:05:18,050 --> 00:05:20,080
improvement, which is we
completely rewrote how

136
00:05:20,080 --> 00:05:21,540
we schedule resources.

137
00:05:21,540 --> 00:05:24,150
It's one thing for us
to get the HTML bytes.

138
00:05:24,150 --> 00:05:25,541
We then discovered
the resources.

139
00:05:25,541 --> 00:05:27,790
And then we need to figure
out how do we schedule them

140
00:05:27,790 --> 00:05:30,620
efficiently on the wire,
like we care about JavaScript

141
00:05:30,620 --> 00:05:33,070
before images and other things.

142
00:05:33,070 --> 00:05:37,620
And the big change that we've
done in there, in M27, is we

143
00:05:37,620 --> 00:05:40,150
replaced that scheduler.

144
00:05:40,150 --> 00:05:43,090
And we also started focusing
on perceived performance.

145
00:05:43,090 --> 00:05:45,090
So instead of just measuring
the page load time,

146
00:05:45,090 --> 00:05:47,500
we started measuring
things like speed index.

147
00:05:47,500 --> 00:05:50,480
So what kind of optimizations
we can do in Resource Scheduler

148
00:05:50,480 --> 00:05:51,590
to improve speed index.

149
00:05:51,590 --> 00:05:55,970
In fact, we've made decisions
where we've intentionally

150
00:05:55,970 --> 00:05:59,740
chosen speed index over
page load time, or unload.

151
00:05:59,740 --> 00:06:01,420
So there are changes
that have gone

152
00:06:01,420 --> 00:06:04,840
in where we've regressed,
in some cases, on load time.

153
00:06:04,840 --> 00:06:06,820
But we've improved
speed index, because we

154
00:06:06,820 --> 00:06:08,760
think that perceived
performance, getting

155
00:06:08,760 --> 00:06:13,140
useful pixels on the screen,
is a win for the user.

156
00:06:13,140 --> 00:06:16,350
And one interesting
takeaway from this work

157
00:06:16,350 --> 00:06:20,730
that was done in M27 was that
we realized that a lot of pages

158
00:06:20,730 --> 00:06:22,970
were actually competing for
bandwidth unnecessarily.

159
00:06:22,970 --> 00:06:25,350
So they were trying to
download too many things.

160
00:06:25,350 --> 00:06:28,770
We've gotten so good at charting
our assets that it's actually

161
00:06:28,770 --> 00:06:31,220
backfiring on a lot of sites.

162
00:06:31,220 --> 00:06:34,800
So, in particular, one
big interesting change

163
00:06:34,800 --> 00:06:38,490
that went in in that iteration
was that the new scheduler

164
00:06:38,490 --> 00:06:40,950
would only download up
to 10 images in parallel.

165
00:06:40,950 --> 00:06:43,610
So, for example, if you
have a gallery of images,

166
00:06:43,610 --> 00:06:45,800
you have let's say 30
of them on the page,

167
00:06:45,800 --> 00:06:48,640
and you sharded them
in 20 different ways,

168
00:06:48,640 --> 00:06:51,322
we would not open more than
10 connections at once.

169
00:06:51,322 --> 00:06:52,780
Because we found
that that actually

170
00:06:52,780 --> 00:06:56,190
hurts performance in most cases.

171
00:06:56,190 --> 00:06:59,070
So if you're developing
your site today,

172
00:06:59,070 --> 00:07:01,940
Chrome will limit you
to 10 image downloads.

173
00:07:01,940 --> 00:07:05,270
But in other browsers,
you'll still have no problem.

174
00:07:05,270 --> 00:07:08,670
I'm not sure what exact
scheduling algorithms

175
00:07:08,670 --> 00:07:10,470
they're using, but
perhaps something you

176
00:07:10,470 --> 00:07:11,790
should consider on your site.

177
00:07:11,790 --> 00:07:16,110
There is such thing as
oversharding your site.

178
00:07:16,110 --> 00:07:18,600
Later in M28, speaking
of perceived performance,

179
00:07:18,600 --> 00:07:22,970
we've also improved the SPDY
performance quite a bit.

180
00:07:22,970 --> 00:07:26,037
So the change here is
actually pretty awesome

181
00:07:26,037 --> 00:07:27,620
and pretty trivial
in that now that we

182
00:07:27,620 --> 00:07:29,030
have control over the
Resource Scheduler

183
00:07:29,030 --> 00:07:30,770
we said, look, if
you're using SPDY,

184
00:07:30,770 --> 00:07:33,530
we have a much better way
to schedule resources, which

185
00:07:33,530 --> 00:07:34,550
is we know the priority.

186
00:07:34,550 --> 00:07:36,620
We can send that
priority to the server.

187
00:07:36,620 --> 00:07:38,250
The server can do
the right thing.

188
00:07:38,250 --> 00:07:41,429
So we won't delay any
resource scheduling

189
00:07:41,429 --> 00:07:43,970
on the client, which is kind of
this like this fake latency--

190
00:07:43,970 --> 00:07:46,540
not fake, unnecessary
latency that we're otherwise

191
00:07:46,540 --> 00:07:47,500
introducing.

192
00:07:47,500 --> 00:07:50,330
So if you're using SPDY,
this is a nice performance

193
00:07:50,330 --> 00:07:52,100
win because it allows
us once again to get

194
00:07:52,100 --> 00:07:55,420
those pixels visible
earlier on the screen.

195
00:07:55,420 --> 00:07:58,490
So if you haven't
already, I definitely

196
00:07:58,490 --> 00:08:01,620
encourage you to look
into playing with SPDY.

197
00:08:01,620 --> 00:08:04,500
So if you're using Apache, you
can sell them on SPDY EngineX,

198
00:08:04,500 --> 00:08:06,810
and other server are
supported as well.

199
00:08:06,810 --> 00:08:10,610
And actually, we'll come back
to SPDY a little bit later.

200
00:08:10,610 --> 00:08:14,150
In M30, there's been
yet more improvements

201
00:08:14,150 --> 00:08:16,470
to the Resource Scheduler.

202
00:08:16,470 --> 00:08:19,290
We keep improving
and iterating on all

203
00:08:19,290 --> 00:08:20,740
of these different strategies.

204
00:08:20,740 --> 00:08:24,430
One interesting kind of takeaway
that we had in this iteration

205
00:08:24,430 --> 00:08:27,130
was that we actually
started distinguishing

206
00:08:27,130 --> 00:08:30,350
between optimizing for the
popular sites versus sites

207
00:08:30,350 --> 00:08:31,300
in the tail.

208
00:08:31,300 --> 00:08:32,960
There's different
ways that sites

209
00:08:32,960 --> 00:08:35,600
are constructed in terms of
kind of patterns that they use,

210
00:08:35,600 --> 00:08:37,780
how they lay out the
resources, and all the rest.

211
00:08:37,780 --> 00:08:41,010
And this iteration,
in particular,

212
00:08:41,010 --> 00:08:43,409
actually helped
quite a bit in terms

213
00:08:43,409 --> 00:08:47,440
of accelerating the
sites in the long tail.

214
00:08:47,440 --> 00:08:49,460
And if you think about
a 10% improvement

215
00:08:49,460 --> 00:08:51,390
in firing the
onload, this is just

216
00:08:51,390 --> 00:08:55,500
like one Chrome m
revision, it's huge.

217
00:08:55,500 --> 00:08:59,720
That's a 10% win in onload and
a 9% improvement in speed index.

218
00:08:59,720 --> 00:09:01,850
So there's just faster
pixels on the screen.

219
00:09:01,850 --> 00:09:04,110
So these are impressive numbers.

220
00:09:04,110 --> 00:09:07,780
And I think what's most exciting
for me is if we look forward,

221
00:09:07,780 --> 00:09:10,560
based on the work that we
have in the pipeline now,

222
00:09:10,560 --> 00:09:14,770
and project it a little bit,
we see significant improvements

223
00:09:14,770 --> 00:09:16,670
that we can still make
to these algorithms.

224
00:09:16,670 --> 00:09:20,820
So right now, at least based on
the current code that we have,

225
00:09:20,820 --> 00:09:26,060
you can expect more wins
rolling out to our users.

226
00:09:26,060 --> 00:09:27,967
So this is great.

227
00:09:27,967 --> 00:09:30,050
As far as I'm concerned,
this is free performance.

228
00:09:30,050 --> 00:09:31,837
Like the apps,
it's the same apps,

229
00:09:31,837 --> 00:09:33,670
they're just rendering
faster, because we're

230
00:09:33,670 --> 00:09:35,240
doing a better job
of how we schedule

231
00:09:35,240 --> 00:09:37,080
those resources in Chrome.

232
00:09:37,080 --> 00:09:39,480
So that's pretty exciting.

233
00:09:39,480 --> 00:09:45,010
Another huge win that's coming
and that's available on Android

234
00:09:45,010 --> 00:09:47,650
today is what we're
calling the "simple Cache".

235
00:09:47,650 --> 00:09:50,650
So one of the problems
that we realized

236
00:09:50,650 --> 00:09:53,460
that we had on Android
and mobile phones,

237
00:09:53,460 --> 00:09:57,560
in particular, is that in order
for us to dispatch a network

238
00:09:57,560 --> 00:10:00,060
request, we actually had to do
a number of different context

239
00:10:00,060 --> 00:10:00,560
switches.

240
00:10:00,560 --> 00:10:03,150
Like we would go from the main
threads to an I/O thread to

241
00:10:03,150 --> 00:10:04,480
we'd do another jump.

242
00:10:04,480 --> 00:10:09,100
We would always do a check
on the file system, which

243
00:10:09,100 --> 00:10:11,220
in itself can take
quite a bit of time.

244
00:10:11,220 --> 00:10:14,540
And the idea behind Simple Cache
is to try to simplify that,

245
00:10:14,540 --> 00:10:17,880
as the name implies,
to the extent

246
00:10:17,880 --> 00:10:21,610
that we can, and ideally, avoid
any context switches ongoing

247
00:10:21,610 --> 00:10:22,500
to disk.

248
00:10:22,500 --> 00:10:24,260
So that should help
quite a bit in terms

249
00:10:24,260 --> 00:10:28,130
of the actual performance
of the Simple Cache.

250
00:10:28,130 --> 00:10:29,920
And here's some early numbers.

251
00:10:29,920 --> 00:10:31,910
These look very, very good.

252
00:10:31,910 --> 00:10:34,360
The blue line on the
bottom is the original,

253
00:10:34,360 --> 00:10:37,364
and what you see
here is the latency.

254
00:10:37,364 --> 00:10:39,530
So you kind of had this
like long tail distribution,

255
00:10:39,530 --> 00:10:41,320
where basically every
request incurred

256
00:10:41,320 --> 00:10:43,590
a minimum of several
milliseconds.

257
00:10:43,590 --> 00:10:45,230
But then you had
this long tail, where

258
00:10:45,230 --> 00:10:48,790
it wasn't atypical for a
request to take 50 milliseconds

259
00:10:48,790 --> 00:10:50,402
before we could
even dispatch it.

260
00:10:50,402 --> 00:10:52,360
Because we had to kind
of do a couple of thread

261
00:10:52,360 --> 00:10:55,030
hops and then check
disk, or check

262
00:10:55,030 --> 00:10:58,740
Flash, in this case, and
kind of bubble that back up.

263
00:10:58,740 --> 00:11:00,685
With the new Simple
Cache, basically we

264
00:11:00,685 --> 00:11:02,060
can just complete
it immediately,

265
00:11:02,060 --> 00:11:03,320
most of the requests.

266
00:11:03,320 --> 00:11:06,190
Every once in a while, we
still have some delays,

267
00:11:06,190 --> 00:11:09,100
but this is the
type of line where

268
00:11:09,100 --> 00:11:12,020
you want to see on all of
your performance charts.

269
00:11:12,020 --> 00:11:16,730
And this is quite amazing
because once we have the Simple

270
00:11:16,730 --> 00:11:20,200
Cache, based on
our measurements,

271
00:11:20,200 --> 00:11:22,794
this has improved all
HTTP transfers, the speed

272
00:11:22,794 --> 00:11:24,460
of these transfers,
in terms of the time

273
00:11:24,460 --> 00:11:26,110
from the first
request byte that we

274
00:11:26,110 --> 00:11:28,850
want to send to
completion by 10%, which,

275
00:11:28,850 --> 00:11:31,500
if you think about
it, is massive, right?

276
00:11:31,500 --> 00:11:33,620
And not only that,
but in M31 we're

277
00:11:33,620 --> 00:11:36,860
seeing 7% page load
time improvement.

278
00:11:36,860 --> 00:11:39,200
So this is simply eliminating
that extra latency

279
00:11:39,200 --> 00:11:42,190
at the beginning of
each and every request.

280
00:11:42,190 --> 00:11:45,337
And once again, there's
more work going into M32,

281
00:11:45,337 --> 00:11:47,420
and we hope that we can
improve this even further.

282
00:11:47,420 --> 00:11:50,425
So this is huge,
and this will be

283
00:11:50,425 --> 00:11:53,590
an awesome win for
mobile browsers.

284
00:11:53,590 --> 00:11:56,100
And then finally, one of
the last things that we've

285
00:11:56,100 --> 00:11:58,234
started iterating towards
the end of the year here,

286
00:11:58,234 --> 00:12:00,400
and something that I'm
really, really excited about,

287
00:12:00,400 --> 00:12:05,412
is focusing on improving the
speculative optimizations

288
00:12:05,412 --> 00:12:06,620
that we already do in Chrome.

289
00:12:06,620 --> 00:12:10,140
We do a lot of speculative
optimization as it is today.

290
00:12:10,140 --> 00:12:12,527
But now we're also looking
at how do we refine these?

291
00:12:12,527 --> 00:12:14,110
How do we expose the
right primitives,

292
00:12:14,110 --> 00:12:15,693
and how do we make
better use of them?

293
00:12:15,693 --> 00:12:17,860
One example is something
like prefetch, right?

294
00:12:17,860 --> 00:12:21,010
So if you're familiar
with a link rel=prefetch,

295
00:12:21,010 --> 00:12:22,870
what it allows you
to say is, hey,

296
00:12:22,870 --> 00:12:25,177
I will need this resource
perhaps on the next page.

297
00:12:25,177 --> 00:12:26,760
That could be an
HTML page, that could

298
00:12:26,760 --> 00:12:29,390
be a CSS file, an
image, what have you.

299
00:12:29,390 --> 00:12:30,960
Please fetch this
for me, such that I

300
00:12:30,960 --> 00:12:33,920
don't have to fetch that,
or I can just fetch it out

301
00:12:33,920 --> 00:12:36,850
of the cache when the
user initiates that load.

302
00:12:36,850 --> 00:12:39,720
One of the gotchas there
was, if that request did not

303
00:12:39,720 --> 00:12:41,680
complete in time for
the next navigation,

304
00:12:41,680 --> 00:12:42,620
it would get canceled.

305
00:12:42,620 --> 00:12:44,300
So you kind of incur
the double download

306
00:12:44,300 --> 00:12:46,480
and it just didn't make sense.

307
00:12:46,480 --> 00:12:49,410
So, for example, we have
this new patch that's in.

308
00:12:49,410 --> 00:12:52,640
It's not available in Canary
yet, but it's coming soon,

309
00:12:52,640 --> 00:12:54,740
called detachable prefetch,
which will actually

310
00:12:54,740 --> 00:12:57,890
keep the prefetch alive even
as you navigate away, such

311
00:12:57,890 --> 00:12:59,910
that you can still make
use of that resource

312
00:12:59,910 --> 00:13:01,549
once you get to
your destination.

313
00:13:01,549 --> 00:13:02,590
So that's pretty awesome.

314
00:13:02,590 --> 00:13:06,130
And this will also apply to
other things like prerenders

315
00:13:06,130 --> 00:13:08,750
and other types of improvements.

316
00:13:08,750 --> 00:13:10,060
So this is pretty cool.

317
00:13:10,060 --> 00:13:12,120
And this is how,
basically, it looks.

318
00:13:12,120 --> 00:13:16,360
Chrome allows you to actually
dynamically create these hints.

319
00:13:16,360 --> 00:13:19,280
So, for example, if, let's
say, the user initiates

320
00:13:19,280 --> 00:13:21,790
some sort of an action, like
they click on the Checkout

321
00:13:21,790 --> 00:13:23,552
button or they click
on Add To Cart button

322
00:13:23,552 --> 00:13:26,010
and you know that they're going
to go to the checkout page,

323
00:13:26,010 --> 00:13:29,492
at that moment you can actually
inject one of these link

324
00:13:29,492 --> 00:13:30,950
elements and say,
hey, I would like

325
00:13:30,950 --> 00:13:34,220
you to prefetch that asset
for me, because now I

326
00:13:34,220 --> 00:13:35,380
know I will need it.

327
00:13:35,380 --> 00:13:38,220
And vice versa, you can
actually delete this element out

328
00:13:38,220 --> 00:13:41,570
of the DOM, and we will
cancel the prefetch as well.

329
00:13:41,570 --> 00:13:44,110
So you can dynamically
script how and basically

330
00:13:44,110 --> 00:13:46,730
drive Chrome to do these
prefetches for you.

331
00:13:46,730 --> 00:13:48,380
So this is pretty cool stuff.

332
00:13:48,380 --> 00:13:50,890
And I think this
is a place where

333
00:13:50,890 --> 00:13:54,730
we can do a lot more
in the future as well.

334
00:13:54,730 --> 00:13:57,290
So that's a little bit about
kind of the low-level guts

335
00:13:57,290 --> 00:13:59,450
and improvements in Chrome.

336
00:13:59,450 --> 00:14:01,930
Now let's take a look
at some of the protocols

337
00:14:01,930 --> 00:14:03,650
that we've been working on.

338
00:14:03,650 --> 00:14:08,110
So back in 2009, roughly,
actually four years ago

339
00:14:08,110 --> 00:14:10,480
almost on the dot,
we announced our work

340
00:14:10,480 --> 00:14:13,240
on SPDY or initial
efforts around SPDY.

341
00:14:13,240 --> 00:14:15,510
And since then we've gone,
I think, quite a long way.

342
00:14:15,510 --> 00:14:18,900
We've had several iterations
of the protocol itself, so v2,

343
00:14:18,900 --> 00:14:20,000
v3, 3.1.

344
00:14:20,000 --> 00:14:21,810
Now we're working on Version 4.

345
00:14:21,810 --> 00:14:23,900
And that actually
became the foundation

346
00:14:23,900 --> 00:14:26,080
of HTTP 2.0, which
is pretty exciting.

347
00:14:26,080 --> 00:14:29,950
And HTTP 2.0 work in itself
is progressing quite rapidly,

348
00:14:29,950 --> 00:14:31,760
and I'm really
excited about that.

349
00:14:31,760 --> 00:14:36,240
So today we actually have
both SPDY and HTTP 2.0 support

350
00:14:36,240 --> 00:14:39,110
in Chrome, although HTTP
2.0 is under a flag.

351
00:14:39,110 --> 00:14:40,040
But it is there.

352
00:14:40,040 --> 00:14:41,810
It's something that
we're iterating on.

353
00:14:41,810 --> 00:14:44,265
And then once HTTP 2.0-- I
know this is a common question.

354
00:14:44,265 --> 00:14:47,960
Once HTTP 2.0 is marked
as ready, as a standard,

355
00:14:47,960 --> 00:14:49,760
we'll just switch
over to HTTP 2.0.

356
00:14:49,760 --> 00:14:52,940
So think of SPDY as kind of like
an experimental ground for us

357
00:14:52,940 --> 00:14:55,670
to try different ideas
and feed them back

358
00:14:55,670 --> 00:14:57,260
into the HTTP 2.0 spec, right?

359
00:14:57,260 --> 00:14:59,230
So like it'd be great
if we had this feature.

360
00:14:59,230 --> 00:15:01,250
Let's go and try and
implement that feature.

361
00:15:01,250 --> 00:15:04,270
We try it, and we
discover the rough edges,

362
00:15:04,270 --> 00:15:07,760
and then we kind of feed
that back into HTTP 2.0.

363
00:15:07,760 --> 00:15:09,790
So earlier in the
year, we actually

364
00:15:09,790 --> 00:15:14,040
deployed SPDY 3.1 across
all of our Google servers

365
00:15:14,040 --> 00:15:16,240
and, of course, added
support in Chrome.

366
00:15:16,240 --> 00:15:18,800
Firefox also supports SPDY v3.1.

367
00:15:18,800 --> 00:15:21,340
And here's some numbers.

368
00:15:21,340 --> 00:15:23,490
We've never released
this before,

369
00:15:23,490 --> 00:15:25,450
but these are the
performance numbers

370
00:15:25,450 --> 00:15:29,460
that we see for SPDY across some
of the major Google properties,

371
00:15:29,460 --> 00:15:32,954
and these are consistent across
all the different Google sites.

372
00:15:32,954 --> 00:15:35,370
So you're kind of looking at
the right order of magnitude,

373
00:15:35,370 --> 00:15:40,460
anywhere between 20 to 40 to
50% improvement in latency as

374
00:15:40,460 --> 00:15:42,720
compared to HTTPS.

375
00:15:42,720 --> 00:15:45,510
And in some cases,
we're actually-- so even

376
00:15:45,510 --> 00:15:49,690
despite the fact that we have
these extra handshake round

377
00:15:49,690 --> 00:15:52,340
trips and all the rest
in CLS, oftentimes

378
00:15:52,340 --> 00:15:55,240
we actually end up going
faster than just vanilla HTTP

379
00:15:55,240 --> 00:15:58,640
as well, which is,
of course, the point

380
00:15:58,640 --> 00:16:00,816
of this whole exercise
to begin with.

381
00:16:00,816 --> 00:16:01,940
So this is really exciting.

382
00:16:01,940 --> 00:16:05,774
And I guess the important bit
here is also that not only is

383
00:16:05,774 --> 00:16:08,440
it helping the median, which is,
of course, what we like to see,

384
00:16:08,440 --> 00:16:10,950
but it's also consistently
helping all of our users,

385
00:16:10,950 --> 00:16:14,085
the ones on fast connections,
and especially so for the ones

386
00:16:14,085 --> 00:16:15,960
that are ion the slow
connections or the ones

387
00:16:15,960 --> 00:16:18,550
with the high RTT times,
which is especially

388
00:16:18,550 --> 00:16:21,740
relevant for things like mobile,
where RTTs are definitely

389
00:16:21,740 --> 00:16:22,540
higher.

390
00:16:22,540 --> 00:16:23,940
So this is really exciting.

391
00:16:23,940 --> 00:16:26,030
This is very promising.

392
00:16:26,030 --> 00:16:28,700
And I hope that this will help
kind of drive the HTTP 2.0

393
00:16:28,700 --> 00:16:30,860
adoption as well.

394
00:16:30,860 --> 00:16:32,400
So if you haven't
looked at SPDY,

395
00:16:32,400 --> 00:16:34,370
I definitely encourage
you to do so.

396
00:16:34,370 --> 00:16:36,932
There are modules for
virtually every popular server

397
00:16:36,932 --> 00:16:38,765
out there today that
you can enable and just

398
00:16:38,765 --> 00:16:41,600
play with, enable
it on your site.

399
00:16:41,600 --> 00:16:44,300
And there's also
commercial support for it

400
00:16:44,300 --> 00:16:48,120
as well, so F5, Akamai,
and others support SPDY.

401
00:16:48,120 --> 00:16:49,990
So that's pretty cool.

402
00:16:49,990 --> 00:16:53,330
And as I mentioned, we
also do have HTTP 2.0.

403
00:16:53,330 --> 00:16:56,070
If you're curious, if
you want to play with it,

404
00:16:56,070 --> 00:16:58,610
we do have HTTP 2.0
support under a flag.

405
00:16:58,610 --> 00:17:00,970
So you can actually
enable that and then

406
00:17:00,970 --> 00:17:02,860
run it against
your local server.

407
00:17:02,860 --> 00:17:05,500
I think the only big
public site that supports

408
00:17:05,500 --> 00:17:08,033
HTTP 2.0 today is twitter.com.

409
00:17:08,033 --> 00:17:10,329
So in theory, you
can test it on that.

410
00:17:10,329 --> 00:17:14,099
But there are also
open source servers

411
00:17:14,099 --> 00:17:16,859
that speak HTTP 2.0 today
that you can play with.

412
00:17:16,859 --> 00:17:20,290
So SPDY is kind of a production
version, if you will.

413
00:17:20,290 --> 00:17:22,760
HTTP 2.0 is coming soon
and hopefully, fingers

414
00:17:22,760 --> 00:17:26,950
crossed, sometime in 2014.

415
00:17:26,950 --> 00:17:30,120
So that's SPDY.

416
00:17:30,120 --> 00:17:33,192
You may have caught the
wind of some other protocol

417
00:17:33,192 --> 00:17:35,400
that we started working on
earlier in the year, which

418
00:17:35,400 --> 00:17:38,290
is QUIC, which is Quick
UDP Internet Connections.

419
00:17:38,290 --> 00:17:40,840
And the idea here is
actually to kind of take

420
00:17:40,840 --> 00:17:44,000
what we've done with SPDY
and go one step beyond.

421
00:17:44,000 --> 00:17:47,340
And this was actually our intent
right at the very beginning

422
00:17:47,340 --> 00:17:49,610
when we started
thinking of SPDY.

423
00:17:49,610 --> 00:17:51,030
But it was just
too much of a leap

424
00:17:51,030 --> 00:17:54,850
to change both the protocol,
kind of the application

425
00:17:54,850 --> 00:17:56,770
protocol, and the
transfer protocols.

426
00:17:56,770 --> 00:17:59,310
So we kind of decoupled those,
and QUIC is basically that.

427
00:17:59,310 --> 00:18:03,650
We're trying to go one
step further and say, well,

428
00:18:03,650 --> 00:18:05,590
could we build a
better transport

429
00:18:05,590 --> 00:18:07,890
for HTTP traffic,
period, on top of UDP?

430
00:18:07,890 --> 00:18:11,300
Could we experiment
with new ideas?

431
00:18:11,300 --> 00:18:14,460
The core premise of this stuff
is it's all about latency.

432
00:18:14,460 --> 00:18:16,790
We're trying to eliminate
latency everywhere we can.

433
00:18:16,790 --> 00:18:19,590
So can we eliminate
extra round trips

434
00:18:19,590 --> 00:18:22,560
to establish the secure tunnel?

435
00:18:22,560 --> 00:18:24,310
Can we do better
congestion control?

436
00:18:24,310 --> 00:18:25,820
What if we do packet pacing?

437
00:18:25,820 --> 00:18:27,840
What if we do forward
error correction?

438
00:18:27,840 --> 00:18:29,910
What can we do to
innovate in the space

439
00:18:29,910 --> 00:18:33,590
to help reduce the page
load times on the web?

440
00:18:33,590 --> 00:18:35,809
And there's a lot of
interesting ideas.

441
00:18:35,809 --> 00:18:37,850
If you guys are curious
about this kind of stuff,

442
00:18:37,850 --> 00:18:39,190
we posted our design docs.

443
00:18:39,190 --> 00:18:41,980
And it's a very long doc.

444
00:18:41,980 --> 00:18:44,360
I encourage you to read
it and give us feedback.

445
00:18:44,360 --> 00:18:47,160
We have a Google group for that.

446
00:18:47,160 --> 00:18:49,370
And this question comes
up quite frequently,

447
00:18:49,370 --> 00:18:51,690
which is, like,
what's the point?

448
00:18:51,690 --> 00:18:53,670
What are you trying to do here?

449
00:18:53,670 --> 00:18:55,360
And the answer is very simple.

450
00:18:55,360 --> 00:18:59,246
We just want to make faster
internet for everybody to use.

451
00:18:59,246 --> 00:19:01,120
And there are two ways
that this will happen.

452
00:19:01,120 --> 00:19:03,520
One is we end up building
a really awesome protocol

453
00:19:03,520 --> 00:19:05,500
that everybody loves
and we take it to ITF.

454
00:19:05,500 --> 00:19:08,110
And just like with
HTTP 2.0 and SPDY,

455
00:19:08,110 --> 00:19:11,770
we work with the community and
kind of make that the standard.

456
00:19:11,770 --> 00:19:14,930
That's plausible and
maybe that will happen.

457
00:19:14,930 --> 00:19:17,830
The alternative route is, we
just experiment with QUIC.

458
00:19:17,830 --> 00:19:19,450
We experiment with
different ideas.

459
00:19:19,450 --> 00:19:22,240
And those ideas get adopted,
the good ones get adopted

460
00:19:22,240 --> 00:19:24,936
into existing protocol
stacks, like TCP and TLS.

461
00:19:24,936 --> 00:19:26,310
And actually we're
already seeing

462
00:19:26,310 --> 00:19:30,020
some of that, where based on our
experience with the encryption

463
00:19:30,020 --> 00:19:33,270
stuff in QUIC, the TLS
working group is looking

464
00:19:33,270 --> 00:19:34,960
at improvements
in terms of can we

465
00:19:34,960 --> 00:19:36,660
eliminate some
extra round trips.

466
00:19:36,660 --> 00:19:39,980
So in either case, the point
is, no matter which one of these

467
00:19:39,980 --> 00:19:41,790
happens, the users will win.

468
00:19:41,790 --> 00:19:42,910
We'll get faster internet.

469
00:19:42,910 --> 00:19:44,770
And that's our intent with QUIC.

470
00:19:44,770 --> 00:19:47,380
So that's pretty awesome.

471
00:19:47,380 --> 00:19:51,045
We don't have any benchmarks
for it as of today.

472
00:19:51,045 --> 00:19:53,670
We're still at a point where we
want to make sure that it works

473
00:19:53,670 --> 00:19:55,460
and it works correctly
before we start

474
00:19:55,460 --> 00:19:58,470
optimizing kind of all
the edges around it.

475
00:19:58,470 --> 00:20:01,050
But you can actually
play with QUIC today.

476
00:20:01,050 --> 00:20:03,156
We have it deployed
on Google servers,

477
00:20:03,156 --> 00:20:04,280
and you can also enable it.

478
00:20:04,280 --> 00:20:08,090
If you go into Chrome flags,
you can flip QUIC Support.

479
00:20:08,090 --> 00:20:10,290
And then you can, for
example, access YouTube,

480
00:20:10,290 --> 00:20:14,250
and you'll get served--
youtube.com or other Google

481
00:20:14,250 --> 00:20:16,950
service-- over UDP, over QUIC.

482
00:20:16,950 --> 00:20:19,880
And if you're curious, you can
dive into Chrome net internals

483
00:20:19,880 --> 00:20:21,880
and kind of look at
the actual protocol

484
00:20:21,880 --> 00:20:23,000
and all this other stuff.

485
00:20:23,000 --> 00:20:27,160
So if you're into kind of
low-level networking protocols,

486
00:20:27,160 --> 00:20:29,620
definitely a thing you want
to check out and play with.

487
00:20:29,620 --> 00:20:32,200
There's lots of interesting
ideas in the protocol.

488
00:20:32,200 --> 00:20:34,717

489
00:20:34,717 --> 00:20:35,800
All right, shifting gears.

490
00:20:35,800 --> 00:20:37,730
Linus mentioned Chrome
data compression.

491
00:20:37,730 --> 00:20:40,250
This is something that we
launched early in the year.

492
00:20:40,250 --> 00:20:42,542
As you heard, it provides
roughly 50% data savings.

493
00:20:42,542 --> 00:20:44,750
That's kind of the average
number for a lot of users.

494
00:20:44,750 --> 00:20:48,030
It turns out there's a lot
of poorly compressed content

495
00:20:48,030 --> 00:20:49,300
on the web.

496
00:20:49,300 --> 00:20:52,240
People still forget to
gzip their content, which

497
00:20:52,240 --> 00:20:56,320
is one of the optimizations
that we apply for text, like

498
00:20:56,320 --> 00:20:56,970
[INAUDIBLE].

499
00:20:56,970 --> 00:20:58,870
And we also convert
all the images

500
00:20:58,870 --> 00:21:01,260
to IP, which provides
a significant savings.

501
00:21:01,260 --> 00:21:03,730
So this is a big benefit
to a lot of users.

502
00:21:03,730 --> 00:21:05,410
But one thing that
Linus didn't mention

503
00:21:05,410 --> 00:21:08,930
is that there are other
secondary benefits to that.

504
00:21:08,930 --> 00:21:11,770
Because we run over SPDY,
so between your phone

505
00:21:11,770 --> 00:21:14,220
and the Google server, it's
actually a SPDY connection.

506
00:21:14,220 --> 00:21:15,650
It's an encrypted connection.

507
00:21:15,650 --> 00:21:19,690
So I actually use Chrome
data compression in part

508
00:21:19,690 --> 00:21:22,120
for the data compression
part, but also

509
00:21:22,120 --> 00:21:24,970
partially to secure my browsing.

510
00:21:24,970 --> 00:21:28,674
Because when I enable this,
the secure traffic, if you're

511
00:21:28,674 --> 00:21:30,840
connecting to your bank,
for example, an HTTPS site,

512
00:21:30,840 --> 00:21:32,173
it will go directly to the site.

513
00:21:32,173 --> 00:21:33,510
So that traffic is encrypted.

514
00:21:33,510 --> 00:21:36,550
But if you're trying to connect
to some unencrypted site,

515
00:21:36,550 --> 00:21:40,010
it'll just flow basically
as it is on the wire.

516
00:21:40,010 --> 00:21:41,940
With Chrome data
compression, that

517
00:21:41,940 --> 00:21:45,770
goes through a secure tunnel,
so even if you're on a Starbucks

518
00:21:45,770 --> 00:21:49,110
Wi-Fi or whatever,
some unencrypted Wi-Fi

519
00:21:49,110 --> 00:21:53,160
and you're browsing around,
all of your data is encrypted.

520
00:21:53,160 --> 00:21:55,660
So that's really nice.

521
00:21:55,660 --> 00:21:59,100
And maybe one important thing
to highlight with Chrome data

522
00:21:59,100 --> 00:22:04,050
compression is, it is still
the full fidelity HTML5 web

523
00:22:04,050 --> 00:22:04,860
experience, right?

524
00:22:04,860 --> 00:22:07,550
We're not doing anything
to modify your site.

525
00:22:07,550 --> 00:22:09,670
We're not trying to
render it on the server.

526
00:22:09,670 --> 00:22:12,910
Like you have all of the
flexibility of JavaScript, CSS,

527
00:22:12,910 --> 00:22:15,590
and all the rest on your phone.

528
00:22:15,590 --> 00:22:17,340
That's where the
code gets executed.

529
00:22:17,340 --> 00:22:20,150
So we're just modifying and
optimizing some of the assets

530
00:22:20,150 --> 00:22:21,940
as they get delivered.

531
00:22:21,940 --> 00:22:25,140
Some common questions that I get
about Chrome data compression,

532
00:22:25,140 --> 00:22:27,790
something you should know, is
this is going through a proxy.

533
00:22:27,790 --> 00:22:29,800
So if you're developing
a site where you're

534
00:22:29,800 --> 00:22:33,420
relying on GoIP
functionality to customize

535
00:22:33,420 --> 00:22:36,422
the location to the user or
maybe serve relevant ads,

536
00:22:36,422 --> 00:22:38,130
you should be looking
for the X Forwarded

537
00:22:38,130 --> 00:22:40,110
For header, which
is the IP address

538
00:22:40,110 --> 00:22:44,670
of the client as forwarded
by the Chrome data proxy.

539
00:22:44,670 --> 00:22:47,800
And similarly, if
for whatever reason

540
00:22:47,800 --> 00:22:51,020
you absolutely want to make
sure that we don't do anything

541
00:22:51,020 --> 00:22:52,480
to your content,
you can actually

542
00:22:52,480 --> 00:22:54,780
opt out on a per-resource basis.

543
00:22:54,780 --> 00:22:57,160
If you add a no
transform header,

544
00:22:57,160 --> 00:23:00,000
it basically tells the
Chrome data proxy to just

545
00:23:00,000 --> 00:23:01,880
be hands off with that resource.

546
00:23:01,880 --> 00:23:04,100
So we won't
reoptimize that image,

547
00:23:04,100 --> 00:23:06,860
or we won't recompress
that text, or other things.

548
00:23:06,860 --> 00:23:12,100
So these are standard
kind of proxy directives.

549
00:23:12,100 --> 00:23:15,660
Chrome data compression
proxies supports it.

550
00:23:15,660 --> 00:23:18,840
So, just an FYI.

551
00:23:18,840 --> 00:23:20,890
Shifting gears, web sockets.

552
00:23:20,890 --> 00:23:22,520
This is really, really exciting.

553
00:23:22,520 --> 00:23:25,300
Do we have any web socket
developers in the room?

554
00:23:25,300 --> 00:23:26,280
Yes.

555
00:23:26,280 --> 00:23:27,260
Awesome.

556
00:23:27,260 --> 00:23:30,090
So web socket
compression is going

557
00:23:30,090 --> 00:23:34,200
to be live in M32, which
is a long overdue feature.

558
00:23:34,200 --> 00:23:35,960
One of the gotchas
with web sockets

559
00:23:35,960 --> 00:23:38,310
was that you could
transfer binary in text,

560
00:23:38,310 --> 00:23:42,260
but text would always
go as uncompressed

561
00:23:42,260 --> 00:23:44,040
in both directions.

562
00:23:44,040 --> 00:23:45,820
Now that we have
the spec up to date

563
00:23:45,820 --> 00:23:48,970
and we already have
the code in Chrome,

564
00:23:48,970 --> 00:23:53,100
you can actually negotiate
the deflate compression

565
00:23:53,100 --> 00:23:55,920
to apply in both directions,
and the server can selectively

566
00:23:55,920 --> 00:23:57,900
compress any given frame.

567
00:23:57,900 --> 00:23:59,790
And the client, as
of today, Chrome

568
00:23:59,790 --> 00:24:05,020
will compress every
single frame going out

569
00:24:05,020 --> 00:24:08,260
from your mobile device or
from your desktop device.

570
00:24:08,260 --> 00:24:10,350
And I'm not going to
go into details here,

571
00:24:10,350 --> 00:24:12,620
but we also, actually,
the spec provides

572
00:24:12,620 --> 00:24:14,680
a number of different
parameters to customize

573
00:24:14,680 --> 00:24:16,100
how the compression
will be done.

574
00:24:16,100 --> 00:24:18,805
For example, the size of the
sliding window, so essentially

575
00:24:18,805 --> 00:24:22,000
you can control the
resources used on your server

576
00:24:22,000 --> 00:24:24,422
and on your client,
plus some other flags.

577
00:24:24,422 --> 00:24:25,880
So this is really,
really exciting,

578
00:24:25,880 --> 00:24:30,740
because this has definitely been
a sore point for web sockets.

579
00:24:30,740 --> 00:24:33,936
We heard about WebRTC
and DataChannel.

580
00:24:33,936 --> 00:24:35,310
The way I think
about DataChannel

581
00:24:35,310 --> 00:24:38,690
is basically WebSocket,
but over UDP and P2P.

582
00:24:38,690 --> 00:24:41,570
So we can communicate
directly between devices.

583
00:24:41,570 --> 00:24:45,250
We don't have to go through
an intermediary like a server.

584
00:24:45,250 --> 00:24:49,420
And DataChannel and M31
has now officially switched

585
00:24:49,420 --> 00:24:51,150
to SCTP protocol.

586
00:24:51,150 --> 00:24:54,870
So previously we were
using RTP data channels,

587
00:24:54,870 --> 00:24:58,260
and that was the reason for
some of the incompatibilities

588
00:24:58,260 --> 00:24:59,830
with some of the other vendors.

589
00:24:59,830 --> 00:25:02,690
But as of M31, SCTP
is the default,

590
00:25:02,690 --> 00:25:07,150
and we will aggressively remove
support for RTP data channels.

591
00:25:07,150 --> 00:25:10,410
So if you're using
data channels today,

592
00:25:10,410 --> 00:25:12,210
this is something
you want to revisit.

593
00:25:12,210 --> 00:25:14,330
And if you're not familiar
with data channels,

594
00:25:14,330 --> 00:25:16,870
I encourage you to
check out the links.

595
00:25:16,870 --> 00:25:19,280
I'll post the slides
later for how this works

596
00:25:19,280 --> 00:25:20,290
and why this is awesome.

597
00:25:20,290 --> 00:25:23,640
Because it allows you
to define things like,

598
00:25:23,640 --> 00:25:26,180
fire-and-forget semantics,
don't retransmit.

599
00:25:26,180 --> 00:25:30,655
So it's a really nice transport
for doing low-latency data

600
00:25:30,655 --> 00:25:31,155
exchange.

601
00:25:31,155 --> 00:25:33,900

602
00:25:33,900 --> 00:25:36,310
And then finally, let's talk
about measurements, right?

603
00:25:36,310 --> 00:25:38,860
So there's a lot of kind
of protocol improvements

604
00:25:38,860 --> 00:25:40,190
that are going on.

605
00:25:40,190 --> 00:25:42,730
But as we know, we need to
be able to measure things

606
00:25:42,730 --> 00:25:44,210
in order to improve them.

607
00:25:44,210 --> 00:25:46,630
So, of course, we're all
familiar with navigation

608
00:25:46,630 --> 00:25:47,810
timing, or I hope we are.

609
00:25:47,810 --> 00:25:50,220
Most of the people
here I expect would be.

610
00:25:50,220 --> 00:25:53,350
You can get detailed
low-level stats

611
00:25:53,350 --> 00:25:55,500
about how long did
each connection take

612
00:25:55,500 --> 00:25:58,440
in terms of DNS times, TCP
time, and all the other things.

613
00:25:58,440 --> 00:26:01,080
You can throw that into your
analytics solution here.

614
00:26:01,080 --> 00:26:02,870
I'm showing you Google
Analytics, which

615
00:26:02,870 --> 00:26:05,160
allows you to segment
this data to say, well,

616
00:26:05,160 --> 00:26:07,650
I want to look at my mobile
users versus desktop.

617
00:26:07,650 --> 00:26:10,750
You can segment it
by any other variable

618
00:26:10,750 --> 00:26:14,000
you define, like has a user
clicked the Checkout button,

619
00:26:14,000 --> 00:26:15,900
or have they
registered, et cetera.

620
00:26:15,900 --> 00:26:17,080
This is all great.

621
00:26:17,080 --> 00:26:20,000
One gotcha with this is this is
only for the main page, right?

622
00:26:20,000 --> 00:26:23,076
What about the other 85
resources or 100 resources

623
00:26:23,076 --> 00:26:24,200
that you have on your page?

624
00:26:24,200 --> 00:26:25,730
How are those performing?

625
00:26:25,730 --> 00:26:29,530
Well in Chrome, we have support
for resource timing, which

626
00:26:29,530 --> 00:26:32,660
gives you that same level of
access to all of the network

627
00:26:32,660 --> 00:26:35,240
metadata, or
timestamps, I should

628
00:26:35,240 --> 00:26:37,570
say, on a per-resource basis.

629
00:26:37,570 --> 00:26:40,920
So you can see here
that you can actually

630
00:26:40,920 --> 00:26:43,159
query for a specific
resource, like your JavaScript

631
00:26:43,159 --> 00:26:44,200
file that you're loading.

632
00:26:44,200 --> 00:26:45,991
Maybe you're loading
it from CDN and you're

633
00:26:45,991 --> 00:26:48,350
wondering how well
is my CDN performing.

634
00:26:48,350 --> 00:26:50,070
You can get your
real user measurement

635
00:26:50,070 --> 00:26:52,910
data for that specific
resource and then look up

636
00:26:52,910 --> 00:26:56,350
the time for DNS, TCP connect
time, total transfer time,

637
00:26:56,350 --> 00:26:57,300
et cetera.

638
00:26:57,300 --> 00:26:59,160
The only thing that
you need to be aware of

639
00:26:59,160 --> 00:27:02,930
is that the resource has to
manually opt in and allow

640
00:27:02,930 --> 00:27:04,516
the data to be
gathered to begin with.

641
00:27:04,516 --> 00:27:06,390
This is done for privacy
reasons to make sure

642
00:27:06,390 --> 00:27:11,010
that somebody can't just iterate
or recache and figure out

643
00:27:11,010 --> 00:27:14,120
where you've been in the
past, or something like it.

644
00:27:14,120 --> 00:27:17,300
So for your own resources
you need to add this header.

645
00:27:17,300 --> 00:27:19,810
And then if you're using
third party resources,

646
00:27:19,810 --> 00:27:23,000
if that origin is already
not providing this header,

647
00:27:23,000 --> 00:27:25,370
then you should
ask them to do so.

648
00:27:25,370 --> 00:27:31,580
Because here's one example where
I have a web font on my site.

649
00:27:31,580 --> 00:27:34,060
Web fonts delay when
the tech gets painted.

650
00:27:34,060 --> 00:27:37,865
So the question is,
how is-- in this case,

651
00:27:37,865 --> 00:27:38,740
this is a Google CDN.

652
00:27:38,740 --> 00:27:40,550
How is Google CDN
performing in terms

653
00:27:40,550 --> 00:27:41,990
of serving the actual font?

654
00:27:41,990 --> 00:27:43,430
Is it hurting my users?

655
00:27:43,430 --> 00:27:46,160
Well, now I can actually grab
that data from Resource Timing,

656
00:27:46,160 --> 00:27:49,200
just as I showed you
a few slides ago.

657
00:27:49,200 --> 00:27:51,330
And we can just pump that
into Google Analytics.

658
00:27:51,330 --> 00:27:53,495
Here you can see that I'm
tracking the DNS, TCP,

659
00:27:53,495 --> 00:27:54,820
and transfer times.

660
00:27:54,820 --> 00:27:57,380
And it turns out
that the fonts coming

661
00:27:57,380 --> 00:28:01,290
from Google CDN, at
least for my site,

662
00:28:01,290 --> 00:28:04,730
are being loaded in this case
within 150 milliseconds, which

663
00:28:04,730 --> 00:28:07,130
to me was an acceptable time.

664
00:28:07,130 --> 00:28:08,490
And that was fine for me.

665
00:28:08,490 --> 00:28:11,850
But you can now think about
using this sort of data

666
00:28:11,850 --> 00:28:13,730
to define third party SLAs.

667
00:28:13,730 --> 00:28:16,270
You rely on third party
widgets you can say, well,

668
00:28:16,270 --> 00:28:19,879
your widgets must load in x
amount of time, et cetera.

669
00:28:19,879 --> 00:28:21,920
You can actually track
this with Resource Timing,

670
00:28:21,920 --> 00:28:23,920
which is pretty awesome.

671
00:28:23,920 --> 00:28:27,200
So as a quick recap, we
covered a lot of ground.

672
00:28:27,200 --> 00:28:29,060
There's a new DNS
Resolver in Chrome,

673
00:28:29,060 --> 00:28:31,720
which is double-digit
performance improvement

674
00:28:31,720 --> 00:28:32,920
and actual DNS resolutions.

675
00:28:32,920 --> 00:28:34,579
And the new scheduler
is definitely

676
00:28:34,579 --> 00:28:36,120
something we're
really excited about.

677
00:28:36,120 --> 00:28:40,570
We've already seen huge
improvements there,

678
00:28:40,570 --> 00:28:42,680
10% and 20% improvement
in the actual speed

679
00:28:42,680 --> 00:28:44,340
index and page load times.

680
00:28:44,340 --> 00:28:47,250
The Simple Cache stuff
is a huge win on mobile,

681
00:28:47,250 --> 00:28:49,350
and I'm really excited
to have that out there.

682
00:28:49,350 --> 00:28:51,490
And then moving
forward, I'm hoping

683
00:28:51,490 --> 00:28:54,530
that we can make the preresolve
and prefetch and the prerender

684
00:28:54,530 --> 00:28:56,610
stuff much, much smarter.

685
00:28:56,610 --> 00:28:58,990
And you saw the
SPDY wins, right?

686
00:28:58,990 --> 00:29:01,890
So all of these things
are incremental, 10% here,

687
00:29:01,890 --> 00:29:02,620
20% there.

688
00:29:02,620 --> 00:29:04,078
Before you know
it, you're actually

689
00:29:04,078 --> 00:29:07,150
saving hundreds of milliseconds,
and sometimes seconds,

690
00:29:07,150 --> 00:29:09,310
for the user, which
is a huge win.

691
00:29:09,310 --> 00:29:11,850
And some of these things you
guys need to optimize for.

692
00:29:11,850 --> 00:29:14,215
These are the things where
you need to install SPDY,

693
00:29:14,215 --> 00:29:15,715
you need to configure
SPDY, you need

694
00:29:15,715 --> 00:29:18,920
to make sure that your stacks
are configured correctly.

695
00:29:18,920 --> 00:29:20,940
And in other cases,
it's just also doing

696
00:29:20,940 --> 00:29:23,120
a better job of scheduling
this kind of stuff.

697
00:29:23,120 --> 00:29:25,024
And then finally, if
you haven't already,

698
00:29:25,024 --> 00:29:26,440
I definitely
encourage you to look

699
00:29:26,440 --> 00:29:29,620
at things like Nav Timing, User
Timing, and Resource Timing.

700
00:29:29,620 --> 00:29:31,680
So I talked about
Resource Timing.

701
00:29:31,680 --> 00:29:35,230
User Timing allows you to
measure any chunk of code

702
00:29:35,230 --> 00:29:40,290
and just get high-resolution
time stamps for this

703
00:29:40,290 --> 00:29:43,030
is when I started, this is when
I ended, and beacon that back

704
00:29:43,030 --> 00:29:43,772
to your server.

705
00:29:43,772 --> 00:29:45,730
So all of these things
are supported in Chrome.

706
00:29:45,730 --> 00:29:50,620
And what you can measure,
you can optimize.

707
00:29:50,620 --> 00:29:56,170
So with that, I'll leave
you the link to the slides.

708
00:29:56,170 --> 00:29:57,780
Thank you.

709
00:29:57,780 --> 00:29:58,338

