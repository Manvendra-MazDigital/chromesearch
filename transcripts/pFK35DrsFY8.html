<style>* {font-family: "Open Sans", sans-serif}
a {color: #77aaff}
a.video {border-bottom: 1px solid #ddd; display: block; margin: 0 0 2em 0; padding: 0 0 2em 0}
h2 {color: #444; font-size: 18px;}
span.speakerName {color: black; font-weight: 900;}
body {padding: 2em}
p {color: #444; margin: 0; text-indent: 1.5em;}
p.speaker {margin: 1em 0 0 0; text-indent: 0;}
div#transcript > p:first-child {text-indent: 0;}
</style>

<h1>Google I/O 2013 &mdash; Demystifying Video Encoding: WebM/VP8 for the Rest of Us</h1>

<h2>John Luther, Frank Galligan</h2>

<a class="video" href="http://youtu.be/pFK35DrsFY8">youtu.be/pFK35DrsFY8</a><div id="transcript"><p class="speaker"><span class="line" data-starttime="1"><span class="speakerName">John Luther</span>: Good morning. </span><span class="line" data-startTime="3">How's everybody? </span><span class="line" data-startTime="6">OK, Glass present slide. </span><span class="line" data-startTime="7">Now wait a minute. </span><span class="line" data-startTime="11">It's fun to pretend, right? </span></p>

<p class="speaker"><span class="line" data-starttime="13"><span class="speakerName">Frank Galligan</span>: We're not cool </span><span class="line" data-startTime="13">enough to have Glass. </span></p>

<p class="speaker"><span class="line" data-starttime="14"><span class="speakerName">John Luther</span>: You'd think </span><span class="line" data-startTime="14">we would be. </span><span class="line" data-startTime="17">Good morning. </span><span class="line" data-startTime="17">Welcome to our session on WebM, </span><span class="line" data-startTime="20">demystifying video coding. </span><span class="line" data-startTime="22">My name's John Luther. </span><span class="line" data-startTime="23">I'm the Product Manager at </span><span class="line" data-startTime="23">Google for WebM and for video </span><span class="line" data-startTime="26">technology in the </span><span class="line" data-startTime="26">Chrome browser. </span><span class="line" data-startTime="28">And this is my colleague and </span><span class="line" data-startTime="28">co-presenter Frank Galligan, </span><span class="line" data-startTime="32">Staff Software Engineer at </span><span class="line" data-startTime="32">Google also working on WebM </span><span class="line" data-startTime="36">and Chrome. </span><span class="line" data-startTime="37">And they tell you to </span><span class="line" data-startTime="37">open with a joke. </span><span class="line" data-startTime="39">And my joke is my picture. </span><span class="line" data-startTime="44">This looks so sad </span><span class="line" data-startTime="44">about something. </span></p>

<p class="speaker"><span class="line" data-starttime="46"><span class="speakerName">Frank Galligan</span>: You </span><span class="line" data-startTime="46">look orange. </span></p>

<p class="speaker"><span class="line" data-starttime="47"><span class="speakerName">John Luther</span>: I know. </span> <span class="line" data-startTime="48">All right. </span> <span class="line" data-startTime="48">So what's to demystify? </span><span class="line" data-startTime="50">First, I'm going to just give </span><span class="line" data-startTime="50">sort of an overview of what </span><span class="line" data-startTime="52">WebM is and VP8, but mostly </span><span class="line" data-startTime="52">going to focus on the video </span><span class="line" data-startTime="57">side with WebM today, and then </span><span class="line" data-startTime="57">the reasons why WebM is a </span><span class="line" data-startTime="64">great choice for developers </span><span class="line" data-startTime="64">to do video in their apps. </span> <span class="line" data-startTime="67">I'm going to give some examples </span><span class="line" data-startTime="67">of how to encode WebM </span><span class="line" data-startTime="70">video using ffmpeg, which is a </span><span class="line" data-startTime="70">very popular command line and </span><span class="line" data-startTime="76">coding tool used by pretty much </span><span class="line" data-startTime="76">every video service on </span><span class="line" data-startTime="80">earth these days, including </span><span class="line" data-startTime="80">YouTube. </span> <span class="line" data-startTime="83">So Frank will then do his part </span><span class="line" data-startTime="83">of the presentation on how to </span><span class="line" data-startTime="88">actually build WebM into apps </span><span class="line" data-startTime="88">using our open source </span><span class="line" data-startTime="91">libraries, libvpx, the WebM </span><span class="line" data-startTime="91">container library which is our </span><span class="line" data-startTime="95">wrapper format and libvorbis, </span><span class="line" data-startTime="95">which is our audio encoder. </span></p>

<p><span class="line" data-startTime="100">He'll then &mdash; </span><span class="line" data-startTime="101">if everything goes according </span><span class="line" data-startTime="101">to plan &mdash; </span><span class="line" data-startTime="104">encode a video on an Android </span><span class="line" data-startTime="104">device, upload it to YouTube </span><span class="line" data-startTime="108">where it will instantaneously </span><span class="line" data-startTime="108">appear to the world. </span> <span class="line" data-startTime="112">And then I'll just touch briefly </span><span class="line" data-startTime="112">on what we're up to </span><span class="line" data-startTime="114">next, which is our VP9, </span><span class="line" data-startTime="114">which is our next </span><span class="line" data-startTime="117">generation video codec. </span> <span class="line" data-startTime="119">And we'll have a quick </span><span class="line" data-startTime="119">Q&A. And then we'll </span><span class="line" data-startTime="121">let you go to lunch. </span> <span class="line" data-startTime="122">So how many people know </span><span class="line" data-startTime="122">what WebM is? </span><span class="line" data-startTime="126">That's OK. </span> <span class="line" data-startTime="127">That's good. </span> <span class="line" data-startTime="128">For those of you who don't, WebM </span><span class="line" data-startTime="128">is a high-quality, open, </span><span class="line" data-startTime="131">royalty-free alternative </span><span class="line" data-startTime="131">for web video. </span></p>

<p><span class="line" data-startTime="133">What does that mean? </span><span class="line" data-startTime="134">That means that it's </span><span class="line" data-startTime="134">three things. </span> <span class="line" data-startTime="137">That's this is how we define </span><span class="line" data-startTime="137">WebM for consistency's sake. </span> <span class="line" data-startTime="139">It's the VP8 video codec. </span> <span class="line" data-startTime="142">Soon we're going to add VP9. </span> <span class="line" data-startTime="145">Vorbis audio, which is a </span><span class="line" data-startTime="145">royalty-free, very good audio </span><span class="line" data-startTime="149">codec that's developed by </span><span class="line" data-startTime="149">the Xiph foundation. </span> <span class="line" data-startTime="152">And it's a Matroska-based </span><span class="line" data-startTime="152">file container. </span> <span class="line" data-startTime="154">What that means is the audio </span><span class="line" data-startTime="154">and video streams are </span><span class="line" data-startTime="157">contained in a Matroska file </span><span class="line" data-startTime="157">container, but we use a file </span><span class="line" data-startTime="161">extension WebM to differentiate </span><span class="line" data-startTime="161">it from other </span><span class="line" data-startTime="164">files, because any user agent </span><span class="line" data-startTime="164">or client, we want to make </span><span class="line" data-startTime="169">sure that when they receive </span><span class="line" data-startTime="169">a file of .webm type or </span><span class="line" data-startTime="173">MIME-type WebM that they can </span><span class="line" data-startTime="173">always know that it's going to </span><span class="line" data-startTime="176">be these three things, and </span><span class="line" data-startTime="176">later VP9 and opus. </span></p>

<p><span class="line" data-startTime="182">So benefits for developers. </span> <span class="line" data-startTime="184">Why would a developer </span><span class="line" data-startTime="184">want to use WebM? </span><span class="line" data-startTime="186">Well, more than anything, of </span><span class="line" data-startTime="186">course, is the video quality. </span> <span class="line" data-startTime="189">The VP8 Kodak was developed by a </span><span class="line" data-startTime="189">small company called on OnTo </span><span class="line" data-startTime="192">Technologies, where Frank </span><span class="line" data-startTime="192">and I came from. </span> <span class="line" data-startTime="194">Google acquired OnTo </span><span class="line" data-startTime="194">in 2010 and open </span><span class="line" data-startTime="197">sourced VP8 for the world. </span> <span class="line" data-startTime="201">So if you look at the quality </span><span class="line" data-startTime="201">that VP8 can achieve just sort </span><span class="line" data-startTime="204">of as a base to judge </span><span class="line" data-startTime="204">these things &mdash; </span><span class="line" data-startTime="208">1080p HD video is obviously </span><span class="line" data-startTime="208">very difficult to transmit </span><span class="line" data-startTime="212">over networks, because </span><span class="line" data-startTime="212">it's so many </span><span class="line" data-startTime="214">gigantic frames of pixels. </span></p>

<p><span class="line" data-startTime="216">But with VP8, we can achieve </span><span class="line" data-startTime="216">very good-looking, high PSNR, </span><span class="line" data-startTime="222">which is how these things </span><span class="line" data-startTime="222">are usually measured. </span> <span class="line" data-startTime="226">1080p at about three megabits. </span> <span class="line" data-startTime="228">So most residential, consumer, </span><span class="line" data-startTime="228">internet connections nowadays, </span><span class="line" data-startTime="235">they're getting there, to the </span><span class="line" data-startTime="235">point where people have a sort </span><span class="line" data-startTime="237">of predictable &mdash; </span><span class="line" data-startTime="239">at least, we would hope &mdash; three </span><span class="line" data-startTime="239">megabits connection. </span> <span class="line" data-startTime="242">But you could even do 720 </span><span class="line" data-startTime="242">at lower than this. </span> <span class="line" data-startTime="244">So that's one gauge of </span><span class="line" data-startTime="244">how you can judge it. </span> <span class="line" data-startTime="247">Simplicity of design. </span> <span class="line" data-startTime="249">So VP8 is unlike other codecs </span><span class="line" data-startTime="249">that you might know of in that </span><span class="line" data-startTime="254">we design it to be completely </span><span class="line" data-startTime="254">compliant across any decoder. </span></p>

<p><span class="line" data-startTime="258">So if any valid VP8 stream that </span><span class="line" data-startTime="258">you create will decode </span><span class="line" data-startTime="264">and playback in any compliant </span><span class="line" data-startTime="264">VP8 decoder &mdash; </span><span class="line" data-startTime="269">Why is that different </span><span class="line" data-startTime="269">than other codecs. </span> <span class="line" data-startTime="271">Well, other codecs, let's say, </span><span class="line" data-startTime="271">for example, H.264 &mdash; </span><span class="line" data-startTime="274">they have different profiles </span><span class="line" data-startTime="274">that are defined. </span> <span class="line" data-startTime="277">So H.264 baseline, H.264 main. </span> <span class="line" data-startTime="280">This leads one to believe that </span><span class="line" data-startTime="280">those are inter-compatible but </span><span class="line" data-startTime="284">they're not. </span> <span class="line" data-startTime="285">The main profile decoder cannot </span><span class="line" data-startTime="287">decode a baseline bitstream. </span> <span class="line" data-startTime="289">They're essentially three </span><span class="line" data-startTime="289">different codecs or more. </span> <span class="line" data-startTime="292">There's baseline, </span><span class="line" data-startTime="292">main and high. </span> <span class="line" data-startTime="294">So with VP8, you never have </span><span class="line" data-startTime="294">to worry about that. </span></p>

<p><span class="line" data-startTime="297">So if you have, for example, if </span><span class="line" data-startTime="297">you want to serve video to </span><span class="line" data-startTime="301">Glass users as well as users on </span><span class="line" data-startTime="301">MacBooks, the Glass users, </span><span class="line" data-startTime="306">Glass only supports baseline. </span> <span class="line" data-startTime="308">These support high profile. </span> <span class="line" data-startTime="309">So you'd have to have different </span><span class="line" data-startTime="309">bitstreams for </span><span class="line" data-startTime="311">different clients. </span> <span class="line" data-startTime="312">And you'd always have to be </span><span class="line" data-startTime="312">doing user agent checking. </span> <span class="line" data-startTime="315">What does this one support, </span><span class="line" data-startTime="315">and so on. </span> <span class="line" data-startTime="317">With VP8, you don't have to </span><span class="line" data-startTime="317">worry about that, because </span><span class="line" data-startTime="320">there are no profiles. </span></p>

<p><span class="line" data-startTime="321">There are no levels, which is </span><span class="line" data-startTime="321">another way that codecs were </span><span class="line" data-startTime="325">defined by what's the maximum </span><span class="line" data-startTime="325">frame size of this video, bit </span><span class="line" data-startTime="330">rate, so forth. </span> <span class="line" data-startTime="331">We don't do B-frames, which are </span><span class="line" data-startTime="331">kind of a way to predict </span><span class="line" data-startTime="336">forward or backward </span><span class="line" data-startTime="336">in the video. </span> <span class="line" data-startTime="338">No IDR frames. </span> <span class="line" data-startTime="339">We try to keep it as simple as </span><span class="line" data-startTime="339">possible, yet we do achieve </span><span class="line" data-startTime="342">the same quality as something </span><span class="line" data-startTime="342">like H.264 High Profile. </span> <span class="line" data-startTime="348">On the other side of the </span><span class="line" data-startTime="348">equation, the decoding, we try </span><span class="line" data-startTime="352">to keep it very low complexity, </span><span class="line" data-startTime="352">meaning that it's </span><span class="line" data-startTime="357">very important for us that VVP8 </span><span class="line" data-startTime="357">run fast in software, </span><span class="line" data-startTime="361">even on lower power devices. </span> <span class="line" data-startTime="363">I think a lot of times we in the </span><span class="line" data-startTime="363">Western world forget that </span><span class="line" data-startTime="366">not everybody buys a new </span><span class="line" data-startTime="366">computer every year </span><span class="line" data-startTime="368">or every two years. </span> <span class="line" data-startTime="371">There's still a lot of devices </span><span class="line" data-startTime="371">in the world that have a very </span><span class="line" data-startTime="374">hard time decoding other </span><span class="line" data-startTime="374">codecs and software. </span></p>

<p><span class="line" data-startTime="376">VP8 opens that world up to more </span><span class="line" data-startTime="376">users, because it can </span><span class="line" data-startTime="382">decode on an even lower power, </span><span class="line" data-startTime="382">older generation ARM </span><span class="line" data-startTime="386">processors, which &mdash; there are </span><span class="line" data-startTime="386">still many, many of those in </span><span class="line" data-startTime="389">the world today. </span> <span class="line" data-startTime="392">It's also very widely </span><span class="line" data-startTime="392">supported. </span> <span class="line" data-startTime="394">So WebM, as a format, in the </span><span class="line" data-startTime="394">video tag in desktop web </span><span class="line" data-startTime="397">browsers, this is just some </span><span class="line" data-startTime="397">data I pulled from </span><span class="line" data-startTime="400">StatCounter. </span> <span class="line" data-startTime="401">So native WebM meaning you </span><span class="line" data-startTime="401">install the browser. </span> <span class="line" data-startTime="405">It's WebM capable </span><span class="line" data-startTime="405">out of the box. </span></p>

<p><span class="line" data-startTime="406">Has about 60% of browsers in </span><span class="line" data-startTime="406">use in the world today. </span> <span class="line" data-startTime="410">So that means Chrome, Firefox, </span><span class="line" data-startTime="410">Opera a browser that's built </span><span class="line" data-startTime="417">on top of chromium. </span> <span class="line" data-startTime="420">It's in the chromium source. </span> <span class="line" data-startTime="422">It's in Firefox &mdash; you know </span><span class="line" data-startTime="422">the gecko stuff? </span><span class="line" data-startTime="426">Anyway the light green segment </span><span class="line" data-startTime="426">is browsers that we can </span><span class="line" data-startTime="429">address with plug-ins, which </span><span class="line" data-startTime="429">are freely available and </span><span class="line" data-startTime="433">downloadable from our website. </span> <span class="line" data-startTime="435">This is primarily IE9 and 10 </span><span class="line" data-startTime="435">and Safari 5 and later. </span></p>

<p><span class="line" data-startTime="442">The gray slice is browsers that </span><span class="line" data-startTime="442">not necessarily don't </span><span class="line" data-startTime="447">support WebM, but just simply </span><span class="line" data-startTime="447">don't support HTML5 video </span><span class="line" data-startTime="450">which is IE8, IE7, a lot of the </span><span class="line" data-startTime="450">older browsers that are </span><span class="line" data-startTime="454">still out there in use today, </span><span class="line" data-startTime="454">but don't have the </span><span class="line" data-startTime="456">capabilities. </span> <span class="line" data-startTime="458">So adding it all up, the dark </span><span class="line" data-startTime="458">green wedge is actually </span><span class="line" data-startTime="463">growing pretty fast over time. </span> <span class="line" data-startTime="465">So you can be pretty confident </span><span class="line" data-startTime="465">that in some way your users </span><span class="line" data-startTime="470">will be able to play WebM. </span> <span class="line" data-startTime="473">So also as an &mdash; </span><span class="line" data-startTime="474">I was curious about mobile. </span> <span class="line" data-startTime="477">Tablets are obviously very </span><span class="line" data-startTime="477">becoming very important </span><span class="line" data-startTime="480">platforms for media consumption, </span><span class="line" data-startTime="480">playing videos, </span><span class="line" data-startTime="482">so I wondered OK, well, in the </span><span class="line" data-startTime="482">aggregate worldwide, what </span><span class="line" data-startTime="487">percentage of tablets support </span><span class="line" data-startTime="487">WebM natively. </span> <span class="line" data-startTime="490">And it turns out it's </span><span class="line" data-startTime="490">about 43.4%. </span></p>

<p><span class="line" data-startTime="494">So this is obviously &mdash; </span><span class="line" data-startTime="497">a lot of this is Android. </span> <span class="line" data-startTime="499">And as you heard yesterday in </span><span class="line" data-startTime="499">the keynote, Android is </span><span class="line" data-startTime="503">growing at a kind of </span><span class="line" data-startTime="503">a moderate rate, I </span><span class="line" data-startTime="506">guess you might say. </span> <span class="line" data-startTime="507">So anywhere where Android grows, </span><span class="line" data-startTime="507">WebM grows, because </span><span class="line" data-startTime="510">it's supported in the </span><span class="line" data-startTime="510">Android source </span><span class="line" data-startTime="513">repository out of the box. </span> <span class="line" data-startTime="515">There's also more hardware </span><span class="line" data-startTime="515">coming online for VP8. </span> <span class="line" data-startTime="518">This is a topic that everybody </span><span class="line" data-startTime="518">likes to discuss. </span> <span class="line" data-startTime="522">VP8 &mdash; </span><span class="line" data-startTime="523">hardware support is important to </span><span class="line" data-startTime="523">devices, low power devices </span><span class="line" data-startTime="527">especially, something that's </span><span class="line" data-startTime="527">not plugged into a wall. </span> <span class="line" data-startTime="530">So if it has a battery, you want </span><span class="line" data-startTime="530">to conserve as much of </span><span class="line" data-startTime="532">that battery as possible. </span></p>

<p><span class="line" data-startTime="533">Doing video, encoding and </span><span class="line" data-startTime="533">decoding operations and </span><span class="line" data-startTime="536">hardware is much, much </span><span class="line" data-startTime="536">less power intense </span><span class="line" data-startTime="540">than doing it in software. </span> <span class="line" data-startTime="541">So anyway, a lot of that's </span><span class="line" data-startTime="541">started to come </span><span class="line" data-startTime="542">in the market now. </span> <span class="line" data-startTime="543">Their VP8 decoder's coming to </span><span class="line" data-startTime="543">market pretty much every major </span><span class="line" data-startTime="548">SOC vendor, which is SOC &mdash; the </span><span class="line" data-startTime="548">ARM chip vendors, who have &mdash; </span><span class="line" data-startTime="553">there's an arm corps </span><span class="line" data-startTime="553">of the sock. </span> <span class="line" data-startTime="555">But then it has blocks for </span><span class="line" data-startTime="555">hardware operations </span><span class="line" data-startTime="556">like video and audio. </span> <span class="line" data-startTime="558">Pretty much every major </span><span class="line" data-startTime="558">arm-based sock vendor is now </span><span class="line" data-startTime="561">much shipping chips </span><span class="line" data-startTime="561">with VP8 decoding. </span> <span class="line" data-startTime="564">And they're starting to come in </span><span class="line" data-startTime="564">the market and things like </span><span class="line" data-startTime="566">the Samsung Chromebooks, Nexus </span><span class="line" data-startTime="566">10, Samsung Galaxy S4, those </span><span class="line" data-startTime="571">types of devices. </span></p>

<p><span class="line" data-startTime="574">So as an example of what </span><span class="line" data-startTime="574">I mentioned about the </span><span class="line" data-startTime="575">complexity, YouTube obviously </span><span class="line" data-startTime="575">wanted to support the Wii. </span> <span class="line" data-startTime="580">There's many of those devices </span><span class="line" data-startTime="580">in the world. </span> <span class="line" data-startTime="582">And a lot of users love them. </span> <span class="line" data-startTime="583">They want to play YouTube </span><span class="line" data-startTime="583">video on them. </span> <span class="line" data-startTime="585">But the problem they kept </span><span class="line" data-startTime="585">running into is due to some </span><span class="line" data-startTime="588">platform limitations that </span><span class="line" data-startTime="588">Nintendo puts in place, they </span><span class="line" data-startTime="590">couldn't access the hardware to </span><span class="line" data-startTime="590">do the video in hardware. </span> <span class="line" data-startTime="595">And they're doing it in </span><span class="line" data-startTime="595">software, they had other </span><span class="line" data-startTime="598">limitations where the .264 </span><span class="line" data-startTime="598">streams didn't have the </span><span class="line" data-startTime="602">horsepower to play them back. </span> <span class="line" data-startTime="604">And then the .263 streams, they </span><span class="line" data-startTime="604">just weren't getting the </span><span class="line" data-startTime="606">quality that they thought </span><span class="line" data-startTime="606">the users deserved. </span></p>

<p><span class="line" data-startTime="608">So they said what about VP8? </span><span class="line" data-startTime="612">We ported and optimized VP8 for </span><span class="line" data-startTime="612">that platform, and now Wii </span><span class="line" data-startTime="616">client in the world </span><span class="line" data-startTime="616">gets WebM video. </span> <span class="line" data-startTime="618">And that market is now open </span><span class="line" data-startTime="618">to all those users. </span> <span class="line" data-startTime="620">So that's an example where the </span><span class="line" data-startTime="620">simplicity of the designs that </span><span class="line" data-startTime="624">we always strive for end up </span><span class="line" data-startTime="624">paying off in the end. </span> <span class="line" data-startTime="630">So perhaps most importantly, </span><span class="line" data-startTime="630">WebM is free. </span> <span class="line" data-startTime="636">That means both senses of the </span><span class="line" data-startTime="636">word as people know it &mdash; </span><span class="line" data-startTime="639">beer and speech. </span> <span class="line" data-startTime="642">We don't charge any </span><span class="line" data-startTime="642">money for WebM. </span> <span class="line" data-startTime="644">VP8, Matroska, Vorbis are all </span><span class="line" data-startTime="644">royalty-free technologies. </span></p>

<p><span class="line" data-startTime="650">And it's all open source. </span> <span class="line" data-startTime="652">The VP8 codec is in a </span><span class="line" data-startTime="652">repository in the </span><span class="line" data-startTime="655">WebMproject.org website. </span> <span class="line" data-startTime="656">Anybody's free to use it. </span> <span class="line" data-startTime="659">It's under a BSD license, </span><span class="line" data-startTime="659">which is one of the more </span><span class="line" data-startTime="661">liberal open source licenses. </span> <span class="line" data-startTime="662">It means anybody can fork it. </span> <span class="line" data-startTime="665">I've even had customers ask me </span><span class="line" data-startTime="665">if I use it, do I have to </span><span class="line" data-startTime="672">still call VP8. </span> <span class="line" data-startTime="673">And you don't. </span> <span class="line" data-startTime="673">You can call it whatever </span><span class="line" data-startTime="673">you want. </span> <span class="line" data-startTime="675">That's the beauty of </span><span class="line" data-startTime="675">the BSD license. </span> <span class="line" data-startTime="678">So why is this important </span><span class="line" data-startTime="678">to developers. </span> <span class="line" data-startTime="680">It's important because other </span><span class="line" data-startTime="680">codecs can cost you millions </span><span class="line" data-startTime="683">of dollars a year. </span></p>

<p><span class="line" data-startTime="684">And that's not an </span><span class="line" data-startTime="684">exaggeration. </span> <span class="line" data-startTime="686">A lot of standards-based </span><span class="line" data-startTime="686">codecs have royalties </span><span class="line" data-startTime="690">associated with them. </span> <span class="line" data-startTime="691">It has nothing to do with </span><span class="line" data-startTime="691">the standards groups. </span> <span class="line" data-startTime="694">They just assemble </span><span class="line" data-startTime="694">the technologies </span><span class="line" data-startTime="696">and write the specs. </span> <span class="line" data-startTime="697">It's the people on patents that </span><span class="line" data-startTime="697">are relevant to those </span><span class="line" data-startTime="699">standards that then form pools </span><span class="line" data-startTime="699">to charge royalties for them. </span> <span class="line" data-startTime="703">The H.264 and VC-1 royalty </span><span class="line" data-startTime="703">pools today have maximum </span><span class="line" data-startTime="709">annual royalties of $6.5 </span><span class="line" data-startTime="709">million a year. </span> <span class="line" data-startTime="713">For apps, it's sort of a scaling </span><span class="line" data-startTime="713">sliding scale, but </span><span class="line" data-startTime="719">it's basically $0.20 a unit of </span><span class="line" data-startTime="719">every app that you sell. </span></p>

<p><span class="line" data-startTime="722">So what does that mean to you? </span><span class="line" data-startTime="723">Let's say you're an Android </span><span class="line" data-startTime="723">developer, and you have an app </span><span class="line" data-startTime="726">that you want to do video coding </span><span class="line" data-startTime="726">like Frank's going to </span><span class="line" data-startTime="728">demonstrate. </span> <span class="line" data-startTime="731">Let's say you put it in the </span><span class="line" data-startTime="731">Play Store, and you charge </span><span class="line" data-startTime="733">$0.99 for it. </span> <span class="line" data-startTime="734">$0.20 of every sale you make </span><span class="line" data-startTime="734">goes to a pooling organization </span><span class="line" data-startTime="738">called [INAUDIBLE], up </span><span class="line" data-startTime="738">to the cap of $6 and </span><span class="line" data-startTime="742">1/2 million a year. </span> <span class="line" data-startTime="744">This is even applicable if your </span><span class="line" data-startTime="744">app is free, because the </span><span class="line" data-startTime="749">royalty is to use </span><span class="line" data-startTime="749">the technology. </span> <span class="line" data-startTime="750">It's not a share of the money </span><span class="line" data-startTime="750">you make or anything else. </span></p>

<p><span class="line" data-startTime="753">If your app has just does </span><span class="line" data-startTime="753">content in those formats &mdash; </span><span class="line" data-startTime="758">let's say, you are able to sort </span><span class="line" data-startTime="758">of take advantage of the </span><span class="line" data-startTime="761">codec that's in the Android </span><span class="line" data-startTime="761">platform SDK or hardware, if </span><span class="line" data-startTime="765">you're charging users any amount </span><span class="line" data-startTime="765">of money to consume </span><span class="line" data-startTime="768">that content, you're going </span><span class="line" data-startTime="768">to owe royalties as well. </span> <span class="line" data-startTime="771">So none of this, thankfully, </span><span class="line" data-startTime="771">applies to WebM. </span> <span class="line" data-startTime="774">It's all free. </span> <span class="line" data-startTime="775">It's all open. </span> <span class="line" data-startTime="775">Anybody can use it, and now </span><span class="line" data-startTime="775">owe anybody any money. </span> <span class="line" data-startTime="780">So that's all the great </span><span class="line" data-startTime="780">properties of it. </span> <span class="line" data-startTime="783">I'm just going to show you </span><span class="line" data-startTime="783">how to actually make </span><span class="line" data-startTime="786">one of these files. </span></p>

<p><span class="line" data-startTime="790">Who understands how video </span><span class="line" data-startTime="790">compression works? </span><span class="line" data-startTime="793">Probably most of you, right? </span><span class="line" data-startTime="795">OK. </span> <span class="line" data-startTime="797">The primary aim of any kind of </span><span class="line" data-startTime="797">compression but particularly </span><span class="line" data-startTime="801">video is to remove redundancies </span><span class="line" data-startTime="801">of data. </span> <span class="line" data-startTime="804">With video, you have </span><span class="line" data-startTime="804">redundancies within frames of </span><span class="line" data-startTime="807">video that's called spatial </span><span class="line" data-startTime="807">redundancy. </span> <span class="line" data-startTime="810">Temporal redundancy is things </span><span class="line" data-startTime="810">that are similar in </span><span class="line" data-startTime="812">a sequence of frames. </span> <span class="line" data-startTime="814">You can get rid of </span><span class="line" data-startTime="814">all that stuff. </span> <span class="line" data-startTime="816">Statistical redundancy &mdash; </span><span class="line" data-startTime="818">redundancy in the data stream </span><span class="line" data-startTime="818">itself00 the ones and zeros. </span> <span class="line" data-startTime="822">Take those out. </span> <span class="line" data-startTime="823">There's perceptual &mdash; </span><span class="line" data-startTime="825">it's called redundancy, </span><span class="line" data-startTime="825">but it's not quite. </span> <span class="line" data-startTime="827">It's just things that the human </span><span class="line" data-startTime="827">eye can't even perceive. </span> <span class="line" data-startTime="830">Just take those out. </span> <span class="line" data-startTime="831">So you take all these things out </span><span class="line" data-startTime="831">with the ultimate goal of </span><span class="line" data-startTime="834">removing them, yet keeping the </span><span class="line" data-startTime="834">quality as close as you </span><span class="line" data-startTime="838">possibly can to the original </span><span class="line" data-startTime="838">source video. </span></p>

<p><span class="line" data-startTime="840">This is the way this is the </span><span class="line" data-startTime="840">art of the technology. </span> <span class="line" data-startTime="844">How do you do all this, yet when </span><span class="line" data-startTime="844">you reconstruct the image </span><span class="line" data-startTime="847">from the compressed bitstream, </span><span class="line" data-startTime="847">what the user sees is, you </span><span class="line" data-startTime="850">hope, imperceptible from </span><span class="line" data-startTime="850">what you started from. </span> <span class="line" data-startTime="853">So raw video &mdash; </span><span class="line" data-startTime="855">video right off of a camera and </span><span class="line" data-startTime="855">editing deck, whatever &mdash; </span><span class="line" data-startTime="859">if you just have all those </span><span class="line" data-startTime="859">full pixels, it's not </span><span class="line" data-startTime="861">compressed at all. </span> <span class="line" data-startTime="862">It's gigantic. </span> <span class="line" data-startTime="863">So let's say this video </span><span class="line" data-startTime="863">that I'm going to </span><span class="line" data-startTime="865">encode is not even HD. </span> <span class="line" data-startTime="868">It's around standard </span><span class="line" data-startTime="868">definition. </span></p>

<p><span class="line" data-startTime="871">It's 17 seconds long, just for </span><span class="line" data-startTime="871">the sake of brevity here. </span> <span class="line" data-startTime="875">Yet it's 320 megabytes, </span><span class="line" data-startTime="875">that file. </span> <span class="line" data-startTime="880">So I don't know about you, but </span><span class="line" data-startTime="880">my network at home can't serve </span><span class="line" data-startTime="884">that data rate. </span> <span class="line" data-startTime="886">I don't know, maybe if you had </span><span class="line" data-startTime="886">fiber, maybe, but even then </span><span class="line" data-startTime="889">probably not. </span> <span class="line" data-startTime="890">Audio, same case. </span> <span class="line" data-startTime="892">The raw audio stream I'm going </span><span class="line" data-startTime="892">to use, which is PCM samples, </span><span class="line" data-startTime="896">is three megabytes. </span> <span class="line" data-startTime="898">I got 17 seconds. </span> <span class="line" data-startTime="900">So how are we going to get 323 </span><span class="line" data-startTime="900">megabytes of data over a </span><span class="line" data-startTime="906">network to a user </span><span class="line" data-startTime="906">in 17 seconds. </span> <span class="line" data-startTime="909">Well, we're going to use ffmpeg </span><span class="line" data-startTime="909">We're going to combine </span><span class="line" data-startTime="912">these streams, which is called </span><span class="line" data-startTime="912">muxing, multiplexing. </span> <span class="line" data-startTime="916">We're then going to run </span><span class="line" data-startTime="916">them through ffmpeg. </span> <span class="line" data-startTime="919">And this is represented by this </span><span class="line" data-startTime="919">clever spinning logo. </span></p>

<p><span class="line" data-startTime="924">This is where all that magic </span><span class="line" data-startTime="924">that I talked about happens. </span> <span class="line" data-startTime="927">This is where the codec is going </span><span class="line" data-startTime="927">to look at these frames </span><span class="line" data-startTime="931">of video and look at all the </span><span class="line" data-startTime="931">redundancies and just pull </span><span class="line" data-startTime="934">them all out, compress it </span><span class="line" data-startTime="934">all down into a stream. </span> <span class="line" data-startTime="938">And the final result </span><span class="line" data-startTime="938">is going to be a </span><span class="line" data-startTime="939">WebM file of 1.9 megabytes. </span> <span class="line" data-startTime="943">So we took 323 megabytes worth </span><span class="line" data-startTime="943">of raw data, and now this is </span><span class="line" data-startTime="947">something that 17 seconds, 1.9 </span><span class="line" data-startTime="947">megabytes, easily can be </span><span class="line" data-startTime="953">served to pretty much any user, </span><span class="line" data-startTime="953">even maybe even over a </span><span class="line" data-startTime="958">3G connection. </span> <span class="line" data-startTime="960">So let's look at how </span><span class="line" data-startTime="960">this is done. </span> <span class="line" data-startTime="963">This is the example. </span></p>

<p><span class="line" data-startTime="964">I have a couple examples </span><span class="line" data-startTime="964">in this slide. </span> <span class="line" data-startTime="965">You'll be able to download them </span><span class="line" data-startTime="965">later on and play around </span><span class="line" data-startTime="968">with them yourself. </span> <span class="line" data-startTime="969">You can modify them. </span> <span class="line" data-startTime="970">There are other options. </span> <span class="line" data-startTime="971">You can go as deep into this </span><span class="line" data-startTime="971">stuff as you want. </span> <span class="line" data-startTime="974">But one of the beauties of VP8 </span><span class="line" data-startTime="974">and WebM is that we have, </span><span class="line" data-startTime="977">again, with simplicity in mind, </span><span class="line" data-startTime="977">you don't have to be an </span><span class="line" data-startTime="981">expert in this stuff. </span> <span class="line" data-startTime="982">You don't have to hire </span><span class="line" data-startTime="982">consultants to show you </span><span class="line" data-startTime="985">exactly every parameter </span><span class="line" data-startTime="985">required to do this. </span></p>

<p><span class="line" data-startTime="988">Pretty much if you put a video </span><span class="line" data-startTime="988">into the libvpx compressor, it </span><span class="line" data-startTime="992">makes a lot of the hard </span><span class="line" data-startTime="992">decisions for you. </span> <span class="line" data-startTime="994">What comes out there is, in </span><span class="line" data-startTime="994">most cases, pretty great. </span> <span class="line" data-startTime="997">So let's just step through </span><span class="line" data-startTime="997">these parameters here. </span> <span class="line" data-startTime="1001">First is the binary &mdash; </span><span class="line" data-startTime="1002">ffmpeg. </span> <span class="line" data-startTime="1003">That's the program. </span> <span class="line" data-startTime="1005">The dot i is the input video. </span> <span class="line" data-startTime="1008">Again, this is a raw stream, </span><span class="line" data-startTime="1008">Y4M, just raw pixel data. </span> <span class="line" data-startTime="1012">Same with the audio, just </span><span class="line" data-startTime="1012">a WAV file, PCM samples. </span> <span class="line" data-startTime="1016">This -c v parameter is libvpx. </span> <span class="line" data-startTime="1018">That's the library that we </span><span class="line" data-startTime="1018">at the WebM project make </span><span class="line" data-startTime="1022">available in source or binary </span><span class="line" data-startTime="1022">from the website. </span> <span class="line" data-startTime="1025">Does all the VP8 </span><span class="line" data-startTime="1025">encoding magic. </span> <span class="line" data-startTime="1029">-b v is the bit rate. </span> <span class="line" data-startTime="1031">So I'm going to set the target </span><span class="line" data-startTime="1031">bit-rate of this file to 800 </span><span class="line" data-startTime="1034">kilobits per second. </span> <span class="line" data-startTime="1036">What does that mean? </span><span class="line" data-startTime="1037">That means I tell the encoder I </span><span class="line" data-startTime="1037">say OK, if you could encode </span><span class="line" data-startTime="1042">any frame or segment or one </span><span class="line" data-startTime="1042">second's worth of video in </span><span class="line" data-startTime="1046">these streams, with using less </span><span class="line" data-startTime="1046">than 800 kilobits of </span><span class="line" data-startTime="1050">data, go for it. </span> <span class="line" data-startTime="1052">That's great. </span></p>

<p><span class="line" data-startTime="1053">Yet don't exceed that. </span> <span class="line" data-startTime="1055">Because my target use case, </span><span class="line" data-startTime="1055">I know that my users &mdash; </span><span class="line" data-startTime="1058">let's say, I know from market </span><span class="line" data-startTime="1058">research, whatever &mdash; that most </span><span class="line" data-startTime="1061">of my users don't have any more </span><span class="line" data-startTime="1061">than a megabit reliable </span><span class="line" data-startTime="1065">connectivity. </span> <span class="line" data-startTime="1066">So with overhead and audio, I </span><span class="line" data-startTime="1066">want to keep that well below </span><span class="line" data-startTime="1069">one megabit a second. </span> <span class="line" data-startTime="1071">So I'm going to specify </span><span class="line" data-startTime="1071">800 kilobits as </span><span class="line" data-startTime="1073">my target data rate. </span> <span class="line" data-startTime="1076">Quality setting is just &mdash; </span><span class="line" data-startTime="1077">in the VP8 coder, there's </span><span class="line" data-startTime="1077">three settings &mdash; </span><span class="line" data-startTime="1079">real time, best and good. </span> <span class="line" data-startTime="1081">Best and good are kind of </span><span class="line" data-startTime="1081">misnomers, in that yes, best </span><span class="line" data-startTime="1085">will give you the absolute </span><span class="line" data-startTime="1085">best quality. </span> <span class="line" data-startTime="1088">But in most cases, good </span><span class="line" data-startTime="1088">is just that. </span> <span class="line" data-startTime="1090">It's good enough. </span> <span class="line" data-startTime="1091">And it runs faster. </span> <span class="line" data-startTime="1092">The best quality will give you </span><span class="line" data-startTime="1092">the best output, but it is, in </span><span class="line" data-startTime="1096">some cases, depending on the </span><span class="line" data-startTime="1096">material, can be significantly </span><span class="line" data-startTime="1100">more intense and take </span><span class="line" data-startTime="1100">longer to encode. </span></p>

<p><span class="line" data-startTime="1103">So this next is just the </span><span class="line" data-startTime="1103">video filter, the -vf. </span> <span class="line" data-startTime="1106">There are a number of filters </span><span class="line" data-startTime="1106">that you can use an ffmpeg to </span><span class="line" data-startTime="1109">do all sorts of things like &mdash; </span><span class="line" data-startTime="1112">scaling is one of them. </span> <span class="line" data-startTime="1113">So I'm going to scale </span><span class="line" data-startTime="1113">this video. </span> <span class="line" data-startTime="1115">Right now, it's a little bit </span><span class="line" data-startTime="1115">bigger than standard </span><span class="line" data-startTime="1118">definition. </span> <span class="line" data-startTime="1119">I'm going to scale down to </span><span class="line" data-startTime="1119">standard definition, which is </span><span class="line" data-startTime="1122">480 pixels high. </span> <span class="line" data-startTime="1124">The negative one is I'm saying </span><span class="line" data-startTime="1124">OK, I want you make it 480 </span><span class="line" data-startTime="1129">pixels high, but the width &mdash; </span><span class="line" data-startTime="1131">I want you to keep it </span><span class="line" data-startTime="1131">proportional to the input, to </span><span class="line" data-startTime="1135">that Y4M file. </span></p>

<p><span class="line" data-startTime="1137">So this means that it's going </span><span class="line" data-startTime="1137">to scale it proportionally. </span> <span class="line" data-startTime="1139">Whatever that width ends </span><span class="line" data-startTime="1139">up being, that's what </span><span class="line" data-startTime="1142">it's going to be. </span> <span class="line" data-startTime="1142">This prevents things like if you </span><span class="line" data-startTime="1142">use the defaults, in some </span><span class="line" data-startTime="1146">cases it'll scale &mdash; if you say </span><span class="line" data-startTime="1146">scale 480, but you don't </span><span class="line" data-startTime="1150">preserve the aspect, you get </span><span class="line" data-startTime="1150">these videos with people </span><span class="line" data-startTime="1153">stretched out or squished. </span> <span class="line" data-startTime="1156">So in pretty much every case, </span><span class="line" data-startTime="1156">you want to preserve the </span><span class="line" data-startTime="1159">aspect ratio. </span> <span class="line" data-startTime="1161">Last arguments are just </span><span class="line" data-startTime="1161">for libvorbis. </span> <span class="line" data-startTime="1163">This is the audio encoder, </span><span class="line" data-startTime="1163">also freely available. </span> <span class="line" data-startTime="1166">And I'm just going to use the </span><span class="line" data-startTime="1166">default settings there, which </span><span class="line" data-startTime="1169">are good enough for </span><span class="line" data-startTime="1169">this use case. </span></p>

<p><span class="line" data-startTime="1170">And the last one is the output </span><span class="line" data-startTime="1170">file, which is cleverly enough </span><span class="line" data-startTime="1174">called of W480.webm. </span> <span class="line" data-startTime="1178">So just like on the old cooking </span><span class="line" data-startTime="1178">shows, through the </span><span class="line" data-startTime="1181">magic of technology, I happen </span><span class="line" data-startTime="1181">to have one of these already </span><span class="line" data-startTime="1184">ready to go. </span> <span class="line" data-startTime="1185">So let's see what happens. </span> <span class="line" data-startTime="1189">Now it just spit out a bunch </span><span class="line" data-startTime="1189">of scary looking stuff. </span> <span class="line" data-startTime="1192">It's not that scary. </span> <span class="line" data-startTime="1192">All this is mostly some </span><span class="line" data-startTime="1192">information about how this </span><span class="line" data-startTime="1196">particular instance of ffmpeg </span><span class="line" data-startTime="1196">was compiled &mdash; all the flags </span><span class="line" data-startTime="1199">and things. </span> <span class="line" data-startTime="1200">The interesting stuff here is </span><span class="line" data-startTime="1200">the sort of purple text. </span> <span class="line" data-startTime="1203">So it's saying OK, I see that </span><span class="line" data-startTime="1203">you've handed me a Y4M file. </span></p>

<p><span class="line" data-startTime="1207">It does some piping magic to </span><span class="line" data-startTime="1207">handle those types of files. </span> <span class="line" data-startTime="1211">These are the properties </span><span class="line" data-startTime="1211">of it. </span> <span class="line" data-startTime="1213">It's just telling me look, there </span><span class="line" data-startTime="1213">are no time codes or </span><span class="line" data-startTime="1217">anything here. </span> <span class="line" data-startTime="1217">So this might be inaccurate. </span> <span class="line" data-startTime="1219">I'm going to guess. </span> <span class="line" data-startTime="1219">That's usually good enough. </span> <span class="line" data-startTime="1221">Same with the audio. </span> <span class="line" data-startTime="1222">It says OK, this is what </span><span class="line" data-startTime="1222">you're hading me. </span> <span class="line" data-startTime="1224">You already have one of these </span><span class="line" data-startTime="1224">files there, because you've </span><span class="line" data-startTime="1227">tested it in your hotel </span><span class="line" data-startTime="1227">room this morning. </span> <span class="line" data-startTime="1229">Are you sure you want </span><span class="line" data-startTime="1229">to blow that away? </span><span class="line" data-startTime="1231">And I say sure, let's </span><span class="line" data-startTime="1231">go for it. </span></p>

<p><span class="line" data-startTime="1234">So now the magic starts. </span> <span class="line" data-startTime="1235">All those things I talked </span><span class="line" data-startTime="1235">about, again, with the </span><span class="line" data-startTime="1237">redundancies, removing all </span><span class="line" data-startTime="1237">these things that are not </span><span class="line" data-startTime="1243">needed to reconstruct this </span><span class="line" data-startTime="1243">image later using a </span><span class="line" data-startTime="1245">decompressor. </span> <span class="line" data-startTime="1247">So you can see down at </span><span class="line" data-startTime="1247">the bottom, the final </span><span class="line" data-startTime="1249">file size is growing. </span> <span class="line" data-startTime="1251">The bit-rate, in some sections, </span><span class="line" data-startTime="1251">is exceeding but </span><span class="line" data-startTime="1253">overall, it's going &mdash; across the </span><span class="line" data-startTime="1253">breadth of it should stay </span><span class="line" data-startTime="1257">below and we're done. </span> <span class="line" data-startTime="1259">So let's see how we did. </span> <span class="line" data-startTime="1263">As I said, the aim of this is </span><span class="line" data-startTime="1263">to make what comes out as </span><span class="line" data-startTime="1269">close as possible to what went </span><span class="line" data-startTime="1269">in from visual perspective. </span> <span class="line" data-startTime="1276">So we forgot to plug </span><span class="line" data-startTime="1276">in the audio. </span></p>

<p><span class="line" data-startTime="1281">Trust me, there's audio. </span> <span class="line" data-startTime="1282">And these screen, it's </span><span class="line" data-startTime="1282">always hard. </span> <span class="line" data-startTime="1286">Projectors don't &mdash; </span><span class="line" data-startTime="1286">the fidelity's </span><span class="line" data-startTime="1288">usually not so great. </span> <span class="line" data-startTime="1289">But you can see this looks </span><span class="line" data-startTime="1289">pretty good, right? </span><span class="line" data-startTime="1292">This is only 800 kilobits a </span><span class="line" data-startTime="1292">second of data, which Frank </span><span class="line" data-startTime="1295">and I've been in this business </span><span class="line" data-startTime="1295">for probably &mdash; </span><span class="line" data-startTime="1298">I don't want &mdash; </span></p>

<p class="speaker"><span class="line" data-starttime="1299"><span class="speakerName">Frank Galligan</span>: 15? </span></p>

<p class="speaker"><span class="line" data-starttime="1300"><span class="speakerName">John Luther</span>: Long enough for </span><span class="line" data-startTime="1300">you to gray hairs in your </span><span class="line" data-startTime="1301">[INAUDIBLE]. </span> <span class="line" data-startTime="1303">When we started in this, the </span><span class="line" data-startTime="1303">idea of doing a standard </span><span class="line" data-startTime="1306">definition video at 800 kilobits </span><span class="line" data-startTime="1306">was preposterous. </span> <span class="line" data-startTime="1309">Back then, we were using 300 </span><span class="line" data-startTime="1309">kilobits to do little postage </span><span class="line" data-startTime="1312">size videos. </span> <span class="line" data-startTime="1313">So it's pretty remarkable how </span><span class="line" data-startTime="1313">far the technology has come. </span> <span class="line" data-startTime="1318">OK, so I have a number </span><span class="line" data-startTime="1318">of these examples. </span> <span class="line" data-startTime="1321">I want to give Frank his time. </span> <span class="line" data-startTime="1323">So you can look through these </span><span class="line" data-startTime="1323">later when you download. </span> <span class="line" data-startTime="1325">Just two pass, again, </span><span class="line" data-startTime="1325">more quality, </span><span class="line" data-startTime="1328">but it'll take longer. </span></p>

<p><span class="line" data-startTime="1329">This is an example here of </span><span class="line" data-startTime="1329">running the encoder in a real </span><span class="line" data-startTime="1331">time mode to make it run faster, </span><span class="line" data-startTime="1331">which will slightly </span><span class="line" data-startTime="1335">degrade the quality, but it </span><span class="line" data-startTime="1335">will be done in real time. </span> <span class="line" data-startTime="1339">And I just have an example here </span><span class="line" data-startTime="1339">of how you would do this </span><span class="line" data-startTime="1340">for a mobile use case. </span> <span class="line" data-startTime="1343">So there's lots of information </span><span class="line" data-startTime="1343">on our site </span><span class="line" data-startTime="1345">and around the internet. </span> <span class="line" data-startTime="1346">I put some links in here </span><span class="line" data-startTime="1346">about using ffmpeg </span><span class="line" data-startTime="1349">and some other things. </span> <span class="line" data-startTime="1351">And this is where I hand </span><span class="line" data-startTime="1351">it over to Frank. </span></p>

<p></p>

<p class="speaker"><span class="line" data-starttime="1353"><span class="speakerName">Frank Galligan</span>: Thanks, John. </span> <span class="line" data-startTime="1356">So John showed you one way to </span><span class="line" data-startTime="1356">encode videos on the desktop. </span> <span class="line" data-startTime="1360">I'm going to show you another </span><span class="line" data-startTime="1360">method of adding audio and </span><span class="line" data-startTime="1364">video coding to your Android </span><span class="line" data-startTime="1364">applications. </span> <span class="line" data-startTime="1367">I'm going to use a project </span><span class="line" data-startTime="1367">called WebM JNI bindings. </span> <span class="line" data-startTime="1372">I have two demos. </span> <span class="line" data-startTime="1373">And then I'm going </span><span class="line" data-startTime="1373">take a little &mdash; </span><span class="line" data-startTime="1375">time permitting &mdash; a little </span><span class="line" data-startTime="1375">closer look at the code. </span> <span class="line" data-startTime="1380">So the WebM JNI bindings </span><span class="line" data-startTime="1380">allows your Android </span><span class="line" data-startTime="1387">applications to interface with </span><span class="line" data-startTime="1387">five open source projects. </span> <span class="line" data-startTime="1393">The code in the green boxes is </span><span class="line" data-startTime="1393">the Java JNI code that your </span><span class="line" data-startTime="1397">application will call. </span></p>

<p><span class="line" data-startTime="1400">The code in the orange </span><span class="line" data-startTime="1400">box is the C, C++ </span><span class="line" data-startTime="1404">code of the JNI bindings. </span> <span class="line" data-startTime="1409">Most of the code in the orange </span><span class="line" data-startTime="1409">box is just a pass through </span><span class="line" data-startTime="1414">from the Java NI bindings </span><span class="line" data-startTime="1414">to the C, </span><span class="line" data-startTime="1416">C++ open source projects. </span> <span class="line" data-startTime="1419">There is a Vorbis encoder object </span><span class="line" data-startTime="1419">class that makes it </span><span class="line" data-startTime="1423">easier to add Vorbis encoding. </span> <span class="line" data-startTime="1426">Also has some specific functions </span><span class="line" data-startTime="1426">for Vorbis with </span><span class="line" data-startTime="1430">regards to WebM files. </span> <span class="line" data-startTime="1434">And all the code in the green </span><span class="line" data-startTime="1434">and orange boxes is what's </span><span class="line" data-startTime="1438">comprising the WebM </span><span class="line" data-startTime="1438">JNI bindings. </span> <span class="line" data-startTime="1441">The code in the blue boxes is </span><span class="line" data-startTime="1441">the open source code that </span><span class="line" data-startTime="1444">really does all the heavy </span><span class="line" data-startTime="1444">lifting, does the converting, </span><span class="line" data-startTime="1448">does the encoding, </span><span class="line" data-startTime="1448">does the muxing. </span> <span class="line" data-startTime="1451">And most of the code in the blue </span><span class="line" data-startTime="1451">boxes is hand optimized </span><span class="line" data-startTime="1454">for ARM, as well as x86. </span> <span class="line" data-startTime="1457">Also in the JNI bindings is </span><span class="line" data-startTime="1457">a readme.android file. </span></p>

<p><span class="line" data-startTime="1462">The readme tells you how to set </span><span class="line" data-startTime="1462">everything up, where to </span><span class="line" data-startTime="1465">get the open source code, how </span><span class="line" data-startTime="1465">to build them and how to get </span><span class="line" data-startTime="1469">ready to add audio and video </span><span class="line" data-startTime="1469">encoding to your project. </span> <span class="line" data-startTime="1474">So with that, I'll show </span><span class="line" data-startTime="1474">our first demo. </span> <span class="line" data-startTime="1484">So what I'm going to do is I'm </span><span class="line" data-startTime="1484">going to add audio and &mdash; oops, </span><span class="line" data-startTime="1490">should be coming soon &mdash; anyways, </span><span class="line" data-startTime="1490">I'm going to add </span><span class="line" data-startTime="1492">audio and video encoding to an </span><span class="line" data-startTime="1492">Android device using the WebM </span><span class="line" data-startTime="1496">JNI bindings. </span> <span class="line" data-startTime="1498">I'm using one of the example </span><span class="line" data-startTime="1498">functions from the bindings, </span><span class="line" data-startTime="1501">which basically takes a raw </span><span class="line" data-startTime="1501">video input, raw audio input, </span><span class="line" data-startTime="1508">and output to WebM </span><span class="line" data-startTime="1508">file on a device. </span> <span class="line" data-startTime="1512">What I did, I already created </span><span class="line" data-startTime="1512">the new application. </span></p>

<p><span class="line" data-startTime="1515">Here's the main activity file </span><span class="line" data-startTime="1515">which you probably all know. </span> <span class="line" data-startTime="1519">And I already downloaded the </span><span class="line" data-startTime="1519">NI bindings, set them up. </span> <span class="line" data-startTime="1522">I already downloaded all the </span><span class="line" data-startTime="1522">dependent open source projects </span><span class="line" data-startTime="1525">and set them up. </span> <span class="line" data-startTime="1527">I did that basically from </span><span class="line" data-startTime="1527">the readme.android. </span> <span class="line" data-startTime="1531">It gives you all the steps how </span><span class="line" data-startTime="1531">to do it, run through. </span> <span class="line" data-startTime="1534">It's pretty easy. </span> <span class="line" data-startTime="1535">We actually had a demo of when </span><span class="line" data-startTime="1535">I tried to create a new </span><span class="line" data-startTime="1540">project from scratch, download </span><span class="line" data-startTime="1540">everything, add the audio and </span><span class="line" data-startTime="1543">video encoding and show </span><span class="line" data-startTime="1543">the video file </span><span class="line" data-startTime="1544">in under five minutes. </span></p>

<p><span class="line" data-startTime="1545">It works sometimes, but we had </span><span class="line" data-startTime="1545">to cut it, because it was a </span><span class="line" data-startTime="1548">little confusing. </span> <span class="line" data-startTime="1549">And we didn't have much time. </span> <span class="line" data-startTime="1550">We're already kind of running </span><span class="line" data-startTime="1550">a little late, as it is. </span> <span class="line" data-startTime="1554">So I'm going to copy the code </span><span class="line" data-startTime="1554">from the readme.android and </span><span class="line" data-startTime="1559">add it to my main </span><span class="line" data-startTime="1559">file on Create. </span> <span class="line" data-startTime="1563">This is the code that will do </span><span class="line" data-startTime="1563">the audio and video encoding. </span> <span class="line" data-startTime="1568">I will update my includes. </span> <span class="line" data-startTime="1572">And I'm going to set my video </span><span class="line" data-startTime="1572">input file that I already </span><span class="line" data-startTime="1581">pushed in my device on </span><span class="line" data-startTime="1581">external storage. </span> <span class="line" data-startTime="1583">I'm going to set </span><span class="line" data-startTime="1583">my audio file. </span></p>

<p><span class="line" data-startTime="1586">Again, I already pushed. </span> <span class="line" data-startTime="1588">Save this, and now I'm </span><span class="line" data-startTime="1588">going to switch </span><span class="line" data-startTime="1592">to the Android device. </span> <span class="line" data-startTime="1600">So this is probably the </span><span class="line" data-startTime="1600">simplest example. </span> <span class="line" data-startTime="1602">I'm just reading the audio and </span><span class="line" data-startTime="1602">video input file on the device </span><span class="line" data-startTime="1606">in external storage </span><span class="line" data-startTime="1606">and writing it </span><span class="line" data-startTime="1608">out to external storage. </span> <span class="line" data-startTime="1610">So let me show you that there is </span><span class="line" data-startTime="1610">no WebM file on the device. </span> <span class="line" data-startTime="1618">I kind of feel like </span><span class="line" data-startTime="1618">a magician. </span> <span class="line" data-startTime="1619">There's no cards up my sleeve. </span> <span class="line" data-startTime="1623">And now I'm going to run the </span><span class="line" data-startTime="1623">application on the device. </span> <span class="line" data-startTime="1632">So it's a pretty boring </span><span class="line" data-startTime="1632">application. </span> <span class="line" data-startTime="1634">It won't do too much. </span> <span class="line" data-startTime="1641">OK. </span></p>

<p><span class="line" data-startTime="1642">I agree. </span> <span class="line" data-startTime="1646">There we go. </span> <span class="line" data-startTime="1647">I said it's not going </span><span class="line" data-startTime="1647">to do too much. </span> <span class="line" data-startTime="1649">It'll either say success, </span><span class="line" data-startTime="1649">it's done, or error. </span> <span class="line" data-startTime="1652">OK, good. </span> <span class="line" data-startTime="1653">Success. </span> <span class="line" data-startTime="1655">So let's go back to </span><span class="line" data-startTime="1655">the explorer. </span> <span class="line" data-startTime="1658">Hit refresh. </span> <span class="line" data-startTime="1660">Should have a WebM file. </span> <span class="line" data-startTime="1663">Let me play it. </span> <span class="line" data-startTime="1665">[VIDEO PLAYBACK] </span><span class="line" data-startTime="1665">-Drop! </span><span class="line" data-startTime="1666">[GUN SHOT] </span><span class="line" data-startTime="1670">[EXPLOSION] </span><span class="line" data-startTime="1671">[END VIDEO PLAYBACK] </span></p>

<p class="speaker"><span class="line" data-starttime="1671"><span class="speakerName">Frank Galligan</span>: There we go. </span><span class="line" data-startTime="1674">So it worked. </span><span class="line" data-startTime="1675">It's nice when your first </span><span class="line" data-startTime="1675">demo works, you know. </span></p>

<p class="speaker"><span class="line" data-starttime="1678"><span class="speakerName">Audience</span>: [APPLAUSE] </span></p>

<p class="speaker"><span class="line" data-starttime="1679"><span class="speakerName">Frank Galligan</span>: You </span><span class="line" data-startTime="1679">do it 100 times. </span> <span class="line" data-startTime="1680">It works every time. </span> <span class="line" data-startTime="1681">You get up here, and </span><span class="line" data-startTime="1681">everything changes. </span> <span class="line" data-startTime="1683">So now I'll go back </span><span class="line" data-startTime="1683">to the slides. </span> <span class="line" data-startTime="1692">Maybe. </span> <span class="line" data-startTime="1696">All right. </span> <span class="line" data-startTime="1698">So I'm going to go into a little </span><span class="line" data-startTime="1698">bit of the code, the </span><span class="line" data-startTime="1701">example code, that I used from </span><span class="line" data-startTime="1701">the bindings project. </span> <span class="line" data-startTime="1706">The first set of slides is </span><span class="line" data-startTime="1706">setting up the audio and video </span><span class="line" data-startTime="1709">encoders, also the muxer. </span> <span class="line" data-startTime="1712">You can see we're creating </span><span class="line" data-startTime="1712">libvpx configure object. </span> <span class="line" data-startTime="1717">We're passing in the width </span><span class="line" data-startTime="1717">and the height </span><span class="line" data-startTime="1719">of the source video. </span></p>

<p><span class="line" data-startTime="1721">This is really important </span><span class="line" data-startTime="1721">because libvpx </span><span class="line" data-startTime="1723">not scale the video. </span> <span class="line" data-startTime="1726">At this point, neither </span><span class="line" data-startTime="1726">will the binding. </span> <span class="line" data-startTime="1727">So whenever you're creating on </span><span class="line" data-startTime="1727">the input, it's going to be on </span><span class="line" data-startTime="1731">the output. </span> <span class="line" data-startTime="1734">I'm also, in the example code </span><span class="line" data-startTime="1734">I'm showing, setting the </span><span class="line" data-startTime="1737">target bitrate to </span><span class="line" data-startTime="1737">1,000 kilobits. </span> <span class="line" data-startTime="1740">This is your most important </span><span class="line" data-startTime="1740">setting. </span> <span class="line" data-startTime="1741">This is a setting you will </span><span class="line" data-startTime="1741">always change depending on </span><span class="line" data-startTime="1744">your use case for your </span><span class="line" data-startTime="1744">application. </span> <span class="line" data-startTime="1747">For example, you could have &mdash; </span><span class="line" data-startTime="1749">creating a really small </span><span class="line" data-startTime="1749">video, like 160 by 120 </span><span class="line" data-startTime="1752">for whatever reason. </span></p>

<p><span class="line" data-startTime="1753">You're going to set your target </span><span class="line" data-startTime="1753">bit, right, maybe to </span><span class="line" data-startTime="1755">100 kilobits. </span> <span class="line" data-startTime="1756">Or you could be encoding </span><span class="line" data-startTime="1756">HD, and you </span><span class="line" data-startTime="1760">set it at three megabits. </span> <span class="line" data-startTime="1761">Whatever it is, this is the one </span><span class="line" data-startTime="1761">you're going to change. </span> <span class="line" data-startTime="1764">As John said before, a nice </span><span class="line" data-startTime="1764">feature of libvpx is the most </span><span class="line" data-startTime="1768">part, most of your applications, </span><span class="line" data-startTime="1768">you don't have </span><span class="line" data-startTime="1771">to change the other settings. </span> <span class="line" data-startTime="1773">The defaults will be fine for </span><span class="line" data-startTime="1773">95% of the applications. </span> <span class="line" data-startTime="1777">If you do have a very specific </span><span class="line" data-startTime="1777">need, there are other options </span><span class="line" data-startTime="1781">like if you need to set the key </span><span class="line" data-startTime="1781">frame target, if you have </span><span class="line" data-startTime="1784">certain seeking requirements or </span><span class="line" data-startTime="1784">maybe the quantizer values, </span><span class="line" data-startTime="1788">depending if you want to not go </span><span class="line" data-startTime="1788">too high- the bit rate to </span><span class="line" data-startTime="1792">not go too high or go too low. </span> <span class="line" data-startTime="1794">But for the most part, you set </span><span class="line" data-startTime="1794">the target bit rate, and </span><span class="line" data-startTime="1796">everything else is fine. </span> <span class="line" data-startTime="1799">Here I'm just creating the </span><span class="line" data-startTime="1799">Vorbis configure object for </span><span class="line" data-startTime="1802">passing in a number of channels, </span><span class="line" data-startTime="1802">sample rate, bits </span><span class="line" data-startTime="1805">per sample of the audio. </span></p>

<p><span class="line" data-startTime="1807">It's pretty easy. </span> <span class="line" data-startTime="1811">This code is setting the time </span><span class="line" data-startTime="1811">base for both the VP8 encoder </span><span class="line" data-startTime="1815">and the Vorbis encoder. </span> <span class="line" data-startTime="1817">This is really a convenience </span><span class="line" data-startTime="1817">function because the muxer, </span><span class="line" data-startTime="1821">the WebM expects the time base </span><span class="line" data-startTime="1821">to be nanosecond units. </span> <span class="line" data-startTime="1826">And the only reason we're doing </span><span class="line" data-startTime="1826">this is that we don't </span><span class="line" data-startTime="1827">have to translate the </span><span class="line" data-startTime="1827">time stamps later. </span> <span class="line" data-startTime="1831">If you didn't do this, the video </span><span class="line" data-startTime="1831">default time base is </span><span class="line" data-startTime="1834">milliseconds, and the audio </span><span class="line" data-startTime="1834">default time base is samples </span><span class="line" data-startTime="1837">per second. </span> <span class="line" data-startTime="1840">Oop &mdash; </span><span class="line" data-startTime="1840">a nanoseconds unit. </span></p>

<p><span class="line" data-startTime="1843">Here, we're just creating </span><span class="line" data-startTime="1843">the encoder and </span><span class="line" data-startTime="1846">passing config objects &mdash; </span><span class="line" data-startTime="1847">config fig objects &mdash; </span><span class="line" data-startTime="1848">very simple. </span> <span class="line" data-startTime="1850">At this point, both the </span><span class="line" data-startTime="1850">VP8 and the Vorbis </span><span class="line" data-startTime="1854">encoder are set up. </span> <span class="line" data-startTime="1855">They're ready to start </span><span class="line" data-startTime="1855">encoding data. </span> <span class="line" data-startTime="1857">The next two lines are </span><span class="line" data-startTime="1857">setting up the muxer. </span> <span class="line" data-startTime="1860">The first line is we're creating </span><span class="line" data-startTime="1860">a writer object. </span> <span class="line" data-startTime="1864">And basically what that is is </span><span class="line" data-startTime="1864">it implements a very simple </span><span class="line" data-startTime="1868">I/O interface. </span> <span class="line" data-startTime="1869">So if your application had </span><span class="line" data-startTime="1869">different I/O needs, maybe you </span><span class="line" data-startTime="1874">had a packed file, whatever it </span><span class="line" data-startTime="1874">is, you can create your own </span><span class="line" data-startTime="1877">writer object that implements </span><span class="line" data-startTime="1877">the MPAV writer interface. </span></p>

<p><span class="line" data-startTime="1881">And you pass that </span><span class="line" data-startTime="1881">to the muxer. </span> <span class="line" data-startTime="1884">They did the default </span><span class="line" data-startTime="1884">writer interface &mdash; </span><span class="line" data-startTime="1885">just uses the standard I/O, </span><span class="line" data-startTime="1885">f-open, f-write, f-close. </span> <span class="line" data-startTime="1892">Here we're telling it the file </span><span class="line" data-startTime="1892">to write to, just a string, a </span><span class="line" data-startTime="1897">path and a file name output. </span> <span class="line" data-startTime="1901">And if you're writing to </span><span class="line" data-startTime="1901">external storage in the </span><span class="line" data-startTime="1905">device, you just have to make </span><span class="line" data-startTime="1905">sure that you set the correct </span><span class="line" data-startTime="1907">permission on your Android </span><span class="line" data-startTime="1907">application. </span> <span class="line" data-startTime="1909">Otherwise it won't work, and </span><span class="line" data-startTime="1909">it might get a little </span><span class="line" data-startTime="1911">confusing as to why </span><span class="line" data-startTime="1911">it's not working. </span> <span class="line" data-startTime="1912">But there it is right there. </span> <span class="line" data-startTime="1917">Here we're just creating </span><span class="line" data-startTime="1917">the muxer object </span><span class="line" data-startTime="1918">passing in the writer. </span></p>

<p><span class="line" data-startTime="1921">Now we're adding the audio </span><span class="line" data-startTime="1921">and video track. </span> <span class="line" data-startTime="1925">We save the track numbers </span><span class="line" data-startTime="1925">for later. </span> <span class="line" data-startTime="1928">This is how the muxer </span><span class="line" data-startTime="1928">distinguishes between the </span><span class="line" data-startTime="1929">different tracks is you pass </span><span class="line" data-startTime="1929">it the track number. </span> <span class="line" data-startTime="1933">The first two parameters are </span><span class="line" data-startTime="1933">both pretty self-explanatory, </span><span class="line" data-startTime="1936">same as the config objects. </span> <span class="line" data-startTime="1938">The third parameter to the ad </span><span class="line" data-startTime="1938">track is if you explicitly </span><span class="line" data-startTime="1942">need to set a track number. </span> <span class="line" data-startTime="1945">For most applications, </span><span class="line" data-startTime="1945">you won't need it. </span> <span class="line" data-startTime="1947">Passing in zero to libwebm </span><span class="line" data-startTime="1947">says you pick the number. </span> <span class="line" data-startTime="1952">I'm OK with that. </span> <span class="line" data-startTime="1955">And the last part of this set up </span><span class="line" data-startTime="1955">for the muxer is the Vorbis </span><span class="line" data-startTime="1959">audio needs some private data. </span> <span class="line" data-startTime="1963">So you have to set the codec </span><span class="line" data-startTime="1963">private, which is basically </span><span class="line" data-startTime="1965">what it says. </span> <span class="line" data-startTime="1967">It's data that's only </span><span class="line" data-startTime="1967">interpreted by the codec. </span></p>

<p><span class="line" data-startTime="1971">Again, if you use the Vorbis </span><span class="line" data-startTime="1971">encoder from the orange boxes, </span><span class="line" data-startTime="1974">it makes it pretty simple. </span> <span class="line" data-startTime="1975">You call codec private. </span> <span class="line" data-startTime="1977">It'll return the data in the </span><span class="line" data-startTime="1977">correct format, you set it, </span><span class="line" data-startTime="1981">and you're good to go. </span> <span class="line" data-startTime="1984">So at this point, everything's </span><span class="line" data-startTime="1984">set up. </span> <span class="line" data-startTime="1985">And now we're getting into </span><span class="line" data-startTime="1985">our encoding loop. </span> <span class="line" data-startTime="1989">I kind of have some </span><span class="line" data-startTime="1989">pseudo-code. </span> <span class="line" data-startTime="1990">I just say get the raw frame. </span> <span class="line" data-startTime="1992">The audio &mdash; </span><span class="line" data-startTime="1995">the raw data is just an array </span><span class="line" data-startTime="1995">of PCM samples per &mdash; libvpx, </span><span class="line" data-startTime="2001">the raw data is an I420 </span><span class="line" data-startTime="2001">or YV12 frame. </span> <span class="line" data-startTime="2005">I'll talk a little bit more </span><span class="line" data-startTime="2005">about color formats when we </span><span class="line" data-startTime="2008">get to the encode call. </span></p>

<p><span class="line" data-startTime="2010">If the raw data is audio, </span><span class="line" data-startTime="2010">it's pretty simple. </span> <span class="line" data-startTime="2016">We just call encode, give </span><span class="line" data-startTime="2016">it the raw data. </span> <span class="line" data-startTime="2019">Then we get the compress </span><span class="line" data-startTime="2019">frame. </span> <span class="line" data-startTime="2022">I see I'm getting close on time, </span><span class="line" data-startTime="2022">so I'll try to go quick. </span> <span class="line" data-startTime="2027">For Vorbis, you had to check to </span><span class="line" data-startTime="2027">make sure the encoded frame </span><span class="line" data-startTime="2030">is not null, because Vorbis </span><span class="line" data-startTime="2030">needs a certain amount of </span><span class="line" data-startTime="2034">input samples before </span><span class="line" data-startTime="2034">it'll start passing </span><span class="line" data-startTime="2036">back encoded data. </span></p>

<p><span class="line" data-startTime="2038">First parameter is the </span><span class="line" data-startTime="2038">encoded frame. </span> <span class="line" data-startTime="2041">Second parameter is the </span><span class="line" data-startTime="2041">track number that </span><span class="line" data-startTime="2042">we passed back before. </span> <span class="line" data-startTime="2044">Time stamp, already in the </span><span class="line" data-startTime="2044">correct time base. </span> <span class="line" data-startTime="2047">And the last parameter is a </span><span class="line" data-startTime="2047">flag, a boolean saying if it's </span><span class="line" data-startTime="2050">a key frame or not. </span> <span class="line" data-startTime="2052">All Vorbis audio frames </span><span class="line" data-startTime="2052">are key frames. </span> <span class="line" data-startTime="2056">It's video. </span> <span class="line" data-startTime="2057">Again, we pass the encode </span><span class="line" data-startTime="2057">frame I420. </span> <span class="line" data-startTime="2060">We also have another function </span><span class="line" data-startTime="2060">call, because libvpx will only </span><span class="line" data-startTime="2064">take I420 or YB12. </span> <span class="line" data-startTime="2066">But the libvpx wrapper will take </span><span class="line" data-startTime="2066">some RGB color space as </span><span class="line" data-startTime="2070">well as some other </span><span class="line" data-startTime="2070">YUV color spaces. </span> <span class="line" data-startTime="2072">And what it'll do is it'll get </span><span class="line" data-startTime="2072">the raw frames, send it to </span><span class="line" data-startTime="2077">libyuv to convert it to I420 </span><span class="line" data-startTime="2077">and then send it to libvpx. </span></p>

<p><span class="line" data-startTime="2080">Time stamp duration has to </span><span class="line" data-startTime="2080">be in time stamp units. </span> <span class="line" data-startTime="2085">The libvpx encode </span><span class="line" data-startTime="2085">frame returns an </span><span class="line" data-startTime="2087">array of encoded packets. </span> <span class="line" data-startTime="2088">This is because the libvpx </span><span class="line" data-startTime="2088">encoder can create what we </span><span class="line" data-startTime="2092">call altref frame, which is </span><span class="line" data-startTime="2092">basically a frame that must be </span><span class="line" data-startTime="2096">decoded in order </span><span class="line" data-startTime="2096">but not shown. </span> <span class="line" data-startTime="2099">We loop through the array </span><span class="line" data-startTime="2099">of encoded packets. </span> <span class="line" data-startTime="2104">The only real difference </span><span class="line" data-startTime="2104">at the end &mdash; </span><span class="line" data-startTime="2106">we check to see if the libvpx </span><span class="line" data-startTime="2106">packet is a key frame. </span> <span class="line" data-startTime="2110">Then we pass that. </span> <span class="line" data-startTime="2112">Oop &mdash; hit the wrong button. </span> <span class="line" data-startTime="2114">And finally we tell the muxer </span><span class="line" data-startTime="2114">segment to finalize the </span><span class="line" data-startTime="2117">segment which basically will </span><span class="line" data-startTime="2117">output seek points if you want </span><span class="line" data-startTime="2120">then, which by default </span><span class="line" data-startTime="2120">was yes. </span></p>

<p><span class="line" data-startTime="2123">And it will also seek back to </span><span class="line" data-startTime="2123">the beginning and update </span><span class="line" data-startTime="2125">header values so the file </span><span class="line" data-startTime="2125">will be playable. </span> <span class="line" data-startTime="2130">John, you want to go to &mdash; </span></p>

<p class="speaker"><span class="line" data-starttime="2133"><span class="speakerName">John Luther</span>: Why don't </span><span class="line" data-startTime="2133">you do your slides? </span><span class="line" data-startTime="2134">I'll do the YouTube demo, </span><span class="line" data-startTime="2134">because it can </span><span class="line" data-startTime="2136">take a little while. </span> <span class="line" data-startTime="2157">Anyway, this is where you </span><span class="line" data-startTime="2157">can download this stuff. </span> <span class="line" data-startTime="2161">I'm just going to talk very </span><span class="line" data-startTime="2161">briefly about VP9, which is </span><span class="line" data-startTime="2163">our next generation codec. </span> <span class="line" data-startTime="2166">It's also free, open. </span> <span class="line" data-startTime="2168">We don't charge any </span><span class="line" data-startTime="2168">money for it. </span> <span class="line" data-startTime="2172">The big point with </span><span class="line" data-startTime="2172">VP9 is shhhh. </span> <span class="line" data-startTime="2177">He uses the same quality as </span><span class="line" data-startTime="2177">VP8 and H.264 high profile </span><span class="line" data-startTime="2181">using up to half the data. </span></p>

<p><span class="line" data-startTime="2183">Saw it during the keynote. </span> <span class="line" data-startTime="2184">Linus Upson demonstrated VP9 </span><span class="line" data-startTime="2184">playing side by side with a </span><span class="line" data-startTime="2188">264 video and you could </span><span class="line" data-startTime="2188">see that the 264 </span><span class="line" data-startTime="2192">data rate was up here. </span> <span class="line" data-startTime="2193">VP9 was about half. </span> <span class="line" data-startTime="2195">This'll start rolling </span><span class="line" data-startTime="2195">out in YouTube and </span><span class="line" data-startTime="2196">Chrome in Q3 of 2013. </span> <span class="line" data-startTime="2199">We're getting pretty aggressive </span><span class="line" data-startTime="2199">about rolling this </span><span class="line" data-startTime="2201">out, because everybody involved </span><span class="line" data-startTime="2201">is pretty excited </span><span class="line" data-startTime="2205">about the data savings. </span> <span class="line" data-startTime="2207">Bandwidth is still extremely </span><span class="line" data-startTime="2207">expensive business cost. </span> <span class="line" data-startTime="2212">People keep thinking that it's </span><span class="line" data-startTime="2212">free or that it's going to </span><span class="line" data-startTime="2214">become cheaper, but </span><span class="line" data-startTime="2214">it never does. </span> <span class="line" data-startTime="2217">So anyway, there was a </span><span class="line" data-startTime="2217">session yesterday. </span></p>

<p><span class="line" data-startTime="2219">You can watch the video on </span><span class="line" data-startTime="2219">YouTube later or download the </span><span class="line" data-startTime="2222">slides from that. </span> <span class="line" data-startTime="2223">And that's all I'm going </span><span class="line" data-startTime="2223">to say on VP9. </span> <span class="line" data-startTime="2224">You all get to the really </span><span class="line" data-startTime="2224">exciting demo. </span></p>

<p class="speaker"><span class="line" data-starttime="2226"><span class="speakerName">Frank Galligan</span>: Right. </span><span class="line" data-startTime="2232">So the YouTube demo, it captured </span><span class="line" data-startTime="2232">video and audio from </span><span class="line" data-startTime="2238">the camera and the microphone, </span><span class="line" data-startTime="2238">press in real time, then </span><span class="line" data-startTime="2241">uploaded to YouTube. </span><span class="line" data-startTime="2242">Just looking at it, wait </span><span class="line" data-startTime="2242">and processing. </span><span class="line" data-startTime="2244">If it comes up, maybe </span><span class="line" data-startTime="2244">we can play it. </span><span class="line" data-startTime="2246">Otherwise we can take some </span><span class="line" data-startTime="2246">really, really quick </span><span class="line" data-startTime="2248">questions, if anybody has any. </span><span class="line" data-startTime="2253">Just step up to the mike. </span><span class="line" data-startTime="2255">And then we'll also have </span><span class="line" data-startTime="2255">Q&A afterwards too. </span></p>

<p class="speaker"><span class="line" data-starttime="2258"><span class="speakerName">John Luther</span>: Yeah, you can </span><span class="line" data-startTime="2258">find us afterwards. </span></p>

<p class="speaker"><span class="line" data-starttime="2259"><span class="speakerName">Audience</span>: Glad to hear you </span><span class="line" data-startTime="2259">guys are from OnTo. </span><span class="line" data-startTime="2261">I actually used the OnTo encoder </span><span class="line" data-startTime="2261">probably a decade ago </span><span class="line" data-startTime="2263">to do some video for web. </span><span class="line" data-startTime="2265">Great quality at the time. </span><span class="line" data-startTime="2266">A question for you is for </span><span class="line" data-startTime="2266">people that are video </span><span class="line" data-startTime="2270">producers, is it easy to </span><span class="line" data-startTime="2270">integrate the encoder into </span><span class="line" data-startTime="2275">something like Sony Vegas on the </span><span class="line" data-startTime="2275">PC or whatever's commonly </span><span class="line" data-startTime="2278">used on the Mac? </span></p>

<p class="speaker"><span class="line" data-starttime="2279"><span class="speakerName">John Luther</span>: We have DirectShow </span><span class="line" data-startTime="2279">and QuickTime </span><span class="line" data-startTime="2282">components for the encoder and </span><span class="line" data-startTime="2282">decoder that plug into pretty </span><span class="line" data-startTime="2285">much all those tools. </span></p>

<p class="speaker"><span class="line" data-starttime="2288"><span class="speakerName">Audience</span>: Hi. </span><span class="line" data-startTime="2289">I'm a computer engineer. </span><span class="line" data-startTime="2290">And for us, it's always beat </span><span class="line" data-startTime="2290">into us that there's </span><span class="line" data-startTime="2292">always a trade off. </span><span class="line" data-startTime="2293">And when you guys are talking </span><span class="line" data-startTime="2293">about this, you're saying it's </span><span class="line" data-startTime="2295">low CP utilization, very good </span><span class="line" data-startTime="2295">compression ratio, and it </span><span class="line" data-startTime="2298">still looks as good. </span><span class="line" data-startTime="2299">It makes me wonder like </span><span class="line" data-startTime="2299">what's the catch? </span><span class="line" data-startTime="2301">And if there isn't, why isn't </span><span class="line" data-startTime="2301">there one and why have all the </span><span class="line" data-startTime="2304">previous ones failed to do </span><span class="line" data-startTime="2304">it as good as this has. </span></p>

<p class="speaker"><span class="line" data-starttime="2308"><span class="speakerName">Frank Galligan</span>: There's </span><span class="line" data-startTime="2308">no catch. </span><span class="line" data-startTime="2310">I mean, encoding </span><span class="line" data-startTime="2310">video is a very </span><span class="line" data-startTime="2312">expensive operation, right? </span><span class="line" data-startTime="2314">So when we say it's </span><span class="line" data-startTime="2314">low quality &mdash; </span><span class="line" data-startTime="2319">I mean, it's high quality, </span><span class="line" data-startTime="2319">Low CPU &mdash; </span><span class="line" data-startTime="2321">it's compared to what the </span><span class="line" data-startTime="2321">other current codec is. </span></p>

<p class="speaker"><span class="line" data-starttime="2324"><span class="speakerName">John Luther</span>: Right. </span> <span class="line" data-startTime="2325">And the other thing is you are </span><span class="line" data-startTime="2325">losing something in that the </span><span class="line" data-startTime="2329">raw source has everything. </span> <span class="line" data-startTime="2331">Even like I said, that stuff </span><span class="line" data-startTime="2331">that your eye can't even see. </span> <span class="line" data-startTime="2334">So throw all that out. </span> <span class="line" data-startTime="2336">Like in editing bays, and people </span><span class="line" data-startTime="2336">who do pre-production, </span><span class="line" data-startTime="2339">they keep lost lists versions of </span><span class="line" data-startTime="2339">files around to do editing. </span> <span class="line" data-startTime="2343">But then once it's encoded, </span><span class="line" data-startTime="2343">there's so much in that you </span><span class="line" data-startTime="2346">just really &mdash; </span><span class="line" data-startTime="2347">for the human eye to see </span><span class="line" data-startTime="2347">or anything else, you </span><span class="line" data-startTime="2350">just don't need it. </span></p>

<p class="speaker"><span class="line" data-starttime="2352"><span class="speakerName">Audience</span>: Thank you. </span></p>

<p class="speaker"><span class="line" data-starttime="2353"><span class="speakerName">Frank Galligan</span>: Here. </span><span class="line" data-startTime="2354">I think this is what we took, </span><span class="line" data-startTime="2354">so hopefully, it'll &mdash; </span></p>

<p class="speaker"><span class="line" data-starttime="2357"><span class="speakerName">John Luther</span>: Aaww. </span><span class="line" data-startTime="2357">There's a kitty. </span></p>

<p class="speaker"><span class="line" data-starttime="2359"><span class="speakerName">Frank Galligan</span>: So we had a </span><span class="line" data-startTime="2359">little Easter egg, too. </span><span class="line" data-startTime="2361">We had to show this little cat </span><span class="line" data-startTime="2361">that we overlaid on the video </span><span class="line" data-startTime="2364">that we upload to encode. </span></p>

<p class="speaker"><span class="line" data-starttime="2367"><span class="speakerName">Audience</span>: [APPLAUSE] </span></p>

<p class="speaker"><span class="line" data-starttime="2371"><span class="speakerName">John Luther</span>: I think we could </span><span class="line" data-startTime="2371">do one more question. </span><span class="line" data-startTime="2374">There's also hats. </span><span class="line" data-startTime="2375">It wouldn't be I/O </span><span class="line" data-startTime="2375">without swag. </span><span class="line" data-startTime="2377">So anybody who wants a free hat </span><span class="line" data-startTime="2377">with a handsome WebM logo, </span><span class="line" data-startTime="2380">see me afterwards. </span><span class="line" data-startTime="2381">Sorry, go ahead. </span></p>

<p class="speaker"><span class="line" data-starttime="2382"><span class="speakerName">Audience</span>: Hi, name </span><span class="line" data-startTime="2382">is Mauricio. </span><span class="line" data-startTime="2383">I like to know you see VP8 and </span><span class="line" data-startTime="2383">VP9 being used for video </span><span class="line" data-startTime="2387">calling in mobile devices. </span><span class="line" data-startTime="2389">FRANK GALLIGAN: </span><span class="line" data-startTime="2389">Video-conferencing? </span></p>

<p class="speaker"><span class="line" data-starttime="2392"><span class="speakerName">Audience</span>: Used for </span><span class="line" data-startTime="2392">videocalling from mobile devices. </span><span class="line" data-startTime="2394">Either VP8 or VP9. </span></p>

<p class="speaker"><span class="line" data-starttime="2396"><span class="speakerName">John Luther</span>: I mean, part </span><span class="line" data-startTime="2396">of the webRTC &mdash; </span><span class="line" data-startTime="2399">are you familiar with WebRTC? </span><span class="line" data-startTime="2401">We're trying to recommend it </span><span class="line" data-startTime="2401">or we have as a mandatory </span><span class="line" data-startTime="2406">implement code for WebRTC. </span><span class="line" data-startTime="2407">It's what you were using with </span><span class="line" data-startTime="2407">our WebRTC at Google. </span><span class="line" data-startTime="2411">It's one of things that &mdash; </span><span class="line" data-startTime="2412">we had so little time. </span><span class="line" data-startTime="2414">I had an earlier draft of these </span><span class="line" data-startTime="2414">gone into why VP is also </span><span class="line" data-startTime="2418">a very, very good codec, maybe </span><span class="line" data-startTime="2418">in some ways better than for </span><span class="line" data-startTime="2422">visual, for video on demand. </span><span class="line" data-startTime="2423">Its real time capabilities for </span><span class="line" data-startTime="2423">RTC are pretty amazing. </span><span class="line" data-startTime="2427">So the answer is yes. </span></p>

<p class="speaker"><span class="line" data-starttime="2430"><span class="speakerName">Audience</span>: So on the same line, </span><span class="line" data-startTime="2430">one of the great things about </span><span class="line" data-startTime="2432">the opus codec, which you </span><span class="line" data-startTime="2432">mentioned is coming in WebM, </span><span class="line" data-startTime="2435">is its real time performance. </span><span class="line" data-startTime="2436">It's very, very low latency. </span><span class="line" data-startTime="2438">What kind of latencies can you </span><span class="line" data-startTime="2438">achieve with VP8 or VP9. </span></p>

<p class="speaker"><span class="line" data-starttime="2443"><span class="speakerName">Frank Galligan</span>: Well, VP8, you </span><span class="line" data-startTime="2443">can achieve some frame &mdash; so </span><span class="line" data-startTime="2445">one frame latency. </span></p>

<p class="speaker"><span class="line" data-starttime="2447"><span class="speakerName">Audience</span>: So like like 8, </span><span class="line" data-startTime="2447">9, 10 milliseconds. </span></p>

<p class="speaker"><span class="line" data-starttime="2450"><span class="speakerName">Frank Galligan</span>: Yeah. </span><span class="line" data-startTime="2450">I mean, it depends </span><span class="line" data-startTime="2450">on your options. </span><span class="line" data-startTime="2452">Whatever options you pick, </span><span class="line" data-startTime="2452">we try to keep it like 30 </span><span class="line" data-startTime="2457">milliseconds or whatever. </span><span class="line" data-startTime="2458">Maybe one frame latency. </span><span class="line" data-startTime="2460">You can always turn off your </span><span class="line" data-startTime="2460">options to get it to 8, 9, 10 </span><span class="line" data-startTime="2465">milliseconds latency. </span><span class="line" data-startTime="2465">But then your quality might </span><span class="line" data-startTime="2465">not be as good. </span></p>

<p class="speaker"><span class="line" data-starttime="2467"><span class="speakerName">Audience</span>: Right. </span></p>

<p class="speaker"><span class="line" data-starttime="2467"><span class="speakerName">Frank Galligan</span>: So we try to </span><span class="line" data-startTime="2467">keep it to one-frame latency. </span><span class="line" data-startTime="2471">VP9 &mdash; </span><span class="line" data-startTime="2472">we'll still working on it, but </span><span class="line" data-startTime="2472">we have the same target when </span><span class="line" data-startTime="2475">it comes out. </span><span class="line" data-startTime="2476">I think it's Q3 or </span><span class="line" data-startTime="2476">4 this year. </span></p>

<p class="speaker"><span class="line" data-starttime="2479"><span class="speakerName">John Luther</span>: Q3. </span><span class="line" data-startTime="2479">I mean, the bitstream is &mdash; </span></p>

<p class="speaker"><span class="line" data-starttime="2480"><span class="speakerName">Frank Galligan</span>: For real time. </span></p>

<p class="speaker"><span class="line" data-starttime="2481"><span class="speakerName">John Luther</span>: The bitstream </span><span class="line" data-startTime="2481">will be frozen in June. </span><span class="line" data-startTime="2483">And then &mdash; </span></p>

<p class="speaker"><span class="line" data-starttime="2484"><span class="speakerName">Frank Galligan</span>: Yeah, for </span><span class="line" data-startTime="2484">real times, it's Q &mdash; </span></p>

<p class="speaker"><span class="line" data-starttime="2486"><span class="speakerName">John Luther</span>: For real time, I'm </span><span class="line" data-startTime="2486">sorry, Q4, yeah, when we </span><span class="line" data-startTime="2488">build it in real time. </span><span class="line" data-startTime="2490">They keep giving us more time. </span><span class="line" data-startTime="2492">It's like it's running backwards </span><span class="line" data-startTime="2492">or something. </span><span class="line" data-startTime="2494">So anyway, it you want a </span><span class="line" data-startTime="2494">hat, come and see us. </span><span class="line" data-startTime="2497">If you have any other questions, </span><span class="line" data-startTime="2497">feel free. </span></p>

<p class="speaker"><span class="line" data-starttime="2498"><span class="speakerName">Frank Galligan</span>: And </span><span class="line" data-startTime="2498">we'll be out. </span><span class="line" data-startTime="2499">And it's online. </span></p>

<p class="speaker"><span class="line" data-starttime="2500"><span class="speakerName">John Luther</span>: We'll be </span><span class="line" data-startTime="2500">out in the booth. </span><span class="line" data-startTime="2501">So thanks everybody. </span></p>

<p class="speaker"><span class="line" data-starttime="2502"><span class="speakerName">Frank Galligan</span>: Thank you. </span></p></div>