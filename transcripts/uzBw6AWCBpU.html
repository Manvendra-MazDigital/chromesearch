<p class="speaker"><span class="line" data-starttime="1"><span class="speakerName">Tim Murray</span>: All right. </span> <span class="line" data-startTime="2">Good morning, everyone. </span> <span class="line" data-startTime="3">My name is Tim Murray. </span> <span class="line" data-startTime="4">I'm an engineer at Google on </span><span class="line" data-startTime="4">the RenderScript team. </span> <span class="line" data-startTime="7">And we're here to talk about </span><span class="line" data-startTime="7">writing high performance </span><span class="line" data-startTime="9">applications with </span><span class="line" data-startTime="9">RenderScript. </span> <span class="line" data-startTime="13">So first, I'd like to talk </span><span class="line" data-startTime="13">about GPUs in general. </span> <span class="line" data-startTime="17">So in the past seven years or </span><span class="line" data-startTime="17">so, GPUs have become useful </span><span class="line" data-startTime="21">for a lot more applications </span><span class="line" data-startTime="21">than </span><span class="line" data-startTime="23">just traditional graphics. </span> <span class="line" data-startTime="25">And the reason for this is that </span><span class="line" data-startTime="25">they have a lot of flops </span><span class="line" data-startTime="28">and a lot of memory bandwidth </span><span class="line" data-startTime="28">verses CPUs. </span> <span class="line" data-startTime="31">And so they're really good at </span><span class="line" data-startTime="31">data parallel tasks that </span><span class="line" data-startTime="34">happen to look sort </span><span class="line" data-startTime="34">of like graphics. </span></p>

<p><span class="line" data-startTime="38">And the market where this has </span><span class="line" data-startTime="38">had the most adoption is in </span><span class="line" data-startTime="42">high performance computing, </span><span class="line" data-startTime="42">supercomputing, oil and gas, </span><span class="line" data-startTime="44">things like that. </span> <span class="line" data-startTime="46">The current number one machine </span><span class="line" data-startTime="46">on the top 500 is primarily </span><span class="line" data-startTime="49">GPU based, for example. </span> <span class="line" data-startTime="51">And now in mobile, we're </span><span class="line" data-startTime="51">starting to see these </span><span class="line" data-startTime="54">programmable GPUs arrive </span><span class="line" data-startTime="54">and become useful. </span> <span class="line" data-startTime="58">But before we go into mobile, </span><span class="line" data-startTime="58">I want to talk a little bit </span><span class="line" data-startTime="61">about a traditional </span><span class="line" data-startTime="61">desktop, or server </span><span class="line" data-startTime="65">architecture with a GPU. </span> <span class="line" data-startTime="67">So the first thing you'll notice </span><span class="line" data-startTime="67">is that in terms of raw </span><span class="line" data-startTime="70">computational throughput, </span><span class="line" data-startTime="70">floating point, memory </span><span class="line" data-startTime="74">bandwidth, things like that, </span><span class="line" data-startTime="74">the GPU dominates the CPU. </span> <span class="line" data-startTime="78">It's got four times the </span><span class="line" data-startTime="78">memory bandwidth. </span> <span class="line" data-startTime="79">It's got 10 to 15 times the </span><span class="line" data-startTime="79">flop on a high end GPU. </span> <span class="line" data-startTime="84">However, there's a problem, </span><span class="line" data-startTime="84">and that's </span><span class="line" data-startTime="86">the PCI express bus. </span></p>

<p><span class="line" data-startTime="88">The PCI express bus is something </span><span class="line" data-startTime="88">that all your data </span><span class="line" data-startTime="91">has to traverse in order to move </span><span class="line" data-startTime="91">from the GPU to the CPU, </span><span class="line" data-startTime="95">or vice versa. </span> <span class="line" data-startTime="97">And compared to the speed of </span><span class="line" data-startTime="97">memory bandwidth on either </span><span class="line" data-startTime="101">device, it's very slow. </span> <span class="line" data-startTime="103">So a lot of the work in porting </span><span class="line" data-startTime="103">an application to the </span><span class="line" data-startTime="106">GPU and desktop comes from </span><span class="line" data-startTime="106">managing this data transfer </span><span class="line" data-startTime="109">overhead, and only moving work </span><span class="line" data-startTime="109">to the GPU when you can </span><span class="line" data-startTime="112">actually amortize the cost of </span><span class="line" data-startTime="112">moving data to the GPU. </span> <span class="line" data-startTime="119">In mobile, things look </span><span class="line" data-startTime="119">very different. </span> <span class="line" data-startTime="121">The first thing you'll notice </span><span class="line" data-startTime="121">is that the GPU and the CPU </span><span class="line" data-startTime="124">are now in the same package. </span> <span class="line" data-startTime="126">They share a single pool </span><span class="line" data-startTime="126">of physical memory. </span> <span class="line" data-startTime="129">So there's no more </span><span class="line" data-startTime="129">PCI express bus. </span> <span class="line" data-startTime="131">That transfer time is gone. </span> <span class="line" data-startTime="133">However, this does mean that </span><span class="line" data-startTime="133">because they share the same </span><span class="line" data-startTime="135">pool of physical memory, the </span><span class="line" data-startTime="135">GPU no longer has a number </span><span class="line" data-startTime="138">bandwidth advantage. </span></p>

<p><span class="line" data-startTime="139">And to further reduce the GPU's </span><span class="line" data-startTime="139">advantage, its floating </span><span class="line" data-startTime="143">point performance relative to </span><span class="line" data-startTime="143">the CPU is now only about </span><span class="line" data-startTime="147">three to four times faster. </span> <span class="line" data-startTime="149">We're not talking 10 to 15 </span><span class="line" data-startTime="149">times faster anymore. </span> <span class="line" data-startTime="152">We also may have additional </span><span class="line" data-startTime="152">processors </span><span class="line" data-startTime="155">available to us in mobile. </span> <span class="line" data-startTime="156">For example, you could have a </span><span class="line" data-startTime="156">camera ISP that can do things </span><span class="line" data-startTime="160">like color space conversion </span><span class="line" data-startTime="160">or basic convolution, or </span><span class="line" data-startTime="163">something like that. </span> <span class="line" data-startTime="165">And you may have a </span><span class="line" data-startTime="165">programmable DSP </span><span class="line" data-startTime="167">on your SoC as well. </span> <span class="line" data-startTime="169">And you may really want to </span><span class="line" data-startTime="169">use these processors when </span><span class="line" data-startTime="173">possible, because they're </span><span class="line" data-startTime="173">relatively fixed function. </span> <span class="line" data-startTime="177">And they may provide very, </span><span class="line" data-startTime="177">very good perf per watt. </span></p>

<p><span class="line" data-startTime="182">So in terms of architecture, </span><span class="line" data-startTime="182">mobile </span><span class="line" data-startTime="185">versus desktop is different. </span> <span class="line" data-startTime="186">And it's different in more </span><span class="line" data-startTime="186">than just the block </span><span class="line" data-startTime="188">diagram ways, too. </span> <span class="line" data-startTime="190">Mobile has a lot of </span><span class="line" data-startTime="190">architectural diversity. </span> <span class="line" data-startTime="193">In desktop you have two CPU </span><span class="line" data-startTime="193">vendors, three GPU vendors. </span> <span class="line" data-startTime="198">In mobile you have </span><span class="line" data-startTime="198">three CPU ISAs. </span> <span class="line" data-startTime="201">Within ARM, you have a number </span><span class="line" data-startTime="201">of different ARM cores and </span><span class="line" data-startTime="205">licensed ARM cores. </span> <span class="line" data-startTime="207">You have dramatically more </span><span class="line" data-startTime="207">GPUs and GPU vendors. </span> <span class="line" data-startTime="212">And particularly within the GPU </span><span class="line" data-startTime="212">space, the architecture of </span><span class="line" data-startTime="216">these GPUs are very different </span><span class="line" data-startTime="216">from one another. </span> <span class="line" data-startTime="221">If you look at a kind of desktop </span><span class="line" data-startTime="221">GPUs, in broad strokes </span><span class="line" data-startTime="224">they look mostly similar. </span></p>

<p><span class="line" data-startTime="226">That's not true in mobile. </span> <span class="line" data-startTime="227">Some of them look very CPU like, </span><span class="line" data-startTime="227">and have very small SIMD </span><span class="line" data-startTime="230">widths, and things like that. </span> <span class="line" data-startTime="232">Others look more like </span><span class="line" data-startTime="232">traditional desktop GPUs, and </span><span class="line" data-startTime="236">then they have very wide </span><span class="line" data-startTime="236">vector widths. </span> <span class="line" data-startTime="239">Others look sort of </span><span class="line" data-startTime="239">like a pool of </span><span class="line" data-startTime="241">fixed function hardware. </span> <span class="line" data-startTime="244">And additionally in mobile, and </span><span class="line" data-startTime="244">you have concerns about </span><span class="line" data-startTime="247">system resources. </span> <span class="line" data-startTime="249">The biggest two there are power </span><span class="line" data-startTime="249">and thermal constraints, </span><span class="line" data-startTime="253">which generally don't affect </span><span class="line" data-startTime="253">you as much on desktop. </span> <span class="line" data-startTime="256">You also have issues like the </span><span class="line" data-startTime="256">GPU may be busy rendering a </span><span class="line" data-startTime="260">lot of pixels. </span></p>

<p><span class="line" data-startTime="261">For example on a Nexux 10, we </span><span class="line" data-startTime="261">have a 2560x1600 display, </span><span class="line" data-startTime="266">which is equivalent to a 30 </span><span class="line" data-startTime="266">inch desktop monitor. </span> <span class="line" data-startTime="269">And we're trying to drive that </span><span class="line" data-startTime="269">on the GPU with 80 gigaflops, </span><span class="line" data-startTime="272">instead of over a teraflop. </span> <span class="line" data-startTime="276">And you may have additional </span><span class="line" data-startTime="276">processors that you want to </span><span class="line" data-startTime="277">use as well. </span> <span class="line" data-startTime="279">So our goal here is really to </span><span class="line" data-startTime="279">develop high performance </span><span class="line" data-startTime="282">applications for these wide </span><span class="line" data-startTime="282">variety of SoCs without </span><span class="line" data-startTime="288">sacrificing performance </span><span class="line" data-startTime="288">portability. </span> <span class="line" data-startTime="289">Without guaranteeing that the </span><span class="line" data-startTime="289">more you optimize for one SoC, </span><span class="line" data-startTime="295">the worse you run on </span><span class="line" data-startTime="295">certain other SoCs. </span> <span class="line" data-startTime="298">So our approach to solving that </span><span class="line" data-startTime="298">is called RenderScript. </span> <span class="line" data-startTime="303">And RenderScript is our platform </span><span class="line" data-startTime="303">for high performance </span><span class="line" data-startTime="305">computing across different </span><span class="line" data-startTime="305">hardware on Android. </span></p>

<p><span class="line" data-startTime="309">So the first thing you'll notice </span><span class="line" data-startTime="309">about the API is that </span><span class="line" data-startTime="312">the API is focused </span><span class="line" data-startTime="312">on the system. </span> <span class="line" data-startTime="313">You don't get a list </span><span class="line" data-startTime="313">of devices. </span> <span class="line" data-startTime="315">You don't get a big collection </span><span class="line" data-startTime="315">of device properties and have </span><span class="line" data-startTime="317">to try to figure out </span><span class="line" data-startTime="317">at run time which </span><span class="line" data-startTime="319">device you should use. </span> <span class="line" data-startTime="321">The runtime handles </span><span class="line" data-startTime="321">that for you. </span> <span class="line" data-startTime="322">You simply have a computation </span><span class="line" data-startTime="322">that you want to run quickly, </span><span class="line" data-startTime="326">and we will try to put that on </span><span class="line" data-startTime="326">the best processor we can. </span> <span class="line" data-startTime="330">What this means is that this </span><span class="line" data-startTime="330">gives developers a consistent </span><span class="line" data-startTime="333">target that will run well </span><span class="line" data-startTime="333">across any SoC. </span> <span class="line" data-startTime="336">We work with the SoC vendors and </span><span class="line" data-startTime="336">get drivers for their GPUs </span><span class="line" data-startTime="341">and DSPs, ISPs, whatever, and </span><span class="line" data-startTime="341">have those available on </span><span class="line" data-startTime="346">tablets and phones. </span> <span class="line" data-startTime="348">And this way, the runtime </span><span class="line" data-startTime="348">knows about whatever </span><span class="line" data-startTime="353">processors and capabilities </span><span class="line" data-startTime="353">it can use. </span> <span class="line" data-startTime="356">It doesn't require the developer </span><span class="line" data-startTime="356">to go in and may </span><span class="line" data-startTime="360">call these decisions at run time </span><span class="line" data-startTime="360">about an SoC it's never </span><span class="line" data-startTime="363">seen before. </span></p>

<p><span class="line" data-startTime="365">We've been influenced by other </span><span class="line" data-startTime="365">data parallel run times, </span><span class="line" data-startTime="369">obviously, but we've kind of </span><span class="line" data-startTime="369">taken things in a very </span><span class="line" data-startTime="372">different direction. </span> <span class="line" data-startTime="376">So at a very high level view, </span><span class="line" data-startTime="376">we do look very similar to </span><span class="line" data-startTime="380">some of these other data </span><span class="line" data-startTime="380">parallel runtimes. </span> <span class="line" data-startTime="383">We write performance </span><span class="line" data-startTime="383">critical kernels </span><span class="line" data-startTime="384">in a C99 based language. </span> <span class="line" data-startTime="388">These kernels are distributed </span><span class="line" data-startTime="388">with your application as </span><span class="line" data-startTime="391">architecture independent </span><span class="line" data-startTime="391">bit code. </span> <span class="line" data-startTime="393">We then JIT compile those at </span><span class="line" data-startTime="393">run time to one or more </span><span class="line" data-startTime="398">processor targets. </span> <span class="line" data-startTime="399">For example, we may compile them </span><span class="line" data-startTime="399">to ARM D7A with Neon, and </span><span class="line" data-startTime="405">we may compile them to, for </span><span class="line" data-startTime="405">example on the Nexus 10, we </span><span class="line" data-startTime="409">have GPU support in </span><span class="line" data-startTime="409">the Mali-T604. </span></p>

<p><span class="line" data-startTime="412">So we may compile to build a </span><span class="line" data-startTime="412">CPU and GPU at run time. </span> <span class="line" data-startTime="417">We also reflect Java classes </span><span class="line" data-startTime="417">for easy integration with </span><span class="line" data-startTime="422">existing applications. </span> <span class="line" data-startTime="423">And what this means is </span><span class="line" data-startTime="423">essentially that every time </span><span class="line" data-startTime="425">you have a RenderScript file, </span><span class="line" data-startTime="425">we generate a set of Java </span><span class="line" data-startTime="430">classes that go with it, so that </span><span class="line" data-startTime="430">you can control execution </span><span class="line" data-startTime="434">of that without relying on </span><span class="line" data-startTime="434">string based APIs, or having </span><span class="line" data-startTime="437">to use JNI, or something </span><span class="line" data-startTime="437">like that. </span> <span class="line" data-startTime="440">We also have kind of standard </span><span class="line" data-startTime="440">resource management and </span><span class="line" data-startTime="443">execution in our Java </span><span class="line" data-startTime="443">API as well. </span> <span class="line" data-startTime="445">One thing I didn't mention </span><span class="line" data-startTime="445">here is we also have a </span><span class="line" data-startTime="447">collection of, they're called </span><span class="line" data-startTime="447">script intrinsics. </span> <span class="line" data-startTime="450">Essentially these are built in, </span><span class="line" data-startTime="450">very fast operations that </span><span class="line" data-startTime="455">we can tune to specific </span><span class="line" data-startTime="455">architectures very well. </span></p>

<p><span class="line" data-startTime="459">And they're things like YUV </span><span class="line" data-startTime="459">conversion, or convolution, </span><span class="line" data-startTime="463">stuff like that. </span> <span class="line" data-startTime="464">Common operations you may use </span><span class="line" data-startTime="464">very often, where you can get </span><span class="line" data-startTime="469">a really significant speedup by </span><span class="line" data-startTime="469">tuning very, very closely </span><span class="line" data-startTime="473">to a particular piece </span><span class="line" data-startTime="473">of hardware. </span> <span class="line" data-startTime="478">So let's go through some basic </span><span class="line" data-startTime="478">RenderScript definitions. </span> <span class="line" data-startTime="481">The first thing to talk </span><span class="line" data-startTime="481">about is the element. </span> <span class="line" data-startTime="484">So an element is essentially </span><span class="line" data-startTime="484">a C type. </span> <span class="line" data-startTime="488">In this case, it's an INT. </span> <span class="line" data-startTime="490">So it can be a scalar type, </span><span class="line" data-startTime="490">like an INT, it could be a </span><span class="line" data-startTime="492">vector type, like an INT4, </span><span class="line" data-startTime="492">Float 4, whatever. </span> <span class="line" data-startTime="496">We can also supports C </span><span class="line" data-startTime="496">structs as elements. </span></p>

<p><span class="line" data-startTime="499">So if you declare a struct in </span><span class="line" data-startTime="499">your RenderScript file, we </span><span class="line" data-startTime="502">will actually reflect an element </span><span class="line" data-startTime="502">class for that, that </span><span class="line" data-startTime="507">will be available to Java. </span> <span class="line" data-startTime="509">So you can use that from </span><span class="line" data-startTime="509">your Java API directly. </span> <span class="line" data-startTime="513">So an element is not very </span><span class="line" data-startTime="513">useful in and of itself. </span> <span class="line" data-startTime="516">So to actually make use of this, </span><span class="line" data-startTime="516">we have allocations. </span> <span class="line" data-startTime="519">And allocations are collections </span><span class="line" data-startTime="519">of a single type </span><span class="line" data-startTime="522">of element in some </span><span class="line" data-startTime="522">arrangement. </span> <span class="line" data-startTime="527">It could be 1D or 2D. </span> <span class="line" data-startTime="529">They have an x and y dimension, </span><span class="line" data-startTime="529">and they have a </span><span class="line" data-startTime="532">backing store. </span> <span class="line" data-startTime="532">And essentially, an allocation </span><span class="line" data-startTime="532">is how you get data from Java </span><span class="line" data-startTime="536">into RenderScript, so </span><span class="line" data-startTime="536">it can be processed </span><span class="line" data-startTime="538">by one or more kernels. </span> <span class="line" data-startTime="542">And an allocation has one other </span><span class="line" data-startTime="542">important aspects, and </span><span class="line" data-startTime="546">that is the type. </span></p>

<p><span class="line" data-startTime="548">And the type is essentially the </span><span class="line" data-startTime="548">size of the allocation, </span><span class="line" data-startTime="552">along with the elements used </span><span class="line" data-startTime="552">within that allocation. </span> <span class="line" data-startTime="557">And we use this for </span><span class="line" data-startTime="557">two things. </span> <span class="line" data-startTime="559">First of all, we use it to do </span><span class="line" data-startTime="559">safety checking on copies and </span><span class="line" data-startTime="565">kernel launches, and things like </span><span class="line" data-startTime="565">that, to make sure that </span><span class="line" data-startTime="568">you don't try to copy an </span><span class="line" data-startTime="568">allocation of floats onto an </span><span class="line" data-startTime="574">allocation of chars, because </span><span class="line" data-startTime="574">it won't fit. </span> <span class="line" data-startTime="577">Or a 5x5 allocation of INTs onto </span><span class="line" data-startTime="577">a 3x3 allocation of INTs, </span><span class="line" data-startTime="583">because it won't fit. </span></p>

<p><span class="line" data-startTime="585">We also do type checking when </span><span class="line" data-startTime="585">we launch kernels, to make </span><span class="line" data-startTime="589">sure that the element type </span><span class="line" data-startTime="589">past tense of the kernel </span><span class="line" data-startTime="592">matches what the </span><span class="line" data-startTime="592">kernel expects. </span> <span class="line" data-startTime="595">The other way we use types is </span><span class="line" data-startTime="595">to control how much parallel </span><span class="line" data-startTime="598">work actually gets launched </span><span class="line" data-startTime="598">by a kernel. </span> <span class="line" data-startTime="601">And we'll get into this </span><span class="line" data-startTime="601">more in a bit. </span> <span class="line" data-startTime="606">So this is a dot RS file, a </span><span class="line" data-startTime="606">very basic dot RS file. </span> <span class="line" data-startTime="610">And in general, we refer to each </span><span class="line" data-startTime="610">one of these dot RS files </span><span class="line" data-startTime="613">as a script. </span> <span class="line" data-startTime="614">And a script is essentially </span><span class="line" data-startTime="614">its own little world. </span> <span class="line" data-startTime="616">There's no linkage between </span><span class="line" data-startTime="616">scripts, or </span><span class="line" data-startTime="618">anything like that. </span> <span class="line" data-startTime="620">So every script is </span><span class="line" data-startTime="620">self-contained. </span> <span class="line" data-startTime="623">And the first thing you'll </span><span class="line" data-startTime="623">notice here is that the script </span><span class="line" data-startTime="626">starts with two pragmas. </span></p>

<p><span class="line" data-startTime="627">First we have the RS </span><span class="line" data-startTime="627">language revision. </span> <span class="line" data-startTime="631">For now it's one. </span> <span class="line" data-startTime="632">It will be one for the </span><span class="line" data-startTime="632">foreseeable future. </span> <span class="line" data-startTime="634">After that, we have a </span><span class="line" data-startTime="634">Java package name. </span> <span class="line" data-startTime="638">And this is the package name </span><span class="line" data-startTime="638">that we use for the reflected </span><span class="line" data-startTime="641">classes from this script. </span> <span class="line" data-startTime="644">After that we have what looks </span><span class="line" data-startTime="644">like a normal C99 global. </span> <span class="line" data-startTime="647">We call that a script </span><span class="line" data-startTime="647">global because it is </span><span class="line" data-startTime="649">local to the script. </span> <span class="line" data-startTime="651">And this will reflect a method </span><span class="line" data-startTime="651">called set add val, which </span><span class="line" data-startTime="655">takes an INT to Java. </span></p>

<p><span class="line" data-startTime="657">So if you want to update this </span><span class="line" data-startTime="657">add val global from Java, you </span><span class="line" data-startTime="661">can do that. </span> <span class="line" data-startTime="663">After that we have a kernel, and </span><span class="line" data-startTime="663">this kernel looks mostly </span><span class="line" data-startTime="667">like a standard C99 function, </span><span class="line" data-startTime="667">except it has this decorator </span><span class="line" data-startTime="671">attribute kernel. </span> <span class="line" data-startTime="672">An attribute kernel is the new </span><span class="line" data-startTime="672">kernel syntax we introduced in </span><span class="line" data-startTime="676">API 17, and I highly recommend </span><span class="line" data-startTime="676">you use that. </span> <span class="line" data-startTime="679">And essentially what this means </span><span class="line" data-startTime="679">is the kernel has an </span><span class="line" data-startTime="682">input value and an output. </span> <span class="line" data-startTime="685">Or an input type and </span><span class="line" data-startTime="685">an output type. </span> <span class="line" data-startTime="687">And here the input type is an </span><span class="line" data-startTime="687">INT, so we get an INT in. </span> <span class="line" data-startTime="692">And then we also get two UINT </span><span class="line" data-startTime="692">32Ts, x and y, which are </span><span class="line" data-startTime="697">coordinates within </span><span class="line" data-startTime="697">the allocation. </span> <span class="line" data-startTime="700">And this function returns an </span><span class="line" data-startTime="700">INT, so essentially what </span><span class="line" data-startTime="703">happens is when we run this </span><span class="line" data-startTime="703">kernel on a given allocation, </span><span class="line" data-startTime="708">for every element in the </span><span class="line" data-startTime="708">allocation, this function will </span><span class="line" data-startTime="712">be executed. </span></p>

<p><span class="line" data-startTime="713">And so at every particular </span><span class="line" data-startTime="713">coordinate pair in the </span><span class="line" data-startTime="719">allocation, the value of that </span><span class="line" data-startTime="719">element at that location will </span><span class="line" data-startTime="723">be passed to this function. </span> <span class="line" data-startTime="725">And then the return value from </span><span class="line" data-startTime="725">this function will be written </span><span class="line" data-startTime="728">to the output application. </span> <span class="line" data-startTime="730">So because this kernel has both </span><span class="line" data-startTime="730">an in argument and a non </span><span class="line" data-startTime="735">void return type, it reflects </span><span class="line" data-startTime="735">a method called for each </span><span class="line" data-startTime="739">underscore kernel. </span> <span class="line" data-startTime="740">Just kernel here because that's </span><span class="line" data-startTime="742">the name of the function. </span> <span class="line" data-startTime="743">And for each kernel takes two </span><span class="line" data-startTime="743">allocations, an input </span><span class="line" data-startTime="748">allocation and an output </span><span class="line" data-startTime="748">application. </span> <span class="line" data-startTime="750">If you didn't have INT in and </span><span class="line" data-startTime="750">you simply had x and y, it </span><span class="line" data-startTime="755">would only take the </span><span class="line" data-startTime="755">output allocation. </span> <span class="line" data-startTime="757">And similarly, if it didn't </span><span class="line" data-startTime="757">return an INT, but simply </span><span class="line" data-startTime="761">returned void, it would not </span><span class="line" data-startTime="761">need an output allocation. </span> <span class="line" data-startTime="768">So I want to talk a little bit </span><span class="line" data-startTime="768">about a more complicated part </span><span class="line" data-startTime="773">of the API where you can do </span><span class="line" data-startTime="773">more advanced things. </span></p>

<p><span class="line" data-startTime="777">And that is called </span><span class="line" data-startTime="777">us script group. </span> <span class="line" data-startTime="779">And a script group allows </span><span class="line" data-startTime="779">a group of kernels to be </span><span class="line" data-startTime="782">executed as a single </span><span class="line" data-startTime="782">Java call. </span> <span class="line" data-startTime="785">More specifically, this allows </span><span class="line" data-startTime="785">a dag of kernels to be </span><span class="line" data-startTime="788">executed as a single </span><span class="line" data-startTime="788">function call. </span> <span class="line" data-startTime="791">And by passing this entire </span><span class="line" data-startTime="791">workload to the driver as one </span><span class="line" data-startTime="797">monolithic entity before we </span><span class="line" data-startTime="797">actually run any part of that </span><span class="line" data-startTime="800">workload, we can enable </span><span class="line" data-startTime="800">all sorts of different </span><span class="line" data-startTime="804">optimizations in the run time, </span><span class="line" data-startTime="804">and in the compiler. </span> <span class="line" data-startTime="808">For example, we can actually </span><span class="line" data-startTime="808">enable, like, parallel </span><span class="line" data-startTime="811">execution across devices, or </span><span class="line" data-startTime="811">tiling, kernel fusion, which </span><span class="line" data-startTime="814">we'll get into in a minute. </span> <span class="line" data-startTime="816">We actually see some significant </span><span class="line" data-startTime="816">speed improvements </span><span class="line" data-startTime="820">today by using script </span><span class="line" data-startTime="820">group versus </span><span class="line" data-startTime="822">using individual scripts. </span> <span class="line" data-startTime="824">And in general, I highly </span><span class="line" data-startTime="824">recommend that you see script </span><span class="line" data-startTime="827">group as much as possible going </span><span class="line" data-startTime="827">forward, because it is a </span><span class="line" data-startTime="830">place where we're going </span><span class="line" data-startTime="830">to spend a lot of time </span><span class="line" data-startTime="832">optimizing. </span></p>

<p><span class="line" data-startTime="834">So let's go through an example </span><span class="line" data-startTime="834">of script group. </span> <span class="line" data-startTime="836">So here we have five kernels, </span><span class="line" data-startTime="836">and essentially input is </span><span class="line" data-startTime="841">passed to A, and output comes </span><span class="line" data-startTime="841">from E. And then you have this </span><span class="line" data-startTime="846">set of dependencies </span><span class="line" data-startTime="846">in between. </span> <span class="line" data-startTime="848">And according to the semantics </span><span class="line" data-startTime="848">of script group, the </span><span class="line" data-startTime="852">intermediate state is not </span><span class="line" data-startTime="852">visible to the user. </span> <span class="line" data-startTime="855">So all of these connections </span><span class="line" data-startTime="855">between A and B and A and C, </span><span class="line" data-startTime="859">et cetera, which would </span><span class="line" data-startTime="859">normally be stored in </span><span class="line" data-startTime="862">programmer managed allocations </span><span class="line" data-startTime="862">are instead simply set up as </span><span class="line" data-startTime="867">connections between these </span><span class="line" data-startTime="867">kernels and the graph. </span></p>

<p><span class="line" data-startTime="872">And what this allows us to do </span><span class="line" data-startTime="872">is the runtime can either </span><span class="line" data-startTime="875">create those allocations if </span><span class="line" data-startTime="875">necessary automatically, or we </span><span class="line" data-startTime="879">can optimize them away </span><span class="line" data-startTime="879">if possible. </span> <span class="line" data-startTime="883">And so we can do things here </span><span class="line" data-startTime="883">like, because there's no </span><span class="line" data-startTime="887">dependence between B and C, we </span><span class="line" data-startTime="887">could run B on the CPU and C </span><span class="line" data-startTime="891">on the GPU if possible, or </span><span class="line" data-startTime="891">something like that. </span> <span class="line" data-startTime="894">If we wanted to get more </span><span class="line" data-startTime="894">advanced, if we have more </span><span class="line" data-startTime="897">knowledge about the way the </span><span class="line" data-startTime="897">kernels actually run and the </span><span class="line" data-startTime="900">particular dependency </span><span class="line" data-startTime="900">information between colonels, </span><span class="line" data-startTime="904">we could potentially do </span><span class="line" data-startTime="904">something like fusing B and D </span><span class="line" data-startTime="909">into a single kernel. </span> <span class="line" data-startTime="911">And this way you could simply </span><span class="line" data-startTime="911">take the results of some </span><span class="line" data-startTime="914">portion of B, depending on how </span><span class="line" data-startTime="914">much you actually need to run </span><span class="line" data-startTime="918">at a time, and immediately start </span><span class="line" data-startTime="918">running that on D. And </span><span class="line" data-startTime="922">this is potentially really good </span><span class="line" data-startTime="922">for GPUs, and also really </span><span class="line" data-startTime="925">good for CPUs, because it allows </span><span class="line" data-startTime="925">you to use things like </span><span class="line" data-startTime="929">local memory on the </span><span class="line" data-startTime="929">GPU, and keep your </span><span class="line" data-startTime="934">cache hot on the CPU. </span></p>

<p><span class="line" data-startTime="939">So I'm going to talk about some </span><span class="line" data-startTime="939">features coming up in an </span><span class="line" data-startTime="943">upcoming release. </span> <span class="line" data-startTime="946">And the first feature we will </span><span class="line" data-startTime="946">talk about this is the </span><span class="line" data-startTime="950">compatibility library </span><span class="line" data-startTime="950">for gingerbread. </span> <span class="line" data-startTime="952">And I'll go into that in a lot </span><span class="line" data-startTime="952">more detail in a minute. </span> <span class="line" data-startTime="956">Other than that, we've added </span><span class="line" data-startTime="956">rsSetElementAt, which </span><span class="line" data-startTime="958">essentially is scatter support </span><span class="line" data-startTime="958">for RenderScript. </span> <span class="line" data-startTime="961">You can now write arbitrary </span><span class="line" data-startTime="961">allocations </span><span class="line" data-startTime="965">from a given kernel. </span> <span class="line" data-startTime="966">We have debug runtime, which </span><span class="line" data-startTime="966">does things like bounce </span><span class="line" data-startTime="969">checking and prints out errors </span><span class="line" data-startTime="969">to make it easier </span><span class="line" data-startTime="972">to debug your code. </span> <span class="line" data-startTime="974">We've added more script </span><span class="line" data-startTime="974">intrinsics, things like 3D </span><span class="line" data-startTime="977">look up tables, and I think </span><span class="line" data-startTime="977">something else. </span></p>

<p><span class="line" data-startTime="981">We have native support for YUV </span><span class="line" data-startTime="981">allocations, so you can take a </span><span class="line" data-startTime="984">YUV allocation directly from a </span><span class="line" data-startTime="984">camera, and process that in </span><span class="line" data-startTime="988">RenderScript. </span> <span class="line" data-startTime="989">We've also improved launch </span><span class="line" data-startTime="989">latency significantly. </span> <span class="line" data-startTime="994">So, the compatibility library. </span> <span class="line" data-startTime="996">The compatibility library </span><span class="line" data-startTime="996">enables API 18 RenderScript on </span><span class="line" data-startTime="1001">devices running Gingerbread </span><span class="line" data-startTime="1001">or higher. </span> <span class="line" data-startTime="1004">And the way this works is </span><span class="line" data-startTime="1004">essentially we can do an </span><span class="line" data-startTime="1008">offline compilation of your </span><span class="line" data-startTime="1008">RenderScript bit code. </span> <span class="line" data-startTime="1013">When you build your app, you can </span><span class="line" data-startTime="1013">actually create a shared </span><span class="line" data-startTime="1017">library that runs on the CPU. </span> <span class="line" data-startTime="1019">And we compile this for sort </span><span class="line" data-startTime="1019">of the lowest common </span><span class="line" data-startTime="1021">denominator CPU that can </span><span class="line" data-startTime="1021">run all the way back to </span><span class="line" data-startTime="1024">Gingerbread. </span> <span class="line" data-startTime="1028">When the app is actually built, </span><span class="line" data-startTime="1028">then, the compatibility </span><span class="line" data-startTime="1032">library, as well as the shared </span><span class="line" data-startTime="1032">libraries for your </span><span class="line" data-startTime="1035">RenderScript kernels are </span><span class="line" data-startTime="1035">packaged with the app. </span></p>

<p><span class="line" data-startTime="1038">And we also package the normal </span><span class="line" data-startTime="1038">RS bit code as well. </span> <span class="line" data-startTime="1044">So on an older device, something </span><span class="line" data-startTime="1044">running between </span><span class="line" data-startTime="1048">Gingerbread and Android 4.2, we </span><span class="line" data-startTime="1048">can use this shared library </span><span class="line" data-startTime="1054">that we've built into the app </span><span class="line" data-startTime="1054">because it doesn't have API18. </span> <span class="line" data-startTime="1060">On a suitable device, we can </span><span class="line" data-startTime="1060">compile the native bit code </span><span class="line" data-startTime="1063">automatically and use whatever </span><span class="line" data-startTime="1063">processors or optimizations </span><span class="line" data-startTime="1068">are available on that device </span><span class="line" data-startTime="1068">without the developer having </span><span class="line" data-startTime="1072">to do anything special there. </span> <span class="line" data-startTime="1074">So what this means, essentially, </span><span class="line" data-startTime="1074">is that you can </span><span class="line" data-startTime="1076">have one APK that runs on the </span><span class="line" data-startTime="1076">Nexus 1 running gingerbread. </span></p>

<p><span class="line" data-startTime="1082">And you can take that same APK </span><span class="line" data-startTime="1082">and run it on the Nexus 10. </span> <span class="line" data-startTime="1086">And on the Nexus 1, it'll run </span><span class="line" data-startTime="1086">using the CPU shared library. </span> <span class="line" data-startTime="1089">It will run the CPU, and run </span><span class="line" data-startTime="1089">as fast as possible there. </span> <span class="line" data-startTime="1095">And on the Nexus 10, we'll </span><span class="line" data-startTime="1095">compile the bit code for A15. </span> <span class="line" data-startTime="1100">Use whatever A15 optimizations </span><span class="line" data-startTime="1100">we can. </span> <span class="line" data-startTime="1103">We'll use the GPU, and it'll </span><span class="line" data-startTime="1103">run a lot faster. </span> <span class="line" data-startTime="1106">And so now for the first </span><span class="line" data-startTime="1106">time, you can do all </span><span class="line" data-startTime="1108">that from one APK. </span> <span class="line" data-startTime="1111">And with that, I'm going to turn </span><span class="line" data-startTime="1111">it over to Jason Sams, </span><span class="line" data-startTime="1115">who's going to go through </span><span class="line" data-startTime="1115">application. </span></p>

<p class="speaker"><span class="line" data-starttime="1123"><span class="speakerName">Jason Sams</span>: Thanks, Tim. </span> <span class="line" data-startTime="1124">My name is Jason Sams. </span> <span class="line" data-startTime="1126">I'm the tech lead for </span><span class="line" data-startTime="1126">RenderScript script on </span><span class="line" data-startTime="1128">Android, and I'm going to take </span><span class="line" data-startTime="1128">us through a simple example of </span><span class="line" data-startTime="1133">using RenderScript. </span> <span class="line" data-startTime="1135">And then we're actually going </span><span class="line" data-startTime="1135">to follow up with a more </span><span class="line" data-startTime="1136">complex example. </span> <span class="line" data-startTime="1140">So, the examples we're going </span><span class="line" data-startTime="1140">to use are going to be a </span><span class="line" data-startTime="1143">Gaussian Blur and a histogram. </span> <span class="line" data-startTime="1147">So for anyone who attended the </span><span class="line" data-startTime="1147">talk yesterday that Rowan and </span><span class="line" data-startTime="1150">Chet gave, you may have noticed </span><span class="line" data-startTime="1150">that they were talking </span><span class="line" data-startTime="1152">about doing drop shadows </span><span class="line" data-startTime="1152">using RenderScript. </span> <span class="line" data-startTime="1156">And I'm actually going to talk </span><span class="line" data-startTime="1156">about the primitive they're </span><span class="line" data-startTime="1158">using to do this. </span></p>

<p><span class="line" data-startTime="1161">RenderScript has been optimized </span><span class="line" data-startTime="1161">for doing image </span><span class="line" data-startTime="1163">processing tasks. </span> <span class="line" data-startTime="1164">We've been tuning it for </span><span class="line" data-startTime="1164">this workload for a </span><span class="line" data-startTime="1167">couple years now. </span> <span class="line" data-startTime="1168">It's getting pretty </span><span class="line" data-startTime="1168">good at it. </span> <span class="line" data-startTime="1171">The intrinsics that Tim </span><span class="line" data-startTime="1171">talked about include a </span><span class="line" data-startTime="1174">Gaussian Blur intrinsic. </span> <span class="line" data-startTime="1176">And so for blurring images </span><span class="line" data-startTime="1176">or applying other simple </span><span class="line" data-startTime="1181">operations to bitmaps, it's </span><span class="line" data-startTime="1181">actually extremely easy to do </span><span class="line" data-startTime="1185">that, and that's why we'll walk </span><span class="line" data-startTime="1185">through that example. </span> <span class="line" data-startTime="1188">Histogram will demonstrate </span><span class="line" data-startTime="1188">some of the more advanced </span><span class="line" data-startTime="1191">techniques. </span></p>

<p><span class="line" data-startTime="1192">Things I clipped kernel </span><span class="line" data-startTime="1192">launches, which </span><span class="line" data-startTime="1195">is coming up soon. </span> <span class="line" data-startTime="1197">The rsSetElementAt, which </span><span class="line" data-startTime="1197">Tim was talking about. </span> <span class="line" data-startTime="1200">And we'll also demonstrate </span><span class="line" data-startTime="1200">multipass </span><span class="line" data-startTime="1202">processing over a workload. </span> <span class="line" data-startTime="1208">So general image processing in </span><span class="line" data-startTime="1208">RS, and how you go about it. </span> <span class="line" data-startTime="1213">The code to do this is actually </span><span class="line" data-startTime="1213">pretty simple, and </span><span class="line" data-startTime="1218">the first thing you'll want to </span><span class="line" data-startTime="1218">do in an application, if </span><span class="line" data-startTime="1219">you're going to do some use of </span><span class="line" data-startTime="1219">RS is you'll want to create a </span><span class="line" data-startTime="1223">RenderScript context. </span> <span class="line" data-startTime="1225">And the first line of our code, </span><span class="line" data-startTime="1225">we create this context. </span> <span class="line" data-startTime="1230">We actually pass the application </span><span class="line" data-startTime="1230">context to that. </span></p>

<p><span class="line" data-startTime="1234">Now, coming up soon we'll </span><span class="line" data-startTime="1234">actually have a few additional </span><span class="line" data-startTime="1236">flags you can pass here, one </span><span class="line" data-startTime="1236">of which is a debug mode, </span><span class="line" data-startTime="1240">which you can pass into your </span><span class="line" data-startTime="1240">contacts creation, and it'll </span><span class="line" data-startTime="1243">do things like range check </span><span class="line" data-startTime="1243">your access and give you </span><span class="line" data-startTime="1246">additional warnings, or errors </span><span class="line" data-startTime="1246">if it detects something that's </span><span class="line" data-startTime="1250">not optimal, or wrong. </span> <span class="line" data-startTime="1253">But the next step you'll want </span><span class="line" data-startTime="1253">to do is actually create one </span><span class="line" data-startTime="1256">of those RenderScript </span><span class="line" data-startTime="1256">allocations. </span></p>

<p><span class="line" data-startTime="1258">And typically if you're doing </span><span class="line" data-startTime="1258">image processing, your input's </span><span class="line" data-startTime="1260">probably going to be </span><span class="line" data-startTime="1260">a bitmap. map. </span> <span class="line" data-startTime="1262">And so we have a create from </span><span class="line" data-startTime="1262">bitmap helper function, which </span><span class="line" data-startTime="1266">will actually create an </span><span class="line" data-startTime="1266">allocation from a bitmap, and </span><span class="line" data-startTime="1269">it'll automatically set the type </span><span class="line" data-startTime="1269">and the height and the </span><span class="line" data-startTime="1272">width of that allocation to that </span><span class="line" data-startTime="1272">of the incoming bitmap. </span> <span class="line" data-startTime="1276">Now in addition, you can </span><span class="line" data-startTime="1276">optionally map that </span><span class="line" data-startTime="1279">allocation, and we have </span><span class="line" data-startTime="1279">a few usage flags. </span> <span class="line" data-startTime="1283">Usage shared, it's new, </span><span class="line" data-startTime="1283">or upcoming soon. </span> <span class="line" data-startTime="1287">And it allows us to share the </span><span class="line" data-startTime="1287">back end store with the </span><span class="line" data-startTime="1290">bitmap, and that avoids a lot of </span><span class="line" data-startTime="1290">the copy overhead that you </span><span class="line" data-startTime="1293">would normally get if you had </span><span class="line" data-startTime="1293">a separate bitmap and </span><span class="line" data-startTime="1297">allocation in the older APIs. </span></p>

<p><span class="line" data-startTime="1300">Also, usage graphic texture. </span> <span class="line" data-startTime="1302">If you were going to use this </span><span class="line" data-startTime="1302">in combination with RS </span><span class="line" data-startTime="1304">sampler, you can set the </span><span class="line" data-startTime="1304">flag to enable that. </span> <span class="line" data-startTime="1307">And usage script just </span><span class="line" data-startTime="1307">means we're going to </span><span class="line" data-startTime="1309">pass it into a kernel. </span> <span class="line" data-startTime="1310">Now, this is actually the </span><span class="line" data-startTime="1310">default set of flags, so if </span><span class="line" data-startTime="1312">you were to weed the flags </span><span class="line" data-startTime="1312">off completely, this is </span><span class="line" data-startTime="1314">what you would get. </span> <span class="line" data-startTime="1316">For the output, we're going </span><span class="line" data-startTime="1316">to write this to a bitmap. </span> <span class="line" data-startTime="1318">So we'll create a second </span><span class="line" data-startTime="1318">allocation, and I'm going to </span><span class="line" data-startTime="1321">leave off the graphics texture </span><span class="line" data-startTime="1321">usage, because we're not going </span><span class="line" data-startTime="1324">to sample from it. </span> <span class="line" data-startTime="1327">So we have a bitmap we're going </span><span class="line" data-startTime="1327">to work on, and we're </span><span class="line" data-startTime="1330">going to apply a large </span><span class="line" data-startTime="1330">blur to this. </span> <span class="line" data-startTime="1334">So after you have your two </span><span class="line" data-startTime="1334">allocations, how would you go </span><span class="line" data-startTime="1336">about blurring that image? </span><span class="line" data-startTime="1339">The first thing I would do is </span><span class="line" data-startTime="1339">I would create a variable to </span><span class="line" data-startTime="1341">hold the intrinsic script, </span><span class="line" data-startTime="1341">that is the blur. </span></p>

<p><span class="line" data-startTime="1345">And then I would create </span><span class="line" data-startTime="1345">that blur script. </span> <span class="line" data-startTime="1349">In this case, since it's an </span><span class="line" data-startTime="1349">intrinsic, you don't actually </span><span class="line" data-startTime="1351">have to provide a dot RS file. </span> <span class="line" data-startTime="1352">It's built into the system, But </span><span class="line" data-startTime="1352">You still need to tell it </span><span class="line" data-startTime="1355">what type of data you </span><span class="line" data-startTime="1355">want it to work on. </span> <span class="line" data-startTime="1358">In this case, we're going </span><span class="line" data-startTime="1358">to say it's a uchar4. </span> <span class="line" data-startTime="1361">That's the element </span><span class="line" data-startTime="1361">U8 underscore 4. </span> <span class="line" data-startTime="1364">We support just uchar buffers, </span><span class="line" data-startTime="1364">if you had, say, an alpha </span><span class="line" data-startTime="1368">channel, or just a </span><span class="line" data-startTime="1368">grayscale image. </span> <span class="line" data-startTime="1371">And now we'll take that script </span><span class="line" data-startTime="1371">that we loaded, and we'll </span><span class="line" data-startTime="1375">configure it to perform </span><span class="line" data-startTime="1375">our blur. </span></p>

<p><span class="line" data-startTime="1377">Now, I'm going to first </span><span class="line" data-startTime="1377">set of radius. </span> <span class="line" data-startTime="1378">In this case, we're </span><span class="line" data-startTime="1378">going to set it to </span><span class="line" data-startTime="1379">a nice, large radius. </span> <span class="line" data-startTime="1381">20 pixels, so it's going to </span><span class="line" data-startTime="1381">be a big blur operation. </span> <span class="line" data-startTime="1385">And we'll set on that script </span><span class="line" data-startTime="1385">the input allocation we </span><span class="line" data-startTime="1388">created in the previous slide, </span><span class="line" data-startTime="1388">that will act as our input. </span> <span class="line" data-startTime="1392">And for the blur, we're </span><span class="line" data-startTime="1392">going to run it. </span> <span class="line" data-startTime="1394">We're just going to call </span><span class="line" data-startTime="1394">it the for each. </span> <span class="line" data-startTime="1396">Since it's an intrinsic, there </span><span class="line" data-startTime="1396">is actually no name provided. </span></p>

<p><span class="line" data-startTime="1399">It's just called for each, and </span><span class="line" data-startTime="1399">write it to our output </span><span class="line" data-startTime="1402">allocation. </span> <span class="line" data-startTime="1404">And after we have done that, </span><span class="line" data-startTime="1404">we need to copy our output </span><span class="line" data-startTime="1408">allocation back into </span><span class="line" data-startTime="1408">our output bitmap. </span> <span class="line" data-startTime="1411">Now, with usage shared it's </span><span class="line" data-startTime="1411">possible this will be a no op </span><span class="line" data-startTime="1414">on some devices, and be </span><span class="line" data-startTime="1414">extremely efficient. </span> <span class="line" data-startTime="1419">And with that, you get </span><span class="line" data-startTime="1419">a nice blurred image. </span> <span class="line" data-startTime="1422">This intrinsic is actually </span><span class="line" data-startTime="1422">implemented extremely </span><span class="line" data-startTime="1425">efficiently. </span> <span class="line" data-startTime="1426">So if you have an ARM device, </span><span class="line" data-startTime="1426">you get handed to a Neon. </span> <span class="line" data-startTime="1429">If you have an x86 device, </span><span class="line" data-startTime="1429">you get SSE that's been </span><span class="line" data-startTime="1431">hand-tuned. </span></p>

<p><span class="line" data-startTime="1433">On some devices you'll get </span><span class="line" data-startTime="1433">a hand-tuned GPU kernel. </span> <span class="line" data-startTime="1437">So it really is up to each </span><span class="line" data-startTime="1437">device how they implement </span><span class="line" data-startTime="1439">this, but the key takeaway is </span><span class="line" data-startTime="1439">on each device, it's pretty </span><span class="line" data-startTime="1442">much the fastest </span><span class="line" data-startTime="1442">possible way to </span><span class="line" data-startTime="1444">implement it on that device. </span> <span class="line" data-startTime="1448">Now for histogram, this </span><span class="line" data-startTime="1448">is going to be a </span><span class="line" data-startTime="1449">more complex example. </span> <span class="line" data-startTime="1451">We're going to present an </span><span class="line" data-startTime="1451">algorithm that does the </span><span class="line" data-startTime="1454">histogram in two passes. </span> <span class="line" data-startTime="1456">The first pass we'll use a </span><span class="line" data-startTime="1456">large number of workers. </span></p>

<p><span class="line" data-startTime="1460">The second pass will be a much </span><span class="line" data-startTime="1460">smaller summation pass. </span> <span class="line" data-startTime="1464">We do this because the first </span><span class="line" data-startTime="1464">pass, we're breaking the image </span><span class="line" data-startTime="1468">up into chunks to build </span><span class="line" data-startTime="1468">intermediate sums. </span> <span class="line" data-startTime="1472">And that allows us to do a </span><span class="line" data-startTime="1472">lot of work in parallel. </span> <span class="line" data-startTime="1476">And we'll for the purpose of </span><span class="line" data-startTime="1476">time ignore the actual </span><span class="line" data-startTime="1479">rendering pass into how we draw </span><span class="line" data-startTime="1479">it on the screen, because </span><span class="line" data-startTime="1482">there's a lot of different ways </span><span class="line" data-startTime="1482">you could theoretically </span><span class="line" data-startTime="1483">render this. </span> <span class="line" data-startTime="1486">So how would you write </span><span class="line" data-startTime="1486">a histogram script? </span><span class="line" data-startTime="1489">Now, since we don't have an </span><span class="line" data-startTime="1489">intrinsic, I'm actually going </span><span class="line" data-startTime="1491">to write a dot RS file. </span> <span class="line" data-startTime="1493">The first thing I'm going to </span><span class="line" data-startTime="1493">do is declare some globals. </span> <span class="line" data-startTime="1496">In this case they're </span><span class="line" data-startTime="1496">going to be an RS </span><span class="line" data-startTime="1498">underscore allocation type. </span></p>

<p><span class="line" data-startTime="1499">That is just the script </span><span class="line" data-startTime="1499">equivalent of the allocation </span><span class="line" data-startTime="1502">class on the Java side </span><span class="line" data-startTime="1502">that will hold our </span><span class="line" data-startTime="1505">input and output data. </span> <span class="line" data-startTime="1508">I will also attach, since it's </span><span class="line" data-startTime="1508">a multipass, an intermediate </span><span class="line" data-startTime="1511">buffer that'll hold the sums </span><span class="line" data-startTime="1511">from the first pass. </span> <span class="line" data-startTime="1516">And that buffer will be the </span><span class="line" data-startTime="1516">number of steps, meaning how </span><span class="line" data-startTime="1520">many threads I'm going to run to </span><span class="line" data-startTime="1520">do the summations, and 256 </span><span class="line" data-startTime="1523">units wide, one for each </span><span class="line" data-startTime="1523">level of the histogram. </span> <span class="line" data-startTime="1529">And we'll also have a final sum </span><span class="line" data-startTime="1529">buffer, which will just be </span><span class="line" data-startTime="1532">a one dimensional allocation </span><span class="line" data-startTime="1532">of 256 different levels. </span> <span class="line" data-startTime="1539">So, additional globals we're </span><span class="line" data-startTime="1539">going to pass in will have </span><span class="line" data-startTime="1542">just integers that will </span><span class="line" data-startTime="1542">represent the height and width </span><span class="line" data-startTime="1545">of the input image. </span> <span class="line" data-startTime="1548">And we will have an integer </span><span class="line" data-startTime="1548">which will represent how many </span><span class="line" data-startTime="1551">steps, or how many items is in </span><span class="line" data-startTime="1551">each step of the image, and </span><span class="line" data-startTime="1555">how many steps are in total. </span> <span class="line" data-startTime="1560">So the kernel for the first </span><span class="line" data-startTime="1560">pass, and I'll have a diagram </span><span class="line" data-startTime="1563">of how this works in a moment. </span></p>

<p><span class="line" data-startTime="1565">What this is going to do is </span><span class="line" data-startTime="1565">it's going to walk over a </span><span class="line" data-startTime="1568">number of scan lines </span><span class="line" data-startTime="1568">in the image. </span> <span class="line" data-startTime="1573">However many scan lines </span><span class="line" data-startTime="1573">will be determined </span><span class="line" data-startTime="1574">by the steps value. </span> <span class="line" data-startTime="1576">Typically you're going to see </span><span class="line" data-startTime="1576">values like two or four. </span> <span class="line" data-startTime="1579">I tried experimentally, a number </span><span class="line" data-startTime="1579">of different steps </span><span class="line" data-startTime="1581">value, and it's very hardware </span><span class="line" data-startTime="1581">dependent what the most </span><span class="line" data-startTime="1583">efficient value is. </span> <span class="line" data-startTime="1586">But you can actually pick values </span><span class="line" data-startTime="1586">that worked across a </span><span class="line" data-startTime="1588">very large range of hardware. </span> <span class="line" data-startTime="1592">And we're going to actually </span><span class="line" data-startTime="1592">run this kernel. </span> <span class="line" data-startTime="1595">So you see it takes an x and </span><span class="line" data-startTime="1595">y-coordinate, because it's </span><span class="line" data-startTime="1597">running on a 2D input image. </span></p>

<p><span class="line" data-startTime="1599">But when we watch the kernel </span><span class="line" data-startTime="1599">from the Java side, we're </span><span class="line" data-startTime="1602">actually going to clip it so </span><span class="line" data-startTime="1602">that it only iterates over x </span><span class="line" data-startTime="1604">equals 0 and walks through the </span><span class="line" data-startTime="1604">different y-coordinates. </span> <span class="line" data-startTime="1607">I'll go over how we </span><span class="line" data-startTime="1607">do that in a bit. </span> <span class="line" data-startTime="1609">So the first thing we do for </span><span class="line" data-startTime="1609">each of these histogram worker </span><span class="line" data-startTime="1613">threads is we're going to want </span><span class="line" data-startTime="1613">to clear our output of </span><span class="line" data-startTime="1615">accumulation buffers. </span> <span class="line" data-startTime="1616">And I do that just by walking </span><span class="line" data-startTime="1616">through a simple loop that </span><span class="line" data-startTime="1620">sets the sums buffer. </span> <span class="line" data-startTime="1622">It sets our particular line, and </span><span class="line" data-startTime="1622">then we just loop over the </span><span class="line" data-startTime="1625">256 elements. </span> <span class="line" data-startTime="1630">So, continuing our first pass. </span></p>

<p><span class="line" data-startTime="1632">After we've cleared our </span><span class="line" data-startTime="1632">accumulation buffer, we'll </span><span class="line" data-startTime="1635">need to iterate over </span><span class="line" data-startTime="1635">our image. </span> <span class="line" data-startTime="1638">And we do this for 0 to </span><span class="line" data-startTime="1638">the number of scan </span><span class="line" data-startTime="1642">lines in our step. </span> <span class="line" data-startTime="1644">Then we calculate which </span><span class="line" data-startTime="1644">wine we're working on. </span> <span class="line" data-startTime="1647">That's the PY variable. </span> <span class="line" data-startTime="1649">And if steps is not equally </span><span class="line" data-startTime="1649">divisible by the number of </span><span class="line" data-startTime="1654">lines in the image, it's </span><span class="line" data-startTime="1654">possible we'll need to check </span><span class="line" data-startTime="1656">for an overrun here. </span> <span class="line" data-startTime="1657">So we'll return in that case, </span><span class="line" data-startTime="1657">because we'll be done. </span> <span class="line" data-startTime="1661">And then we walk through </span><span class="line" data-startTime="1661">one scan line. </span> <span class="line" data-startTime="1664">So we just iterate in the kernel </span><span class="line" data-startTime="1664">from left to right, and </span><span class="line" data-startTime="1669">we'll get an element from our </span><span class="line" data-startTime="1669">input image and load that into </span><span class="line" data-startTime="1673">a temporary uchar4 value. </span> <span class="line" data-startTime="1676">We then calculate a luminance </span><span class="line" data-startTime="1676">value from that. </span> <span class="line" data-startTime="1680">In this case, it's just </span><span class="line" data-startTime="1680">the integer math. </span></p>

<p><span class="line" data-startTime="1682">Nothing terribly exciting. </span> <span class="line" data-startTime="1685">And then after we've calculated </span><span class="line" data-startTime="1685">a luminance value, </span><span class="line" data-startTime="1688">we use that is the x-coordinate </span><span class="line" data-startTime="1688">index into our </span><span class="line" data-startTime="1693">intermediate buffer, and we </span><span class="line" data-startTime="1693">load the existing value, </span><span class="line" data-startTime="1697">increment it by one, and then </span><span class="line" data-startTime="1697">you set [INAUDIBLE] </span><span class="line" data-startTime="1699">to write it back. </span> <span class="line" data-startTime="1701">And this is how we're constantly </span><span class="line" data-startTime="1701">accumulating from </span><span class="line" data-startTime="1704">each work item and </span><span class="line" data-startTime="1704">output value. </span> <span class="line" data-startTime="1709">So for the second pass, after </span><span class="line" data-startTime="1709">the first pass, we have </span><span class="line" data-startTime="1714">basically an image which a </span><span class="line" data-startTime="1714">number of temporary buffers </span><span class="line" data-startTime="1719">that indicate however many </span><span class="line" data-startTime="1719">values of each level were run </span><span class="line" data-startTime="1724">for that threat. </span> <span class="line" data-startTime="1725">Now we need to sum all those </span><span class="line" data-startTime="1725">together and get one set of </span><span class="line" data-startTime="1727">results, not n sets </span><span class="line" data-startTime="1727">of results. </span> <span class="line" data-startTime="1731">This kernel is a 1D kernel, so </span><span class="line" data-startTime="1731">it's only going to operate </span><span class="line" data-startTime="1734">over one dimension. </span></p>

<p><span class="line" data-startTime="1737">And we just simply loop over </span><span class="line" data-startTime="1737">within that kernel the input </span><span class="line" data-startTime="1742">values, and sum up one vertical </span><span class="line" data-startTime="1742">column of levels. </span> <span class="line" data-startTime="1746">And we return the sum, and that </span><span class="line" data-startTime="1746">writes the output value </span><span class="line" data-startTime="1751">for that level. </span> <span class="line" data-startTime="1755">So, rescale. </span> <span class="line" data-startTime="1758">This is an example of an </span><span class="line" data-startTime="1758">invokable function. </span> <span class="line" data-startTime="1760">So after we have our buffer that </span><span class="line" data-startTime="1760">has 256 items and tells </span><span class="line" data-startTime="1766">you how many pixels of each </span><span class="line" data-startTime="1766">level it saw, what you may </span><span class="line" data-startTime="1770">want to do is actually rescale </span><span class="line" data-startTime="1770">that to some range. </span> <span class="line" data-startTime="1773">In this case we'll have </span><span class="line" data-startTime="1773">an invokable. </span></p>

<p><span class="line" data-startTime="1775">If you notice, there's no </span><span class="line" data-startTime="1775">decoration kernel on this. </span> <span class="line" data-startTime="1778">And it's going to be called </span><span class="line" data-startTime="1778">single threaded. </span> <span class="line" data-startTime="1782">This is good for very small </span><span class="line" data-startTime="1782">workloads where you don't want </span><span class="line" data-startTime="1784">to necessarily launch a lot </span><span class="line" data-startTime="1784">of threads and do a lot of </span><span class="line" data-startTime="1787">overhead for a very small </span><span class="line" data-startTime="1787">amount of work. </span> <span class="line" data-startTime="1790">So we loop over, we find the </span><span class="line" data-startTime="1790">maximum value in terms of any </span><span class="line" data-startTime="1794">one bucket, and then we just </span><span class="line" data-startTime="1794">integrate over our buckets, </span><span class="line" data-startTime="1798">and we divide the values there </span><span class="line" data-startTime="1798">by the greatest value to </span><span class="line" data-startTime="1803">effectively normalize </span><span class="line" data-startTime="1803">the range. </span> <span class="line" data-startTime="1808">So what does this look like </span><span class="line" data-startTime="1808">on the Java side? </span><span class="line" data-startTime="1811">So you've written this </span><span class="line" data-startTime="1811">dot RS file. </span> <span class="line" data-startTime="1813">What do you actually do with </span><span class="line" data-startTime="1813">it in terms of interfacing </span><span class="line" data-startTime="1815">that with your application? </span><span class="line" data-startTime="1817">Well, the first thing you </span><span class="line" data-startTime="1817">need to do is load it. </span> <span class="line" data-startTime="1820">The first line here </span><span class="line" data-startTime="1820">is how we do that. </span></p>

<p><span class="line" data-startTime="1823">We create a script variable, and </span><span class="line" data-startTime="1823">then we can just say new </span><span class="line" data-startTime="1826">script C underscore whatever </span><span class="line" data-startTime="1826">the name of </span><span class="line" data-startTime="1828">your dot RS file is. </span> <span class="line" data-startTime="1830">And this works because we've </span><span class="line" data-startTime="1830">reflected a Java file from </span><span class="line" data-startTime="1833">your dot RS file, and </span><span class="line" data-startTime="1833">effectively you now have a </span><span class="line" data-startTime="1836">Java class with all the methods </span><span class="line" data-startTime="1836">that you could use to </span><span class="line" data-startTime="1841">actually talk to that </span><span class="line" data-startTime="1841">dot RS file. </span> <span class="line" data-startTime="1844">And so after it's loaded, things </span><span class="line" data-startTime="1844">like the width and the </span><span class="line" data-startTime="1848">height, those globals, you can </span><span class="line" data-startTime="1848">just actually call Java </span><span class="line" data-startTime="1851">methods, and it will </span><span class="line" data-startTime="1851">set those for you. </span> <span class="line" data-startTime="1853">You can set any value you want </span><span class="line" data-startTime="1853">at that point, but in this </span><span class="line" data-startTime="1857">case we'll set the width. </span> <span class="line" data-startTime="1859">Now </span><span class="line" data-startTime="1860">We, need to create the </span><span class="line" data-startTime="1860">allocations to hold our data. </span> <span class="line" data-startTime="1863">We demonstrated earlier how you </span><span class="line" data-startTime="1863">would create the input and </span><span class="line" data-startTime="1865">output allocations for the </span><span class="line" data-startTime="1865">input image and the final </span><span class="line" data-startTime="1868">image, but how do you create </span><span class="line" data-startTime="1868">those intermediate buffers? </span><span class="line" data-startTime="1872">In this case, we're going to </span><span class="line" data-startTime="1872">have to do it by building a </span><span class="line" data-startTime="1874">custom type, because it's </span><span class="line" data-startTime="1874">going to be shaped very </span><span class="line" data-startTime="1878">specific to that intermediate </span><span class="line" data-startTime="1878">buffer. </span></p>

<p><span class="line" data-startTime="1881">So we create a type builder. </span> <span class="line" data-startTime="1883">We specify an element of INT </span><span class="line" data-startTime="1883">32, which is just regular </span><span class="line" data-startTime="1887">integer is our element type. </span> <span class="line" data-startTime="1890">And then we set the x and y </span><span class="line" data-startTime="1890">dimensions that we want, in </span><span class="line" data-startTime="1893">this case, 256 wide </span><span class="line" data-startTime="1893">by steps high. </span> <span class="line" data-startTime="1897">We create a type from that. </span> <span class="line" data-startTime="1899">That's the dimensions </span><span class="line" data-startTime="1899">of the allocation. </span> <span class="line" data-startTime="1902">And then we actually allocate </span><span class="line" data-startTime="1902">the back end store from that. </span> <span class="line" data-startTime="1906">So we'll also need to create </span><span class="line" data-startTime="1906">that 1D buffer to hold the </span><span class="line" data-startTime="1910">final histogram. </span> <span class="line" data-startTime="1912">And in this case, we'll </span><span class="line" data-startTime="1912">again choose INT. </span> <span class="line" data-startTime="1915">But we have a helper function so </span><span class="line" data-startTime="1915">that you don't necessarily </span><span class="line" data-startTime="1917">have to create a type for every </span><span class="line" data-startTime="1920">allocation you want to create. </span> <span class="line" data-startTime="1922">If it's a 1D allocation, we </span><span class="line" data-startTime="1922">actually have a helper </span><span class="line" data-startTime="1924">function that will automatically </span><span class="line" data-startTime="1924">create </span><span class="line" data-startTime="1926">a 1D type for you. </span></p>

<p><span class="line" data-startTime="1928">In this case, 256 elements. </span> <span class="line" data-startTime="1931">And then we set those </span><span class="line" data-startTime="1931">allocations we just created to </span><span class="line" data-startTime="1934">the script. </span> <span class="line" data-startTime="1937">So, running the first pass. </span> <span class="line" data-startTime="1941">Now, launching scripts from </span><span class="line" data-startTime="1941">Java, very straightforward. </span> <span class="line" data-startTime="1945">But we're going to do something </span><span class="line" data-startTime="1945">a little more </span><span class="line" data-startTime="1947">complicated than we talked </span><span class="line" data-startTime="1947">about in the blur. </span> <span class="line" data-startTime="1950">If you remember when we talked </span><span class="line" data-startTime="1950">about the first paths, we said </span><span class="line" data-startTime="1952">we're going to clip this kernel </span><span class="line" data-startTime="1952">so that it only ran on </span><span class="line" data-startTime="1954">x equals zero, but actually </span><span class="line" data-startTime="1954">iterated over all the y's. </span> <span class="line" data-startTime="1959">So coming soon we have on the </span><span class="line" data-startTime="1959">Java side, a new option for </span><span class="line" data-startTime="1963">launching kernels, and the </span><span class="line" data-startTime="1963">ability to clip the kernel to </span><span class="line" data-startTime="1966">the region of interest </span><span class="line" data-startTime="1966">that you want that </span><span class="line" data-startTime="1968">kernel to run on. </span> <span class="line" data-startTime="1969">This is very useful if you want </span><span class="line" data-startTime="1969">to either do what I'm </span><span class="line" data-startTime="1973">about to do here, or if you're </span><span class="line" data-startTime="1973">just editing part of an image. </span></p>

<p><span class="line" data-startTime="1977">We create a launch option </span><span class="line" data-startTime="1977">structure, and then </span><span class="line" data-startTime="1980">we set the x range. </span> <span class="line" data-startTime="1981">The first value's inclusive, the </span><span class="line" data-startTime="1981">second value's exclusive, </span><span class="line" data-startTime="1984">so that's why you see 0 to 1. </span> <span class="line" data-startTime="1986">And then we do our for each </span><span class="line" data-startTime="1986">pass, and coming soon, not </span><span class="line" data-startTime="1990">only can you specify the input </span><span class="line" data-startTime="1990">or output allocation, but we </span><span class="line" data-startTime="1993">actually reflect overloaded </span><span class="line" data-startTime="1993">versions of this that will </span><span class="line" data-startTime="1995">take the launch options, </span><span class="line" data-startTime="1995">if you so choose. </span> <span class="line" data-startTime="2001">And so what does this actually </span><span class="line" data-startTime="2001">look like running? </span><span class="line" data-startTime="2004">So we have the allocation </span><span class="line" data-startTime="2004">we created. </span></p>

<p><span class="line" data-startTime="2007">The kernel's going </span><span class="line" data-startTime="2007">to an each time C </span><span class="line" data-startTime="2008">x-coordinate equals zero. </span> <span class="line" data-startTime="2010">And it's going to see a </span><span class="line" data-startTime="2010">y-coordinate that is the </span><span class="line" data-startTime="2012">number of steps, as </span><span class="line" data-startTime="2012">we drew earlier. </span> <span class="line" data-startTime="2020">Now, running the second pass. </span> <span class="line" data-startTime="2021">So after you run the first pass, </span><span class="line" data-startTime="2021">the output will be in </span><span class="line" data-startTime="2026">that intermediate buffer. </span> <span class="line" data-startTime="2028">And you can just immediately </span><span class="line" data-startTime="2028">call the for each on pass two, </span><span class="line" data-startTime="2032">and this will sum the first </span><span class="line" data-startTime="2032">buffer into the second, and </span><span class="line" data-startTime="2035">now you have a single </span><span class="line" data-startTime="2035">allocation, which contains </span><span class="line" data-startTime="2038">your range of values. </span> <span class="line" data-startTime="2040">And we can simply call </span><span class="line" data-startTime="2040">re-scale by invoke. </span> <span class="line" data-startTime="2044">If you notice, this </span><span class="line" data-startTime="2044">doesn't take any </span><span class="line" data-startTime="2045">parameters in this example. </span> <span class="line" data-startTime="2047">Invoke functions are actually </span><span class="line" data-startTime="2047">very useful for </span><span class="line" data-startTime="2050">things like set up. </span></p>

<p><span class="line" data-startTime="2052">So if in the dot RS file, you </span><span class="line" data-startTime="2052">put some parameters in the </span><span class="line" data-startTime="2056">prototype for that function, </span><span class="line" data-startTime="2056">you can actually pass them </span><span class="line" data-startTime="2059">directly here. </span> <span class="line" data-startTime="2060">However, you cannot </span><span class="line" data-startTime="2060">return values. </span> <span class="line" data-startTime="2061">So the prototype always </span><span class="line" data-startTime="2061">must be void. </span> <span class="line" data-startTime="2065">And you have your histogram. </span> <span class="line" data-startTime="2068">So with that, I'm going to open </span><span class="line" data-startTime="2068">it up to questions, if </span><span class="line" data-startTime="2072">Tim would join us again. </span> <span class="line" data-startTime="2076">Thanks, everyone. </span> <span class="line" data-startTime="2084">One other comment, during office </span><span class="line" data-startTime="2084">hours I actually have </span><span class="line" data-startTime="2086">both an ARM and x86 device that </span><span class="line" data-startTime="2086">can be seen running this </span><span class="line" data-startTime="2091">example, if anyone's curious. </span> <span class="line" data-startTime="2093">But it runs very well </span><span class="line" data-startTime="2093">on both devices. </span></p>

<p><span class="line" data-startTime="2097">The good news here is by writing </span><span class="line" data-startTime="2097">in the agnostic code, </span><span class="line" data-startTime="2101">we actually generate back end </span><span class="line" data-startTime="2101">code that is optimal for all. </span> <span class="line" data-startTime="2110">Hello. </span> <span class="line" data-startTime="2111">Take the first question? </span></p>

<p class="speaker"><span class="line" data-starttime="2113"><span class="speakerName">Audience</span>: So you had mentioned </span><span class="line" data-startTime="2113">two things. </span> <span class="line" data-startTime="2115">You mentioned that the ISP and </span><span class="line" data-startTime="2115">DSPs, so that's the mobile </span><span class="line" data-startTime="2118">devices, is there any access to </span><span class="line" data-startTime="2118">the fixed function hardware </span><span class="line" data-startTime="2122">like the fast resizing, the fast </span><span class="line" data-startTime="2122">color space conversion </span><span class="line" data-startTime="2125">you see on ISPs? </span><span class="line" data-startTime="2127">And then my second question </span><span class="line" data-startTime="2127">was are there any plans to </span><span class="line" data-startTime="2130">have RenderScript run on </span><span class="line" data-startTime="2130">something other than Android? </span><span class="line" data-startTime="2134">Even if it's Chromebooks, or </span><span class="line" data-startTime="2134">just regular old Linux. </span></p>

<p class="speaker"><span class="line" data-starttime="2138"><span class="speakerName">Jason Sams</span>: OK, I'll go ahead </span><span class="line" data-startTime="2138">and answer the first one. </span><span class="line" data-startTime="2140">The answer is yes. </span><span class="line" data-startTime="2142">Part of the reason we have </span><span class="line" data-startTime="2142">intrinsics is we can use </span><span class="line" data-startTime="2146">processors that are more fixed </span><span class="line" data-startTime="2146">function than you can by </span><span class="line" data-startTime="2150">writing code directly from </span><span class="line" data-startTime="2150">a dot RS, or dot FS file. </span><span class="line" data-startTime="2153">And so something like the </span><span class="line" data-startTime="2153">Gaussian Blur we used as an </span><span class="line" data-startTime="2155">example, we actually have other </span><span class="line" data-startTime="2155">intrinsics like involved </span><span class="line" data-startTime="2158">3x3 and 5x5, those will run very </span><span class="line" data-startTime="2158">well on something like a </span><span class="line" data-startTime="2162">fixed function ISP or DSP. </span><span class="line" data-startTime="2164">Another example that's our YUV </span><span class="line" data-startTime="2164">to RGB conversion, again, you </span><span class="line" data-startTime="2167">should be able to take advantage </span><span class="line" data-startTime="2167">of that fixed </span><span class="line" data-startTime="2169">function hardware, because </span><span class="line" data-startTime="2169">it's going to be both </span><span class="line" data-startTime="2170">extremely power efficient, </span><span class="line" data-startTime="2170">and usually very fast. </span><span class="line" data-startTime="2175">I'll let you take </span><span class="line" data-startTime="2175">the second one. </span></p>

<p class="speaker"><span class="line" data-starttime="2176"><span class="speakerName">Tim Murray</span>: So as far as other </span><span class="line" data-startTime="2176">platforms, it's possible. </span><span class="line" data-startTime="2179">Basically during my spare time </span><span class="line" data-startTime="2179">in the last six months or so, </span><span class="line" data-startTime="2184">I ported this two CUBE </span><span class="line" data-startTime="2184">standard Linux. </span><span class="line" data-startTime="2189">It just runs on the CPU, but it </span><span class="line" data-startTime="2189">was really straightforward, </span><span class="line" data-startTime="2192">because we make such heavy use </span><span class="line" data-startTime="2192">of LLVM and Clang, essentially </span><span class="line" data-startTime="2197">we can port trivially to any </span><span class="line" data-startTime="2197">platform that has an LLVM and </span><span class="line" data-startTime="2201">Clang, good LLVM and </span><span class="line" data-startTime="2201">CLang support. </span><span class="line" data-startTime="2204">So in an upcoming AOSP release, </span><span class="line" data-startTime="2204">you'll see all sorts </span><span class="line" data-startTime="2207">of ifdefs for things </span><span class="line" data-startTime="2207">like RS server. </span><span class="line" data-startTime="2211">And if you wanted to construct </span><span class="line" data-startTime="2211">your own MIG file with an </span><span class="line" data-startTime="2213">appropriate version of LLVM </span><span class="line" data-startTime="2213">and Clang, you could </span><span class="line" data-startTime="2215">certainly do that. </span></p>

<p class="speaker"><span class="line" data-starttime="2217"><span class="speakerName">Audience</span>: Thanks. </span></p>

<p class="speaker"><span class="line" data-starttime="2219"><span class="speakerName">Audience</span>: Hi. </span><span class="line" data-startTime="2219">I was wondering when the API </span><span class="line" data-startTime="2219">18 RenderScript stuff gets </span><span class="line" data-startTime="2224">into the compatibility </span><span class="line" data-startTime="2224">package. </span><span class="line" data-startTime="2225">Will that include the </span><span class="line" data-startTime="2225">script intrinsics? </span></p>

<p class="speaker"><span class="line" data-starttime="2228"><span class="speakerName">Jason Sams</span>: Yes. </span></p>

<p class="speaker"><span class="line" data-starttime="2229"><span class="speakerName">Audience</span>: OK. </span><span class="line" data-startTime="2229">Easy question. </span><span class="line" data-startTime="2230">Oh, follow up. </span><span class="line" data-startTime="2232">Is there any time </span><span class="line" data-startTime="2232">frame for that? </span></p>

<p class="speaker"><span class="line" data-starttime="2233"><span class="speakerName">Jason Sams</span>: No. </span></p>

<p class="speaker"><span class="line" data-starttime="2233"><span class="speakerName">Tim Murray</span>: No. </span></p>

<p class="speaker"><span class="line" data-starttime="2236"><span class="speakerName">Jason Sams</span>: You can't </span><span class="line" data-startTime="2236">trick us. </span></p>

<p class="speaker"><span class="line" data-starttime="2238"><span class="speakerName">Audience</span>: So just to confirm, </span><span class="line" data-startTime="2238">the Gingerbread stuff is </span><span class="line" data-startTime="2241">dependent upon 18 coming out. </span><span class="line" data-startTime="2243">And then the compatibility </span><span class="line" data-startTime="2243">library </span><span class="line" data-startTime="2244">will have that, correct? </span></p>

<p class="speaker"><span class="line" data-starttime="2246"><span class="speakerName">Tim Murray</span>: Correct. </span></p>

<p class="speaker"><span class="line" data-starttime="2246"><span class="speakerName">Audience</span>: OK, follow up is what </span><span class="line" data-startTime="2246">memory constraints are </span><span class="line" data-startTime="2249">there for the size of the </span><span class="line" data-startTime="2249">RenderScript kernels </span><span class="line" data-startTime="2252">that you can build? </span></p>

<p class="speaker"><span class="line" data-starttime="2254"><span class="speakerName">Tim Murray</span>: What do you </span><span class="line" data-startTime="2254">mean by the size? </span></p>

<p class="speaker"><span class="line" data-starttime="2257"><span class="speakerName">Audience</span>: Byte code size, like </span><span class="line" data-startTime="2257">how big of function or sets of </span><span class="line" data-startTime="2261">functions can you build for </span><span class="line" data-startTime="2261">might be hitting memory issues </span><span class="line" data-startTime="2265">in your device dependent, </span><span class="line" data-startTime="2265">or things that you </span><span class="line" data-startTime="2268">have seen in the wild? </span></p>

<p class="speaker"><span class="line" data-starttime="2269"><span class="speakerName">Jason Sams</span>: I've seen an entire </span><span class="line" data-startTime="2269">H264 encoder written in </span><span class="line" data-startTime="2272">RenderScript, so the size </span><span class="line" data-startTime="2272">limits are pretty high. </span></p>

<p class="speaker"><span class="line" data-starttime="2276"><span class="speakerName">Tim Murray</span>: Yeah, I don't think </span><span class="line" data-startTime="2276">you'll run into too many </span><span class="line" data-startTime="2277">issues with code size. </span></p>

<p class="speaker"><span class="line" data-starttime="2281"><span class="speakerName">Audience</span>: Hi, my name is Mark. </span><span class="line" data-startTime="2282">I would like to know, like, more </span><span class="line" data-startTime="2282">from the graphical side </span><span class="line" data-startTime="2285">of Android, so they are really </span><span class="line" data-startTime="2285">high, dedicated examples of </span><span class="line" data-startTime="2290">doing graphics in </span><span class="line" data-startTime="2290">Windows script. </span><span class="line" data-startTime="2291">Like for example, the page </span><span class="line" data-startTime="2291">flipping in the ebook reader, </span><span class="line" data-startTime="2294">and in the YouTube app, and I </span><span class="line" data-startTime="2294">guess the cover flow and the </span><span class="line" data-startTime="2298">play music is also done </span><span class="line" data-startTime="2298">with Windows script. </span><span class="line" data-startTime="2302">Have you thought of building </span><span class="line" data-startTime="2302">a website with really high, </span><span class="line" data-startTime="2305">dedicated examples with </span><span class="line" data-startTime="2305">Windows script? </span></p>

<p class="speaker"><span class="line" data-starttime="2310"><span class="speakerName">Tim Murray</span>: So we are trying to </span><span class="line" data-startTime="2310">improve our documentation </span><span class="line" data-startTime="2313">and improve our samples. </span><span class="line" data-startTime="2314">In API [INAUDIBLE] you'll see </span><span class="line" data-startTime="2314">a lot of new and kind of </span><span class="line" data-startTime="2319">hopefully clearer </span><span class="line" data-startTime="2319">documentation. </span><span class="line" data-startTime="2322">Samples we are working on, in </span><span class="line" data-startTime="2322">general, one of hte best </span><span class="line" data-startTime="2325">places to look right now, we </span><span class="line" data-startTime="2325">have a test called image </span><span class="line" data-startTime="2328">processing. </span><span class="line" data-startTime="2330">You can find that in ALSP. </span><span class="line" data-startTime="2331">That has a lot of different </span><span class="line" data-startTime="2331">kernels, and can basically </span><span class="line" data-startTime="2334">give you a good idea of how </span><span class="line" data-startTime="2334">to write a RenderScript </span><span class="line" data-startTime="2336">application. </span></p>

<p class="speaker"><span class="line" data-starttime="2338"><span class="speakerName">Audience</span>: So, no website </span><span class="line" data-startTime="2338">available with great examples </span><span class="line" data-startTime="2341">here, just the examples </span><span class="line" data-startTime="2341">in the SDK? </span></p>

<p class="speaker"><span class="line" data-starttime="2344"><span class="speakerName">Tim Murray</span>: Yeah, most likely. </span><span class="line" data-startTime="2345">I mean, that's where we're </span><span class="line" data-startTime="2345">focusing for now. </span></p>

<p class="speaker"><span class="line" data-starttime="2349"><span class="speakerName">Audience</span>: You said you're not </span><span class="line" data-startTime="2349">going to support anything </span><span class="line" data-startTime="2352">other than the CPU </span><span class="line" data-startTime="2352">on Gingerbread. </span><span class="line" data-startTime="2354">Is there a technical reason </span><span class="line" data-startTime="2354">you can't do that? </span><span class="line" data-startTime="2357">I mean, there are a lot </span><span class="line" data-startTime="2357">of usable phone DSPs. </span></p>

<p class="speaker"><span class="line" data-starttime="2359"><span class="speakerName">Tim Murray</span>: Yeah, so essentially </span><span class="line" data-startTime="2359">we would need a </span><span class="line" data-startTime="2361">new driver on there, and the way </span><span class="line" data-startTime="2361">we have our driver work is </span><span class="line" data-startTime="2368">we're an OS component. </span><span class="line" data-startTime="2370">And the way we can get around </span><span class="line" data-startTime="2370">that on the compatibility </span><span class="line" data-startTime="2373">library is by loading these </span><span class="line" data-startTime="2373">shared libraries, which, </span><span class="line" data-startTime="2377">they're not OS components. </span><span class="line" data-startTime="2379">So essentially, if we were to </span><span class="line" data-startTime="2379">try to support anything more </span><span class="line" data-startTime="2382">than the CPU on Gingerbread, </span><span class="line" data-startTime="2382">they would have to update that </span><span class="line" data-startTime="2387">part of their OS. </span></p>

<p class="speaker"><span class="line" data-starttime="2389"><span class="speakerName">Audience</span>: So is there no way to </span><span class="line" data-startTime="2389">get access to, say, like, </span><span class="line" data-startTime="2391">TIDSP or anything like that? </span></p>

<p class="speaker"><span class="line" data-starttime="2393"><span class="speakerName">Tim Murray</span>: Not on </span><span class="line" data-startTime="2393">Gingerbread, no. </span></p>

<p class="speaker"><span class="line" data-starttime="2394"><span class="speakerName">Jason Sams</span>: The support </span><span class="line" data-startTime="2394">necessarily in the OS simply </span><span class="line" data-startTime="2396">wasn't there in Gingerbread, so </span><span class="line" data-startTime="2396">there's really nothing we </span><span class="line" data-startTime="2399">can do without an OS update. </span><span class="line" data-startTime="2402">OK, thanks everyone. </span><span class="line" data-startTime="2402">I think we're out of time, so </span><span class="line" data-startTime="2402">will be around for office </span><span class="line" data-startTime="2405">hours if anyone has additional </span><span class="line" data-startTime="2405">questions. </span></p>